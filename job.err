
Activating Modules:
  1) GCCcore/13.2.0                   7) bzip2/1.0.8-GCCcore-13.2.0
  2) Python/3.11.5-GCCcore-13.2.0     8) libffi/3.4.4-GCCcore-13.2.0
  3) SQLite/3.43.1-GCCcore-13.2.0     9) libreadline/8.2-GCCcore-13.2.0
  4) Tcl/8.6.13-GCCcore-13.2.0       10) ncurses/6.4-GCCcore-13.2.0
  5) XZ/5.4.4-GCCcore-13.2.0         11) zlib/1.2.13-GCCcore-13.2.0
  6) binutils/2.40-GCCcore-13.2.0


Activating Modules:
  1) CUDA/12.5.0

/home/ucl/irec/darimez/.local/lib/python3.11/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/ucl/irec/darimez/.local/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/ucl/irec/darimez/.local/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
wandb: Tracking run with wandb version 0.22.2
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /auto/home/users/d/a/darimez/MIRO/vllmcluster/wandb/offline-run-20251021_021613-kyyf6zgl
Training Epoch 1:   0%|          | 0/36984 [00:00<?, ?batch/s]Training Epoch 1:   0%|          | 1/36984 [00:14<148:37:11, 14.47s/batch]Training Epoch 1:   0%|          | 2/36984 [00:14<63:46:00,  6.21s/batch] Training Epoch 1:   0%|          | 3/36984 [00:29<103:37:23, 10.09s/batch]Training Epoch 1:   0%|          | 4/36984 [00:29<63:34:07,  6.19s/batch] Training Epoch 1:   0%|          | 5/36984 [00:45<99:05:46,  9.65s/batch]Training Epoch 1:   0%|          | 6/36984 [00:46<68:57:24,  6.71s/batch]Training Epoch 1:   0%|          | 7/36984 [00:58<87:42:21,  8.54s/batch]Training Epoch 1:   0%|          | 8/36984 [00:59<61:51:37,  6.02s/batch]Training Epoch 1:   0%|          | 9/36984 [01:13<88:26:40,  8.61s/batch]Training Epoch 1:   0%|          | 10/36984 [01:14<63:36:38,  6.19s/batch]Training Epoch 1:   0%|          | 11/36984 [01:32<99:27:28,  9.68s/batch]Training Epoch 1:   0%|          | 12/36984 [01:32<71:14:12,  6.94s/batch]Training Epoch 1:   0%|          | 13/36984 [01:44<87:07:00,  8.48s/batch]Training Epoch 1:   0%|          | 14/36984 [01:45<63:31:45,  6.19s/batch]Training Epoch 1:   0%|          | 15/36984 [01:57<81:59:22,  7.98s/batch]Training Epoch 1:   0%|          | 16/36984 [01:59<61:09:17,  5.96s/batch]Training Epoch 1:   0%|          | 17/36984 [02:12<83:46:16,  8.16s/batch]Training Epoch 1:   0%|          | 18/36984 [02:14<65:33:14,  6.38s/batch]Training Epoch 1:   0%|          | 19/36984 [02:23<72:49:16,  7.09s/batch]Training Epoch 1:   0%|          | 20/36984 [02:26<58:54:04,  5.74s/batch]Training Epoch 1:   0%|          | 21/36984 [02:35<69:24:08,  6.76s/batch]Training Epoch 1:   0%|          | 22/36984 [02:40<65:14:03,  6.35s/batch]Training Epoch 1:   0%|          | 23/36984 [02:47<67:50:38,  6.61s/batch]Training Epoch 1:   0%|          | 24/36984 [02:52<61:56:06,  6.03s/batch]Training Epoch 1:   0%|          | 25/36984 [03:01<70:43:39,  6.89s/batch]Training Epoch 1:   0%|          | 26/36984 [03:06<64:18:35,  6.26s/batch]Training Epoch 1:   0%|          | 27/36984 [03:11<61:15:00,  5.97s/batch]Training Epoch 1:   0%|          | 28/36984 [03:16<58:10:32,  5.67s/batch]Training Epoch 1:   0%|          | 29/36984 [03:22<60:47:06,  5.92s/batch]Training Epoch 1:   0%|          | 30/36984 [03:27<58:06:53,  5.66s/batch]Training Epoch 1:   0%|          | 31/36984 [03:34<59:53:43,  5.84s/batch]Training Epoch 1:   0%|          | 31/36984 [03:43<59:53:43,  5.84s/batch, loss=0.0062]Training Epoch 1:   0%|          | 32/36984 [03:43<70:20:03,  6.85s/batch, loss=0.0062]Training Epoch 1:   0%|          | 33/36984 [03:50<70:59:02,  6.92s/batch, loss=0.0062]Training Epoch 1:   0%|          | 34/36984 [03:56<67:21:08,  6.56s/batch, loss=0.0062]Training Epoch 1:   0%|          | 35/36984 [04:03<68:29:20,  6.67s/batch, loss=0.0062]Training Epoch 1:   0%|          | 36/36984 [04:08<63:21:11,  6.17s/batch, loss=0.0062]Training Epoch 1:   0%|          | 37/36984 [04:14<64:11:25,  6.25s/batch, loss=0.0062]Training Epoch 1:   0%|          | 38/36984 [04:23<72:08:21,  7.03s/batch, loss=0.0062]Training Epoch 1:   0%|          | 39/36984 [04:28<65:04:15,  6.34s/batch, loss=0.0062]Training Epoch 1:   0%|          | 40/36984 [04:34<64:27:32,  6.28s/batch, loss=0.0062]Training Epoch 1:   0%|          | 41/36984 [04:39<59:51:17,  5.83s/batch, loss=0.0062]Training Epoch 1:   0%|          | 42/36984 [04:45<60:24:19,  5.89s/batch, loss=0.0062]Training Epoch 1:   0%|          | 43/36984 [04:51<63:13:58,  6.16s/batch, loss=0.0062]Training Epoch 1:   0%|          | 44/36984 [04:59<68:17:59,  6.66s/batch, loss=0.0062]Training Epoch 1:   0%|          | 45/36984 [05:04<62:58:49,  6.14s/batch, loss=0.0062]Training Epoch 1:   0%|          | 46/36984 [05:11<64:27:11,  6.28s/batch, loss=0.0062]Training Epoch 1:   0%|          | 47/36984 [05:16<60:34:24,  5.90s/batch, loss=0.0062]Training Epoch 1:   0%|          | 48/36984 [05:22<61:21:25,  5.98s/batch, loss=0.0062]Training Epoch 1:   0%|          | 49/36984 [05:26<56:10:37,  5.48s/batch, loss=0.0062]Training Epoch 1:   0%|          | 50/36984 [05:33<59:01:58,  5.75s/batch, loss=0.0062]Training Epoch 1:   0%|          | 51/36984 [05:37<54:56:11,  5.35s/batch, loss=0.0062]Training Epoch 1:   0%|          | 52/36984 [05:43<57:25:44,  5.60s/batch, loss=0.0062]Training Epoch 1:   0%|          | 53/36984 [05:48<54:21:31,  5.30s/batch, loss=0.0062]Training Epoch 1:   0%|          | 54/36984 [05:55<59:51:38,  5.84s/batch, loss=0.0062]Training Epoch 1:   0%|          | 55/36984 [06:01<59:54:46,  5.84s/batch, loss=0.0062]Training Epoch 1:   0%|          | 56/36984 [06:08<63:42:44,  6.21s/batch, loss=0.0062]Training Epoch 1:   0%|          | 57/36984 [06:13<58:51:41,  5.74s/batch, loss=0.0062]Training Epoch 1:   0%|          | 58/36984 [06:20<63:05:10,  6.15s/batch, loss=0.0062]Training Epoch 1:   0%|          | 59/36984 [06:25<59:40:37,  5.82s/batch, loss=0.0062]Training Epoch 1:   0%|          | 60/36984 [06:30<58:14:23,  5.68s/batch, loss=0.0062]Training Epoch 1:   0%|          | 61/36984 [06:36<57:57:14,  5.65s/batch, loss=0.0062]Training Epoch 1:   0%|          | 62/36984 [06:47<74:50:35,  7.30s/batch, loss=0.0062]Training Epoch 1:   0%|          | 63/36984 [06:52<70:00:48,  6.83s/batch, loss=0.0062]Training Epoch 1:   0%|          | 63/36984 [06:58<70:00:48,  6.83s/batch, loss=0.0049]Training Epoch 1:   0%|          | 64/36984 [06:58<66:52:15,  6.52s/batch, loss=0.0049]Training Epoch 1:   0%|          | 65/36984 [07:05<67:42:29,  6.60s/batch, loss=0.0049]Training Epoch 1:   0%|          | 66/36984 [07:10<63:29:23,  6.19s/batch, loss=0.0049]Training Epoch 1:   0%|          | 67/36984 [07:16<62:56:48,  6.14s/batch, loss=0.0049]Training Epoch 1:   0%|          | 68/36984 [07:22<60:20:02,  5.88s/batch, loss=0.0049]Training Epoch 1:   0%|          | 69/36984 [07:27<58:51:32,  5.74s/batch, loss=0.0049]Training Epoch 1:   0%|          | 70/36984 [07:33<58:29:27,  5.70s/batch, loss=0.0049]Training Epoch 1:   0%|          | 71/36984 [07:38<58:02:33,  5.66s/batch, loss=0.0049]Training Epoch 1:   0%|          | 72/36984 [07:43<55:43:47,  5.44s/batch, loss=0.0049]Training Epoch 1:   0%|          | 73/36984 [07:49<56:06:52,  5.47s/batch, loss=0.0049]Training Epoch 1:   0%|          | 74/36984 [07:54<55:40:29,  5.43s/batch, loss=0.0049]Training Epoch 1:   0%|          | 75/36984 [07:59<54:24:10,  5.31s/batch, loss=0.0049]Training Epoch 1:   0%|          | 76/36984 [08:05<55:54:24,  5.45s/batch, loss=0.0049]Training Epoch 1:   0%|          | 77/36984 [08:10<53:35:57,  5.23s/batch, loss=0.0049]Training Epoch 1:   0%|          | 78/36984 [08:18<63:43:23,  6.22s/batch, loss=0.0049]Training Epoch 1:   0%|          | 79/36984 [08:24<61:46:25,  6.03s/batch, loss=0.0049]Training Epoch 1:   0%|          | 80/36984 [08:29<60:44:19,  5.93s/batch, loss=0.0049]Training Epoch 1:   0%|          | 81/36984 [08:34<58:09:58,  5.67s/batch, loss=0.0049]Training Epoch 1:   0%|          | 82/36984 [08:40<57:59:35,  5.66s/batch, loss=0.0049]Training Epoch 1:   0%|          | 83/36984 [08:46<58:21:01,  5.69s/batch, loss=0.0049]Training Epoch 1:   0%|          | 84/36984 [09:01<86:52:22,  8.48s/batch, loss=0.0049]Training Epoch 1:   0%|          | 85/36984 [09:08<82:33:05,  8.05s/batch, loss=0.0049]Training Epoch 1:   0%|          | 86/36984 [09:15<78:44:21,  7.68s/batch, loss=0.0049]Training Epoch 1:   0%|          | 87/36984 [09:20<73:03:48,  7.13s/batch, loss=0.0049]Training Epoch 1:   0%|          | 88/36984 [09:25<65:30:41,  6.39s/batch, loss=0.0049]Training Epoch 1:   0%|          | 89/36984 [09:31<64:24:29,  6.28s/batch, loss=0.0049]Training Epoch 1:   0%|          | 90/36984 [09:36<59:26:23,  5.80s/batch, loss=0.0049]Training Epoch 1:   0%|          | 91/36984 [09:42<59:03:33,  5.76s/batch, loss=0.0049]Training Epoch 1:   0%|          | 92/36984 [09:46<56:05:52,  5.47s/batch, loss=0.0049]Training Epoch 1:   0%|          | 93/36984 [09:53<58:31:02,  5.71s/batch, loss=0.0049]Training Epoch 1:   0%|          | 94/36984 [09:57<54:16:26,  5.30s/batch, loss=0.0049]Training Epoch 1:   0%|          | 95/36984 [10:03<57:56:14,  5.65s/batch, loss=0.0049]Training Epoch 1:   0%|          | 95/36984 [10:08<57:56:14,  5.65s/batch, loss=0.0041]Training Epoch 1:   0%|          | 96/36984 [10:08<56:04:34,  5.47s/batch, loss=0.0041]Training Epoch 1:   0%|          | 97/36984 [10:14<57:39:08,  5.63s/batch, loss=0.0041]Training Epoch 1:   0%|          | 98/36984 [10:19<54:06:59,  5.28s/batch, loss=0.0041]Training Epoch 1:   0%|          | 99/36984 [10:26<58:20:43,  5.69s/batch, loss=0.0041]Training Epoch 1:   0%|          | 100/36984 [10:30<53:28:50,  5.22s/batch, loss=0.0041]Training Epoch 1:   0%|          | 101/36984 [10:36<57:30:45,  5.61s/batch, loss=0.0041]Training Epoch 1:   0%|          | 102/36984 [10:42<56:31:21,  5.52s/batch, loss=0.0041]Training Epoch 1:   0%|          | 103/36984 [10:49<62:51:25,  6.14s/batch, loss=0.0041]Training Epoch 1:   0%|          | 104/36984 [10:55<62:28:03,  6.10s/batch, loss=0.0041]Training Epoch 1:   0%|          | 105/36984 [11:01<63:13:18,  6.17s/batch, loss=0.0041]Training Epoch 1:   0%|          | 106/36984 [11:07<60:00:39,  5.86s/batch, loss=0.0041]Training Epoch 1:   0%|          | 107/36984 [11:13<62:07:55,  6.07s/batch, loss=0.0041]Training Epoch 1:   0%|          | 108/36984 [11:18<59:29:12,  5.81s/batch, loss=0.0041]Training Epoch 1:   0%|          | 109/36984 [11:26<64:29:16,  6.30s/batch, loss=0.0041]Training Epoch 1:   0%|          | 110/36984 [11:33<66:36:09,  6.50s/batch, loss=0.0041]Training Epoch 1:   0%|          | 111/36984 [11:41<70:23:28,  6.87s/batch, loss=0.0041]Training Epoch 1:   0%|          | 112/36984 [11:48<70:59:21,  6.93s/batch, loss=0.0041]Training Epoch 1:   0%|          | 113/36984 [11:54<70:57:17,  6.93s/batch, loss=0.0041]Training Epoch 1:   0%|          | 114/36984 [12:04<77:47:36,  7.60s/batch, loss=0.0041]Training Epoch 1:   0%|          | 115/36984 [12:12<79:23:09,  7.75s/batch, loss=0.0041]Training Epoch 1:   0%|          | 116/36984 [12:22<86:51:15,  8.48s/batch, loss=0.0041]Training Epoch 1:   0%|          | 117/36984 [12:26<74:32:46,  7.28s/batch, loss=0.0041]Training Epoch 1:   0%|          | 118/36984 [12:37<85:01:29,  8.30s/batch, loss=0.0041]Training Epoch 1:   0%|          | 119/36984 [12:41<71:15:22,  6.96s/batch, loss=0.0041]Training Epoch 1:   0%|          | 120/36984 [12:50<79:14:25,  7.74s/batch, loss=0.0041]Training Epoch 1:   0%|          | 121/36984 [12:54<67:43:14,  6.61s/batch, loss=0.0041]Training Epoch 1:   0%|          | 122/36984 [13:06<81:16:21,  7.94s/batch, loss=0.0041]Training Epoch 1:   0%|          | 123/36984 [13:09<68:27:31,  6.69s/batch, loss=0.0041]Training Epoch 1:   0%|          | 124/36984 [13:18<73:46:56,  7.21s/batch, loss=0.0041]Training Epoch 1:   0%|          | 125/36984 [13:21<63:15:57,  6.18s/batch, loss=0.0041]Training Epoch 1:   0%|          | 126/36984 [13:30<70:27:53,  6.88s/batch, loss=0.0041]Training Epoch 1:   0%|          | 127/36984 [13:34<60:32:44,  5.91s/batch, loss=0.0041]Training Epoch 1:   0%|          | 127/36984 [13:42<60:32:44,  5.91s/batch, loss=0.0039]Training Epoch 1:   0%|          | 128/36984 [13:42<68:19:10,  6.67s/batch, loss=0.0039]Training Epoch 1:   0%|          | 129/36984 [13:46<59:48:51,  5.84s/batch, loss=0.0039]Training Epoch 1:   0%|          | 130/36984 [14:03<94:22:29,  9.22s/batch, loss=0.0039]Training Epoch 1:   0%|          | 131/36984 [14:07<77:26:59,  7.57s/batch, loss=0.0039]Training Epoch 1:   0%|          | 132/36984 [14:18<87:51:58,  8.58s/batch, loss=0.0039]Training Epoch 1:   0%|          | 133/36984 [14:22<76:01:59,  7.43s/batch, loss=0.0039]Training Epoch 1:   0%|          | 134/36984 [14:30<77:11:17,  7.54s/batch, loss=0.0039]Training Epoch 1:   0%|          | 135/36984 [14:34<64:23:36,  6.29s/batch, loss=0.0039]Training Epoch 1:   0%|          | 136/36984 [14:43<73:32:05,  7.18s/batch, loss=0.0039]Training Epoch 1:   0%|          | 137/36984 [14:46<61:33:41,  6.01s/batch, loss=0.0039]Training Epoch 1:   0%|          | 138/36984 [14:55<68:59:55,  6.74s/batch, loss=0.0039]Training Epoch 1:   0%|          | 139/36984 [14:58<58:44:13,  5.74s/batch, loss=0.0039]Training Epoch 1:   0%|          | 140/36984 [15:09<73:51:45,  7.22s/batch, loss=0.0039]Training Epoch 1:   0%|          | 141/36984 [15:15<71:38:38,  7.00s/batch, loss=0.0039]Training Epoch 1:   0%|          | 142/36984 [15:23<74:44:38,  7.30s/batch, loss=0.0039]Training Epoch 1:   0%|          | 143/36984 [15:28<66:20:52,  6.48s/batch, loss=0.0039]Training Epoch 1:   0%|          | 144/36984 [15:40<82:27:07,  8.06s/batch, loss=0.0039]Training Epoch 1:   0%|          | 145/36984 [15:47<80:48:52,  7.90s/batch, loss=0.0039]Training Epoch 1:   0%|          | 146/36984 [16:02<102:30:05, 10.02s/batch, loss=0.0039]Training Epoch 1:   0%|          | 147/36984 [16:10<95:53:30,  9.37s/batch, loss=0.0039] Training Epoch 1:   0%|          | 148/36984 [16:18<90:30:37,  8.85s/batch, loss=0.0039]Training Epoch 1:   0%|          | 149/36984 [16:20<71:14:54,  6.96s/batch, loss=0.0039]Training Epoch 1:   0%|          | 150/36984 [16:36<98:52:16,  9.66s/batch, loss=0.0039]Training Epoch 1:   0%|          | 151/36984 [16:40<81:16:53,  7.94s/batch, loss=0.0039]Training Epoch 1:   0%|          | 152/36984 [16:50<86:08:03,  8.42s/batch, loss=0.0039]Training Epoch 1:   0%|          | 153/36984 [16:52<67:17:00,  6.58s/batch, loss=0.0039]Training Epoch 1:   0%|          | 154/36984 [17:07<95:09:25,  9.30s/batch, loss=0.0039]Training Epoch 1:   0%|          | 155/36984 [17:09<72:53:21,  7.12s/batch, loss=0.0039]Training Epoch 1:   0%|          | 156/36984 [17:20<83:56:49,  8.21s/batch, loss=0.0039]Training Epoch 1:   0%|          | 157/36984 [17:25<72:09:52,  7.05s/batch, loss=0.0039]Training Epoch 1:   0%|          | 158/36984 [17:34<79:27:36,  7.77s/batch, loss=0.0039]Training Epoch 1:   0%|          | 159/36984 [17:38<66:44:02,  6.52s/batch, loss=0.0039]Training Epoch 1:   0%|          | 159/36984 [17:46<66:44:02,  6.52s/batch, loss=0.0032]Training Epoch 1:   0%|          | 160/36984 [17:46<71:37:45,  7.00s/batch, loss=0.0032]Training Epoch 1:   0%|          | 161/36984 [17:48<58:31:28,  5.72s/batch, loss=0.0032]Training Epoch 1:   0%|          | 162/36984 [17:56<64:33:36,  6.31s/batch, loss=0.0032]Training Epoch 1:   0%|          | 163/36984 [17:59<53:29:34,  5.23s/batch, loss=0.0032]Training Epoch 1:   0%|          | 164/36984 [18:06<60:30:15,  5.92s/batch, loss=0.0032]Training Epoch 1:   0%|          | 165/36984 [18:09<51:28:27,  5.03s/batch, loss=0.0032]Training Epoch 1:   0%|          | 166/36984 [18:17<59:00:12,  5.77s/batch, loss=0.0032]Training Epoch 1:   0%|          | 167/36984 [18:19<49:23:19,  4.83s/batch, loss=0.0032]Training Epoch 1:   0%|          | 168/36984 [18:28<59:12:27,  5.79s/batch, loss=0.0032]Training Epoch 1:   0%|          | 169/36984 [18:30<48:13:37,  4.72s/batch, loss=0.0032]Training Epoch 1:   0%|          | 170/36984 [18:38<59:42:09,  5.84s/batch, loss=0.0032]Training Epoch 1:   0%|          | 171/36984 [18:40<48:36:42,  4.75s/batch, loss=0.0032]Training Epoch 1:   0%|          | 172/36984 [18:49<60:13:53,  5.89s/batch, loss=0.0032]Training Epoch 1:   0%|          | 173/36984 [18:51<47:51:34,  4.68s/batch, loss=0.0032]Training Epoch 1:   0%|          | 174/36984 [19:01<63:59:41,  6.26s/batch, loss=0.0032]Training Epoch 1:   0%|          | 175/36984 [19:01<46:38:02,  4.56s/batch, loss=0.0032]Training Epoch 1:   0%|          | 176/36984 [19:14<71:05:39,  6.95s/batch, loss=0.0032]Training Epoch 1:   0%|          | 177/36984 [19:15<54:33:49,  5.34s/batch, loss=0.0032]Training Epoch 1:   0%|          | 178/36984 [19:27<73:49:19,  7.22s/batch, loss=0.0032]Training Epoch 1:   0%|          | 179/36984 [19:30<59:57:32,  5.86s/batch, loss=0.0032]Training Epoch 1:   0%|          | 180/36984 [19:44<85:38:38,  8.38s/batch, loss=0.0032]Training Epoch 1:   0%|          | 181/36984 [19:45<62:48:33,  6.14s/batch, loss=0.0032]Training Epoch 1:   0%|          | 182/36984 [19:59<86:50:33,  8.50s/batch, loss=0.0032]Training Epoch 1:   0%|          | 183/36984 [20:00<65:22:07,  6.39s/batch, loss=0.0032]Training Epoch 1:   0%|          | 184/36984 [20:10<74:46:28,  7.31s/batch, loss=0.0032]Training Epoch 1:   1%|          | 185/36984 [20:12<58:27:41,  5.72s/batch, loss=0.0032]Training Epoch 1:   1%|          | 186/36984 [20:22<70:33:20,  6.90s/batch, loss=0.0032]Training Epoch 1:   1%|          | 187/36984 [20:24<57:23:01,  5.61s/batch, loss=0.0032]Training Epoch 1:   1%|          | 188/36984 [20:36<76:08:44,  7.45s/batch, loss=0.0032]Training Epoch 1:   1%|          | 189/36984 [20:38<60:23:50,  5.91s/batch, loss=0.0032]Training Epoch 1:   1%|          | 190/36984 [20:51<80:50:32,  7.91s/batch, loss=0.0032]Training Epoch 1:   1%|          | 191/36984 [20:52<59:12:52,  5.79s/batch, loss=0.0032]Training Epoch 1:   1%|          | 191/36984 [21:07<59:12:52,  5.79s/batch, loss=0.0030]Training Epoch 1:   1%|          | 192/36984 [21:07<88:40:12,  8.68s/batch, loss=0.0030]Training Epoch 1:   1%|          | 193/36984 [21:11<73:19:48,  7.18s/batch, loss=0.0030]Training Epoch 1:   1%|          | 194/36984 [21:31<114:33:48, 11.21s/batch, loss=0.0030]Training Epoch 1:   1%|          | 195/36984 [21:33<84:00:18,  8.22s/batch, loss=0.0030] Training Epoch 1:   1%|          | 196/36984 [21:44<92:46:54,  9.08s/batch, loss=0.0030]Training Epoch 1:   1%|          | 197/36984 [21:45<69:29:30,  6.80s/batch, loss=0.0030]Training Epoch 1:   1%|          | 198/36984 [21:56<82:14:40,  8.05s/batch, loss=0.0030]Training Epoch 1:   1%|          | 199/36984 [21:59<65:28:11,  6.41s/batch, loss=0.0030]Training Epoch 1:   1%|          | 200/36984 [22:09<77:53:36,  7.62s/batch, loss=0.0030]Training Epoch 1:   1%|          | 201/36984 [22:12<64:42:26,  6.33s/batch, loss=0.0030]Training Epoch 1:   1%|          | 202/36984 [22:25<85:04:08,  8.33s/batch, loss=0.0030]Training Epoch 1:   1%|          | 203/36984 [22:26<62:33:39,  6.12s/batch, loss=0.0030]Training Epoch 1:   1%|          | 204/36984 [22:37<77:08:57,  7.55s/batch, loss=0.0030]Training Epoch 1:   1%|          | 205/36984 [22:38<56:41:05,  5.55s/batch, loss=0.0030]Training Epoch 1:   1%|          | 206/36984 [22:48<71:05:17,  6.96s/batch, loss=0.0030]Training Epoch 1:   1%|          | 207/36984 [22:49<50:25:31,  4.94s/batch, loss=0.0030]Training Epoch 1:   1%|          | 208/36984 [23:04<81:58:04,  8.02s/batch, loss=0.0030]Training Epoch 1:   1%|          | 209/36984 [23:06<64:06:29,  6.28s/batch, loss=0.0030]Training Epoch 1:   1%|          | 210/36984 [23:20<88:34:23,  8.67s/batch, loss=0.0030]Training Epoch 1:   1%|          | 211/36984 [23:22<66:03:03,  6.47s/batch, loss=0.0030]Training Epoch 1:   1%|          | 212/36984 [23:32<77:02:29,  7.54s/batch, loss=0.0030]Training Epoch 1:   1%|          | 213/36984 [23:34<59:30:37,  5.83s/batch, loss=0.0030]Training Epoch 1:   1%|          | 214/36984 [23:43<71:02:16,  6.96s/batch, loss=0.0030]Training Epoch 1:   1%|          | 215/36984 [23:44<53:54:45,  5.28s/batch, loss=0.0030]Training Epoch 1:   1%|          | 216/36984 [24:00<84:06:18,  8.23s/batch, loss=0.0030]Training Epoch 1:   1%|          | 217/36984 [24:02<66:58:31,  6.56s/batch, loss=0.0030]Training Epoch 1:   1%|          | 218/36984 [24:15<87:04:53,  8.53s/batch, loss=0.0030]Training Epoch 1:   1%|          | 219/36984 [24:18<68:44:41,  6.73s/batch, loss=0.0030]Training Epoch 1:   1%|          | 220/36984 [24:29<83:20:04,  8.16s/batch, loss=0.0030]Training Epoch 1:   1%|          | 221/36984 [24:31<64:25:56,  6.31s/batch, loss=0.0030]Training Epoch 1:   1%|          | 222/36984 [24:41<74:51:22,  7.33s/batch, loss=0.0030]Training Epoch 1:   1%|          | 223/36984 [24:42<56:34:06,  5.54s/batch, loss=0.0030]Training Epoch 1:   1%|          | 223/36984 [24:56<56:34:06,  5.54s/batch, loss=0.0026]Training Epoch 1:   1%|          | 224/36984 [24:56<82:10:32,  8.05s/batch, loss=0.0026]Training Epoch 1:   1%|          | 225/36984 [24:57<58:50:05,  5.76s/batch, loss=0.0026]Training Epoch 1:   1%|          | 226/36984 [25:10<81:07:51,  7.95s/batch, loss=0.0026]Training Epoch 1:   1%|          | 227/36984 [25:10<57:27:07,  5.63s/batch, loss=0.0026]Training Epoch 1:   1%|          | 228/36984 [25:22<76:01:28,  7.45s/batch, loss=0.0026]Training Epoch 1:   1%|          | 229/36984 [25:22<53:52:56,  5.28s/batch, loss=0.0026]Training Epoch 1:   1%|          | 230/36984 [25:35<78:06:19,  7.65s/batch, loss=0.0026]Training Epoch 1:   1%|          | 231/36984 [25:35<55:20:14,  5.42s/batch, loss=0.0026]Training Epoch 1:   1%|          | 232/36984 [25:48<76:42:43,  7.51s/batch, loss=0.0026]Training Epoch 1:   1%|          | 233/36984 [25:48<54:21:33,  5.32s/batch, loss=0.0026]Training Epoch 1:   1%|          | 234/36984 [25:58<67:42:08,  6.63s/batch, loss=0.0026]Training Epoch 1:   1%|          | 235/36984 [25:58<48:02:57,  4.71s/batch, loss=0.0026]Training Epoch 1:   1%|          | 236/36984 [26:15<86:50:14,  8.51s/batch, loss=0.0026]Training Epoch 1:   1%|          | 237/36984 [26:15<61:26:53,  6.02s/batch, loss=0.0026]Training Epoch 1:   1%|          | 238/36984 [26:27<76:57:28,  7.54s/batch, loss=0.0026]Training Epoch 1:   1%|          | 239/36984 [26:27<54:31:59,  5.34s/batch, loss=0.0026]Training Epoch 1:   1%|          | 240/36984 [26:40<77:30:05,  7.59s/batch, loss=0.0026]Training Epoch 1:   1%|          | 241/36984 [26:40<54:54:41,  5.38s/batch, loss=0.0026]Training Epoch 1:   1%|          | 242/36984 [26:50<70:15:27,  6.88s/batch, loss=0.0026]Training Epoch 1:   1%|          | 243/36984 [26:50<49:49:53,  4.88s/batch, loss=0.0026]Training Epoch 1:   1%|          | 244/36984 [27:01<66:27:01,  6.51s/batch, loss=0.0026]Training Epoch 1:   1%|          | 245/36984 [27:01<47:10:44,  4.62s/batch, loss=0.0026]Training Epoch 1:   1%|          | 246/36984 [27:12<67:13:47,  6.59s/batch, loss=0.0026]Training Epoch 1:   1%|          | 247/36984 [27:12<47:43:34,  4.68s/batch, loss=0.0026]Training Epoch 1:   1%|          | 248/36984 [27:25<71:34:41,  7.01s/batch, loss=0.0026]Training Epoch 1:   1%|          | 249/36984 [27:25<50:45:58,  4.98s/batch, loss=0.0026]Training Epoch 1:   1%|          | 250/36984 [27:37<73:09:23,  7.17s/batch, loss=0.0026]Training Epoch 1:   1%|          | 251/36984 [27:38<51:52:37,  5.08s/batch, loss=0.0026]Training Epoch 1:   1%|          | 252/36984 [27:51<76:50:49,  7.53s/batch, loss=0.0026]Training Epoch 1:   1%|          | 253/36984 [27:51<54:27:28,  5.34s/batch, loss=0.0026]Training Epoch 1:   1%|          | 254/36984 [28:01<68:54:18,  6.75s/batch, loss=0.0026]Training Epoch 1:   1%|          | 255/36984 [28:01<48:53:42,  4.79s/batch, loss=0.0026]Training Epoch 1:   1%|          | 255/36984 [28:19<48:53:42,  4.79s/batch, loss=0.0022]Training Epoch 1:   1%|          | 256/36984 [28:19<87:30:44,  8.58s/batch, loss=0.0022]Training Epoch 1:   1%|          | 258/36984 [28:30<73:30:20,  7.21s/batch, loss=0.0022]Training Epoch 1:   1%|          | 259/36984 [28:30<55:49:54,  5.47s/batch, loss=0.0022]Training Epoch 1:   1%|          | 260/36984 [28:41<71:19:33,  6.99s/batch, loss=0.0022]Training Epoch 1:   1%|          | 261/36984 [28:42<52:31:27,  5.15s/batch, loss=0.0022]Training Epoch 1:   1%|          | 262/36984 [28:54<73:35:13,  7.21s/batch, loss=0.0022]Training Epoch 1:   1%|          | 263/36984 [28:54<53:12:07,  5.22s/batch, loss=0.0022]Training Epoch 1:   1%|          | 264/36984 [29:04<67:00:55,  6.57s/batch, loss=0.0022]Training Epoch 1:   1%|          | 265/36984 [29:04<48:02:26,  4.71s/batch, loss=0.0022]Training Epoch 1:   1%|          | 266/36984 [29:15<65:42:44,  6.44s/batch, loss=0.0022]Training Epoch 1:   1%|          | 267/36984 [29:15<46:53:29,  4.60s/batch, loss=0.0022]Training Epoch 1:   1%|          | 268/36984 [29:30<79:03:33,  7.75s/batch, loss=0.0022]Training Epoch 1:   1%|          | 269/36984 [29:31<56:08:21,  5.50s/batch, loss=0.0022]Training Epoch 1:   1%|          | 270/36984 [29:46<85:43:30,  8.41s/batch, loss=0.0022]Training Epoch 1:   1%|          | 271/36984 [29:46<60:44:28,  5.96s/batch, loss=0.0022]Training Epoch 1:   1%|          | 272/36984 [29:58<78:30:43,  7.70s/batch, loss=0.0022]Training Epoch 1:   1%|          | 273/36984 [29:58<55:39:10,  5.46s/batch, loss=0.0022]Training Epoch 1:   1%|          | 274/36984 [30:11<78:21:39,  7.68s/batch, loss=0.0022]Training Epoch 1:   1%|          | 275/36984 [30:11<55:31:51,  5.45s/batch, loss=0.0022]Training Epoch 1:   1%|          | 276/36984 [30:23<73:23:27,  7.20s/batch, loss=0.0022]Training Epoch 1:   1%|          | 277/36984 [30:23<52:02:27,  5.10s/batch, loss=0.0022]Training Epoch 1:   1%|          | 278/36984 [30:35<72:27:37,  7.11s/batch, loss=0.0022]Training Epoch 1:   1%|          | 279/36984 [30:35<51:23:24,  5.04s/batch, loss=0.0022]Training Epoch 1:   1%|          | 280/36984 [30:47<72:05:11,  7.07s/batch, loss=0.0022]Training Epoch 1:   1%|          | 281/36984 [30:47<51:07:42,  5.01s/batch, loss=0.0022]Training Epoch 1:   1%|          | 282/36984 [31:01<78:02:18,  7.65s/batch, loss=0.0022]Training Epoch 1:   1%|          | 283/36984 [31:01<55:17:23,  5.42s/batch, loss=0.0022]Training Epoch 1:   1%|          | 284/36984 [31:20<98:39:27,  9.68s/batch, loss=0.0022]Training Epoch 1:   1%|          | 285/36984 [31:21<69:43:22,  6.84s/batch, loss=0.0022]Training Epoch 1:   1%|          | 286/36984 [31:33<86:51:01,  8.52s/batch, loss=0.0022]Training Epoch 1:   1%|          | 287/36984 [31:33<61:27:24,  6.03s/batch, loss=0.0022]Training Epoch 1:   1%|          | 287/36984 [31:44<61:27:24,  6.03s/batch, loss=0.0021]Training Epoch 1:   1%|          | 288/36984 [31:44<74:42:03,  7.33s/batch, loss=0.0021]Training Epoch 1:   1%|          | 290/36984 [31:57<72:12:42,  7.08s/batch, loss=0.0021]Training Epoch 1:   1%|          | 291/36984 [31:57<54:51:23,  5.38s/batch, loss=0.0021]Training Epoch 1:   1%|          | 292/36984 [32:08<69:23:09,  6.81s/batch, loss=0.0021]Training Epoch 1:   1%|          | 293/36984 [32:09<51:06:33,  5.01s/batch, loss=0.0021]Training Epoch 1:   1%|          | 294/36984 [32:19<66:02:42,  6.48s/batch, loss=0.0021]Training Epoch 1:   1%|          | 295/36984 [32:19<47:48:18,  4.69s/batch, loss=0.0021]Training Epoch 1:   1%|          | 296/36984 [32:31<68:23:01,  6.71s/batch, loss=0.0021]Training Epoch 1:   1%|          | 297/36984 [32:31<49:00:43,  4.81s/batch, loss=0.0021]Training Epoch 1:   1%|          | 298/36984 [32:43<71:00:36,  6.97s/batch, loss=0.0021]Training Epoch 1:   1%|          | 299/36984 [32:43<50:36:40,  4.97s/batch, loss=0.0021]Training Epoch 1:   1%|          | 300/36984 [32:53<66:36:10,  6.54s/batch, loss=0.0021]Training Epoch 1:   1%|          | 301/36984 [32:54<47:23:49,  4.65s/batch, loss=0.0021]Training Epoch 1:   1%|          | 302/36984 [33:09<80:23:26,  7.89s/batch, loss=0.0021]Training Epoch 1:   1%|          | 303/36984 [33:09<56:59:55,  5.59s/batch, loss=0.0021]Training Epoch 1:   1%|          | 304/36984 [33:21<76:14:43,  7.48s/batch, loss=0.0021]Training Epoch 1:   1%|          | 305/36984 [33:21<54:03:39,  5.31s/batch, loss=0.0021]Training Epoch 1:   1%|          | 306/36984 [33:33<74:26:56,  7.31s/batch, loss=0.0021]Training Epoch 1:   1%|          | 307/36984 [33:34<52:47:26,  5.18s/batch, loss=0.0021]Training Epoch 1:   1%|          | 308/36984 [33:53<96:00:19,  9.42s/batch, loss=0.0021]Training Epoch 1:   1%|          | 309/36984 [33:53<67:52:22,  6.66s/batch, loss=0.0021]Training Epoch 1:   1%|          | 310/36984 [34:04<80:57:51,  7.95s/batch, loss=0.0021]Training Epoch 1:   1%|          | 311/36984 [34:04<57:20:21,  5.63s/batch, loss=0.0021]Training Epoch 1:   1%|          | 312/36984 [34:14<69:40:36,  6.84s/batch, loss=0.0021]Training Epoch 1:   1%|          | 313/36984 [34:14<49:26:14,  4.85s/batch, loss=0.0021]Training Epoch 1:   1%|          | 314/36984 [34:25<65:58:12,  6.48s/batch, loss=0.0021]Training Epoch 1:   1%|          | 315/36984 [34:25<46:50:27,  4.60s/batch, loss=0.0021]Training Epoch 1:   1%|          | 316/36984 [34:36<67:38:24,  6.64s/batch, loss=0.0021]Training Epoch 1:   1%|          | 317/36984 [34:36<48:00:28,  4.71s/batch, loss=0.0021]Training Epoch 1:   1%|          | 318/36984 [34:48<69:26:17,  6.82s/batch, loss=0.0021]Training Epoch 1:   1%|          | 319/36984 [34:48<49:15:58,  4.84s/batch, loss=0.0021]Training Epoch 1:   1%|          | 319/36984 [35:02<49:15:58,  4.84s/batch, loss=0.0020]Training Epoch 1:   1%|          | 320/36984 [35:02<76:12:34,  7.48s/batch, loss=0.0020]Training Epoch 1:   1%|          | 322/36984 [35:14<68:31:00,  6.73s/batch, loss=0.0020]Training Epoch 1:   1%|          | 323/36984 [35:14<52:04:24,  5.11s/batch, loss=0.0020]Training Epoch 1:   1%|          | 324/36984 [35:24<66:11:04,  6.50s/batch, loss=0.0020]Training Epoch 1:   1%|          | 325/36984 [35:25<48:46:50,  4.79s/batch, loss=0.0020]Training Epoch 1:   1%|          | 326/36984 [35:35<65:08:34,  6.40s/batch, loss=0.0020]Training Epoch 1:   1%|          | 327/36984 [35:35<47:10:00,  4.63s/batch, loss=0.0020]Training Epoch 1:   1%|          | 328/36984 [35:46<65:07:18,  6.40s/batch, loss=0.0020]Training Epoch 1:   1%|          | 329/36984 [35:46<46:42:19,  4.59s/batch, loss=0.0020]Training Epoch 1:   1%|          | 330/36984 [35:57<64:11:40,  6.30s/batch, loss=0.0020]Training Epoch 1:   1%|          | 331/36984 [35:57<45:49:09,  4.50s/batch, loss=0.0020]Training Epoch 1:   1%|          | 332/36984 [36:08<65:15:05,  6.41s/batch, loss=0.0020]Training Epoch 1:   1%|          | 333/36984 [36:08<46:26:50,  4.56s/batch, loss=0.0020]Training Epoch 1:   1%|          | 334/36984 [36:18<62:55:44,  6.18s/batch, loss=0.0020]Training Epoch 1:   1%|          | 335/36984 [36:18<44:45:55,  4.40s/batch, loss=0.0020]Training Epoch 1:   1%|          | 336/36984 [36:28<61:33:22,  6.05s/batch, loss=0.0020]Training Epoch 1:   1%|          | 337/36984 [36:28<43:46:34,  4.30s/batch, loss=0.0020]Training Epoch 1:   1%|          | 338/36984 [36:41<69:07:49,  6.79s/batch, loss=0.0020]Training Epoch 1:   1%|          | 339/36984 [36:41<49:03:47,  4.82s/batch, loss=0.0020]Training Epoch 1:   1%|          | 340/36984 [36:51<63:59:24,  6.29s/batch, loss=0.0020]Training Epoch 1:   1%|          | 341/36984 [36:51<45:27:45,  4.47s/batch, loss=0.0020]Training Epoch 1:   1%|          | 342/36984 [37:02<63:54:32,  6.28s/batch, loss=0.0020]Training Epoch 1:   1%|          | 343/36984 [37:02<45:24:10,  4.46s/batch, loss=0.0020]Training Epoch 1:   1%|          | 344/36984 [37:15<70:47:55,  6.96s/batch, loss=0.0020]Training Epoch 1:   1%|          | 345/36984 [37:15<50:13:13,  4.93s/batch, loss=0.0020]Training Epoch 1:   1%|          | 346/36984 [37:29<77:04:36,  7.57s/batch, loss=0.0020]Training Epoch 1:   1%|          | 347/36984 [37:29<54:36:46,  5.37s/batch, loss=0.0020]Training Epoch 1:   1%|          | 348/36984 [37:43<82:32:39,  8.11s/batch, loss=0.0020]Training Epoch 1:   1%|          | 349/36984 [37:43<58:26:42,  5.74s/batch, loss=0.0020]Training Epoch 1:   1%|          | 350/36984 [37:57<82:58:29,  8.15s/batch, loss=0.0020]Training Epoch 1:   1%|          | 351/36984 [37:57<58:44:32,  5.77s/batch, loss=0.0020]Training Epoch 1:   1%|          | 351/36984 [38:12<58:44:32,  5.77s/batch, loss=0.0018]Training Epoch 1:   1%|          | 352/36984 [38:12<85:53:36,  8.44s/batch, loss=0.0018]Training Epoch 1:   1%|          | 354/36984 [38:34<96:33:03,  9.49s/batch, loss=0.0018]Training Epoch 1:   1%|          | 355/36984 [38:34<73:09:24,  7.19s/batch, loss=0.0018]Training Epoch 1:   1%|          | 356/36984 [38:48<91:44:33,  9.02s/batch, loss=0.0018]Training Epoch 1:   1%|          | 357/36984 [38:48<67:22:54,  6.62s/batch, loss=0.0018]Training Epoch 1:   1%|          | 358/36984 [39:01<85:46:55,  8.43s/batch, loss=0.0018]Training Epoch 1:   1%|          | 359/36984 [39:01<61:54:10,  6.08s/batch, loss=0.0018]Training Epoch 1:   1%|          | 360/36984 [39:17<90:21:55,  8.88s/batch, loss=0.0018]Training Epoch 1:   1%|          | 361/36984 [39:17<64:33:02,  6.35s/batch, loss=0.0018]Training Epoch 1:   1%|          | 362/36984 [39:28<77:30:46,  7.62s/batch, loss=0.0018]Training Epoch 1:   1%|          | 363/36984 [39:28<55:11:19,  5.43s/batch, loss=0.0018]Training Epoch 1:   1%|          | 364/36984 [39:42<79:49:07,  7.85s/batch, loss=0.0018]Training Epoch 1:   1%|          | 365/36984 [39:42<56:40:11,  5.57s/batch, loss=0.0018]Training Epoch 1:   1%|          | 366/36984 [39:57<83:48:33,  8.24s/batch, loss=0.0018]Training Epoch 1:   1%|          | 367/36984 [39:57<59:24:00,  5.84s/batch, loss=0.0018]Training Epoch 1:   1%|          | 368/36984 [40:08<77:12:59,  7.59s/batch, loss=0.0018]Training Epoch 1:   1%|          | 369/36984 [40:09<54:44:51,  5.38s/batch, loss=0.0018]Training Epoch 1:   1%|          | 370/36984 [40:20<72:05:05,  7.09s/batch, loss=0.0018]Training Epoch 1:   1%|          | 371/36984 [40:20<51:08:10,  5.03s/batch, loss=0.0018]Training Epoch 1:   1%|          | 372/36984 [40:34<78:42:20,  7.74s/batch, loss=0.0018]Training Epoch 1:   1%|          | 373/36984 [40:34<55:45:38,  5.48s/batch, loss=0.0018]Training Epoch 1:   1%|          | 374/36984 [40:51<91:34:06,  9.00s/batch, loss=0.0018]Training Epoch 1:   1%|          | 375/36984 [40:52<64:45:52,  6.37s/batch, loss=0.0018]Training Epoch 1:   1%|          | 376/36984 [41:02<76:51:59,  7.56s/batch, loss=0.0018]Training Epoch 1:   1%|          | 377/36984 [41:02<54:28:17,  5.36s/batch, loss=0.0018]Training Epoch 1:   1%|          | 378/36984 [41:17<84:02:40,  8.27s/batch, loss=0.0018]Training Epoch 1:   1%|          | 379/36984 [41:18<59:29:21,  5.85s/batch, loss=0.0018]Training Epoch 1:   1%|          | 380/36984 [41:29<75:24:46,  7.42s/batch, loss=0.0018]Training Epoch 1:   1%|          | 381/36984 [41:29<53:26:28,  5.26s/batch, loss=0.0018]Training Epoch 1:   1%|          | 382/36984 [41:40<71:58:56,  7.08s/batch, loss=0.0018]Training Epoch 1:   1%|          | 383/36984 [41:40<51:02:46,  5.02s/batch, loss=0.0018]Training Epoch 1:   1%|          | 383/36984 [41:52<51:02:46,  5.02s/batch, loss=0.0019]Training Epoch 1:   1%|          | 384/36984 [41:52<71:29:00,  7.03s/batch, loss=0.0019]Training Epoch 1:   1%|          | 386/36984 [42:05<69:37:03,  6.85s/batch, loss=0.0019]Training Epoch 1:   1%|          | 387/36984 [42:06<52:53:54,  5.20s/batch, loss=0.0019]Training Epoch 1:   1%|          | 388/36984 [42:17<70:03:18,  6.89s/batch, loss=0.0019]Training Epoch 1:   1%|          | 389/36984 [42:17<51:35:26,  5.08s/batch, loss=0.0019]Training Epoch 1:   1%|          | 390/36984 [42:30<72:19:38,  7.12s/batch, loss=0.0019]Training Epoch 1:   1%|          | 391/36984 [42:30<52:17:52,  5.15s/batch, loss=0.0019]Training Epoch 1:   1%|          | 392/36984 [42:43<74:13:00,  7.30s/batch, loss=0.0019]Training Epoch 1:   1%|          | 393/36984 [42:43<53:07:59,  5.23s/batch, loss=0.0019]Training Epoch 1:   1%|          | 394/36984 [42:59<86:04:25,  8.47s/batch, loss=0.0019]Training Epoch 1:   1%|          | 395/36984 [42:59<61:12:50,  6.02s/batch, loss=0.0019]Training Epoch 1:   1%|          | 396/36984 [43:13<84:02:22,  8.27s/batch, loss=0.0019]Training Epoch 1:   1%|          | 397/36984 [43:13<59:38:03,  5.87s/batch, loss=0.0019]Training Epoch 1:   1%|          | 398/36984 [43:24<75:21:41,  7.42s/batch, loss=0.0019]Training Epoch 1:   1%|          | 399/36984 [43:24<53:28:38,  5.26s/batch, loss=0.0019]Training Epoch 1:   1%|          | 400/36984 [43:35<69:03:08,  6.80s/batch, loss=0.0019]Training Epoch 1:   1%|          | 401/36984 [43:35<49:01:42,  4.82s/batch, loss=0.0019]Training Epoch 1:   1%|          | 402/36984 [43:46<67:21:41,  6.63s/batch, loss=0.0019]Training Epoch 1:   1%|          | 403/36984 [43:46<47:49:35,  4.71s/batch, loss=0.0019]Training Epoch 1:   1%|          | 404/36984 [43:58<70:56:39,  6.98s/batch, loss=0.0019]Training Epoch 1:   1%|          | 405/36984 [43:59<50:19:40,  4.95s/batch, loss=0.0019]Training Epoch 1:   1%|          | 406/36984 [44:13<79:38:53,  7.84s/batch, loss=0.0019]Training Epoch 1:   1%|          | 407/36984 [44:13<56:25:14,  5.55s/batch, loss=0.0019]Training Epoch 1:   1%|          | 408/36984 [44:25<74:46:25,  7.36s/batch, loss=0.0019]Training Epoch 1:   1%|          | 409/36984 [44:25<53:00:13,  5.22s/batch, loss=0.0019]Training Epoch 1:   1%|          | 410/36984 [44:41<86:22:35,  8.50s/batch, loss=0.0019]Training Epoch 1:   1%|          | 411/36984 [44:41<61:07:31,  6.02s/batch, loss=0.0019]Training Epoch 1:   1%|          | 412/36984 [44:52<74:56:31,  7.38s/batch, loss=0.0019]Training Epoch 1:   1%|          | 413/36984 [44:52<53:07:04,  5.23s/batch, loss=0.0019]Training Epoch 1:   1%|          | 414/36984 [45:02<67:06:10,  6.61s/batch, loss=0.0019]Training Epoch 1:   1%|          | 415/36984 [45:02<47:37:50,  4.69s/batch, loss=0.0019]Training Epoch 1:   1%|          | 415/36984 [45:13<47:37:50,  4.69s/batch, loss=0.0016]Training Epoch 1:   1%|          | 416/36984 [45:13<66:24:45,  6.54s/batch, loss=0.0016]Training Epoch 1:   1%|          | 418/36984 [45:25<62:48:15,  6.18s/batch, loss=0.0016]Training Epoch 1:   1%|          | 419/36984 [45:25<47:46:38,  4.70s/batch, loss=0.0016]Training Epoch 1:   1%|          | 420/36984 [45:38<70:40:10,  6.96s/batch, loss=0.0016]Training Epoch 1:   1%|          | 421/36984 [45:38<52:02:46,  5.12s/batch, loss=0.0016]Training Epoch 1:   1%|          | 422/36984 [45:50<70:28:54,  6.94s/batch, loss=0.0016]Training Epoch 1:   1%|          | 423/36984 [45:50<50:58:55,  5.02s/batch, loss=0.0016]Training Epoch 1:   1%|          | 424/36984 [46:04<75:43:54,  7.46s/batch, loss=0.0016]Training Epoch 1:   1%|          | 425/36984 [46:04<54:12:05,  5.34s/batch, loss=0.0016]Training Epoch 1:   1%|          | 426/36984 [46:16<73:09:52,  7.20s/batch, loss=0.0016]Training Epoch 1:   1%|          | 427/36984 [46:16<52:07:55,  5.13s/batch, loss=0.0016]Training Epoch 1:   1%|          | 428/36984 [46:28<73:06:21,  7.20s/batch, loss=0.0016]Training Epoch 1:   1%|          | 429/36984 [46:28<51:57:38,  5.12s/batch, loss=0.0016]Training Epoch 1:   1%|          | 430/36984 [46:40<72:50:28,  7.17s/batch, loss=0.0016]Training Epoch 1:   1%|          | 431/36984 [46:40<51:42:25,  5.09s/batch, loss=0.0016]Training Epoch 1:   1%|          | 432/36984 [46:51<67:32:43,  6.65s/batch, loss=0.0016]Training Epoch 1:   1%|          | 433/36984 [46:51<47:58:05,  4.72s/batch, loss=0.0016]Training Epoch 1:   1%|          | 434/36984 [47:01<65:02:01,  6.41s/batch, loss=0.0016]Training Epoch 1:   1%|          | 435/36984 [47:01<46:11:51,  4.55s/batch, loss=0.0016]Training Epoch 1:   1%|          | 436/36984 [47:12<64:04:31,  6.31s/batch, loss=0.0016]Training Epoch 1:   1%|          | 437/36984 [47:12<45:31:03,  4.48s/batch, loss=0.0016]Training Epoch 1:   1%|          | 438/36984 [47:26<74:27:18,  7.33s/batch, loss=0.0016]Training Epoch 1:   1%|          | 439/36984 [47:26<52:47:03,  5.20s/batch, loss=0.0016]Training Epoch 1:   1%|          | 440/36984 [47:37<69:04:37,  6.80s/batch, loss=0.0016]Training Epoch 1:   1%|          | 441/36984 [47:37<49:00:52,  4.83s/batch, loss=0.0016]Training Epoch 1:   1%|          | 442/36984 [47:48<66:27:21,  6.55s/batch, loss=0.0016]Training Epoch 1:   1%|          | 443/36984 [47:48<47:10:54,  4.65s/batch, loss=0.0016]Training Epoch 1:   1%|          | 444/36984 [47:58<63:13:29,  6.23s/batch, loss=0.0016]Training Epoch 1:   1%|          | 445/36984 [47:58<44:54:55,  4.43s/batch, loss=0.0016]Training Epoch 1:   1%|          | 446/36984 [48:09<64:40:05,  6.37s/batch, loss=0.0016]Training Epoch 1:   1%|          | 447/36984 [48:09<45:55:52,  4.53s/batch, loss=0.0016]Training Epoch 1:   1%|          | 447/36984 [48:20<45:55:52,  4.53s/batch, loss=0.0018]Training Epoch 1:   1%|          | 448/36984 [48:20<65:23:44,  6.44s/batch, loss=0.0018]Training Epoch 1:   1%|          | 450/36984 [48:32<62:47:44,  6.19s/batch, loss=0.0018]Training Epoch 1:   1%|          | 451/36984 [48:32<47:46:12,  4.71s/batch, loss=0.0018]Training Epoch 1:   1%|          | 452/36984 [48:44<68:35:49,  6.76s/batch, loss=0.0018]Training Epoch 1:   1%|          | 453/36984 [48:45<50:32:14,  4.98s/batch, loss=0.0018]Training Epoch 1:   1%|          | 454/36984 [48:55<67:02:20,  6.61s/batch, loss=0.0018]Training Epoch 1:   1%|          | 455/36984 [48:56<48:31:22,  4.78s/batch, loss=0.0018]Training Epoch 1:   1%|          | 456/36984 [49:06<65:27:30,  6.45s/batch, loss=0.0018]Training Epoch 1:   1%|          | 457/36984 [49:06<46:56:14,  4.63s/batch, loss=0.0018]Training Epoch 1:   1%|          | 458/36984 [49:17<65:55:31,  6.50s/batch, loss=0.0018]Training Epoch 1:   1%|          | 459/36984 [49:18<47:02:17,  4.64s/batch, loss=0.0018]Training Epoch 1:   1%|          | 460/36984 [49:30<69:31:17,  6.85s/batch, loss=0.0018]Training Epoch 1:   1%|          | 461/36984 [49:30<49:26:43,  4.87s/batch, loss=0.0018]Training Epoch 1:   1%|          | 462/36984 [49:45<78:53:20,  7.78s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 463/36984 [49:45<55:56:46,  5.51s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 464/36984 [49:55<71:13:29,  7.02s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 465/36984 [49:56<50:32:48,  4.98s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 466/36984 [50:11<82:30:05,  8.13s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 467/36984 [50:11<58:25:37,  5.76s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 468/36984 [50:25<82:05:45,  8.09s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 469/36984 [50:25<58:07:55,  5.73s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 470/36984 [50:35<70:47:52,  6.98s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 471/36984 [50:35<50:13:22,  4.95s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 472/36984 [50:51<84:17:24,  8.31s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 473/36984 [50:51<59:39:53,  5.88s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 474/36984 [51:04<78:23:29,  7.73s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 475/36984 [51:04<55:32:05,  5.48s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 476/36984 [51:23<98:21:47,  9.70s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 477/36984 [51:24<69:30:46,  6.85s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 478/36984 [51:35<82:14:43,  8.11s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 479/36984 [51:35<58:13:55,  5.74s/batch, loss=0.0018]Training Epoch 1:   1%|▏         | 479/36984 [51:46<58:13:55,  5.74s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 480/36984 [51:46<75:26:14,  7.44s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 482/36984 [51:57<66:07:02,  6.52s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 483/36984 [51:57<50:16:05,  4.96s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 484/36984 [52:10<70:01:07,  6.91s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 485/36984 [52:10<51:34:17,  5.09s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 486/36984 [52:21<68:55:37,  6.80s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 487/36984 [52:21<49:52:15,  4.92s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 488/36984 [52:32<65:20:40,  6.45s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 489/36984 [52:32<46:51:26,  4.62s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 490/36984 [52:43<65:42:58,  6.48s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 491/36984 [52:43<46:53:23,  4.63s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 492/36984 [52:56<72:17:45,  7.13s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 493/36984 [52:56<51:23:22,  5.07s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 494/36984 [53:06<66:55:03,  6.60s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 495/36984 [53:07<47:33:30,  4.69s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 496/36984 [53:17<63:52:32,  6.30s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 497/36984 [53:17<45:46:42,  4.52s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 498/36984 [53:27<62:55:46,  6.21s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 499/36984 [53:27<44:43:27,  4.41s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 500/36984 [53:38<62:20:56,  6.15s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 501/36984 [53:38<44:18:38,  4.37s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 502/36984 [53:50<67:42:05,  6.68s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 503/36984 [53:50<48:03:10,  4.74s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 504/36984 [54:01<65:22:15,  6.45s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 505/36984 [54:01<46:25:03,  4.58s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 506/36984 [54:11<64:23:26,  6.35s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 507/36984 [54:11<45:43:11,  4.51s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 508/36984 [54:23<68:17:40,  6.74s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 509/36984 [54:24<48:27:39,  4.78s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 510/36984 [54:34<64:58:12,  6.41s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 511/36984 [54:34<46:08:18,  4.55s/batch, loss=0.0016]Training Epoch 1:   1%|▏         | 511/36984 [54:45<46:08:18,  4.55s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 512/36984 [54:45<64:54:07,  6.41s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 514/36984 [54:57<64:43:10,  6.39s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 515/36984 [54:58<49:13:03,  4.86s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 516/36984 [55:08<62:30:18,  6.17s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 517/36984 [55:08<46:05:55,  4.55s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 518/36984 [55:18<60:41:58,  5.99s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 519/36984 [55:18<43:59:31,  4.34s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 520/36984 [55:28<60:53:27,  6.01s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 521/36984 [55:28<43:42:30,  4.32s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 522/36984 [55:39<62:57:52,  6.22s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 523/36984 [55:39<44:57:10,  4.44s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 524/36984 [55:50<64:24:55,  6.36s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 525/36984 [55:50<45:51:40,  4.53s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 526/36984 [56:00<63:13:23,  6.24s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 527/36984 [56:01<44:58:04,  4.44s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 528/36984 [56:14<71:02:54,  7.02s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 529/36984 [56:14<50:25:05,  4.98s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 530/36984 [56:29<81:09:08,  8.01s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 531/36984 [56:29<57:28:56,  5.68s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 532/36984 [56:47<92:46:04,  9.16s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 533/36984 [56:47<65:36:15,  6.48s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 534/36984 [56:57<78:11:04,  7.72s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 535/36984 [56:58<55:23:33,  5.47s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 536/36984 [57:08<71:17:54,  7.04s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 537/36984 [57:08<50:34:10,  4.99s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 538/36984 [57:22<75:05:17,  7.42s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 539/36984 [57:22<53:13:00,  5.26s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 540/36984 [57:33<70:41:06,  6.98s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 541/36984 [57:33<50:08:22,  4.95s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 542/36984 [57:46<73:05:49,  7.22s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 543/36984 [57:46<51:49:29,  5.12s/batch, loss=0.0013]Training Epoch 1:   1%|▏         | 543/36984 [57:57<51:49:29,  5.12s/batch, loss=0.0014]Training Epoch 1:   1%|▏         | 544/36984 [57:57<71:07:53,  7.03s/batch, loss=0.0014]Training Epoch 1:   1%|▏         | 546/36984 [58:08<63:04:00,  6.23s/batch, loss=0.0014]Training Epoch 1:   1%|▏         | 547/36984 [58:08<47:58:24,  4.74s/batch, loss=0.0014]Training Epoch 1:   1%|▏         | 548/36984 [58:19<65:08:22,  6.44s/batch, loss=0.0014]Training Epoch 1:   1%|▏         | 549/36984 [58:19<48:01:07,  4.74s/batch, loss=0.0014]Training Epoch 1:   1%|▏         | 550/36984 [58:36<80:33:16,  7.96s/batch, loss=0.0014]Training Epoch 1:   1%|▏         | 551/36984 [58:36<58:10:30,  5.75s/batch, loss=0.0014]Training Epoch 1:   1%|▏         | 552/36984 [58:46<71:02:49,  7.02s/batch, loss=0.0014]Training Epoch 1:   1%|▏         | 553/36984 [58:46<50:53:17,  5.03s/batch, loss=0.0014]Training Epoch 1:   1%|▏         | 554/36984 [58:57<67:01:38,  6.62s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 555/36984 [58:57<47:48:18,  4.72s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 556/36984 [59:08<66:05:18,  6.53s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 557/36984 [59:08<47:01:59,  4.65s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 558/36984 [59:18<64:40:38,  6.39s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 559/36984 [59:19<45:59:06,  4.54s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 560/36984 [59:29<65:01:27,  6.43s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 561/36984 [59:30<46:12:02,  4.57s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 562/36984 [59:40<62:52:15,  6.21s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 563/36984 [59:40<44:41:02,  4.42s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 564/36984 [59:50<62:53:54,  6.22s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 565/36984 [59:51<44:41:34,  4.42s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 566/36984 [1:00:02<64:42:00,  6.40s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 567/36984 [1:00:02<45:57:22,  4.54s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 568/36984 [1:00:15<70:53:00,  7.01s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 569/36984 [1:00:15<50:16:41,  4.97s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 570/36984 [1:00:27<70:42:10,  6.99s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 571/36984 [1:00:27<50:09:06,  4.96s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 572/36984 [1:00:40<74:53:54,  7.41s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 573/36984 [1:00:40<53:05:18,  5.25s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 574/36984 [1:00:51<70:54:43,  7.01s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 575/36984 [1:00:51<50:17:47,  4.97s/batch, loss=0.0014]Training Epoch 1:   2%|▏         | 575/36984 [1:01:02<50:17:47,  4.97s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 576/36984 [1:01:02<66:37:48,  6.59s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 578/36984 [1:01:18<73:30:17,  7.27s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 579/36984 [1:01:18<55:49:26,  5.52s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 580/36984 [1:01:33<81:00:24,  8.01s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 581/36984 [1:01:33<59:33:55,  5.89s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 582/36984 [1:01:51<93:38:34,  9.26s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 583/36984 [1:01:52<67:31:23,  6.68s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 584/36984 [1:02:05<88:20:34,  8.74s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 585/36984 [1:02:06<63:07:07,  6.24s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 586/36984 [1:02:21<90:21:03,  8.94s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 587/36984 [1:02:21<64:13:09,  6.35s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 588/36984 [1:02:31<75:57:15,  7.51s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 589/36984 [1:02:32<53:57:33,  5.34s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 590/36984 [1:02:44<75:48:22,  7.50s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 591/36984 [1:02:44<53:46:35,  5.32s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 592/36984 [1:02:59<80:46:28,  7.99s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 593/36984 [1:02:59<57:14:04,  5.66s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 594/36984 [1:03:10<74:15:30,  7.35s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 595/36984 [1:03:10<52:38:51,  5.21s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 596/36984 [1:03:21<70:00:39,  6.93s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 597/36984 [1:03:21<49:40:14,  4.91s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 598/36984 [1:03:34<72:01:33,  7.13s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 599/36984 [1:03:34<51:04:31,  5.05s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 600/36984 [1:03:50<85:04:33,  8.42s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 601/36984 [1:03:50<60:12:41,  5.96s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 602/36984 [1:04:01<75:28:04,  7.47s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 603/36984 [1:04:02<53:29:01,  5.29s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 604/36984 [1:04:12<67:52:35,  6.72s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 605/36984 [1:04:12<48:10:18,  4.77s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 606/36984 [1:04:23<66:10:33,  6.55s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 607/36984 [1:04:23<46:58:59,  4.65s/batch, loss=0.0013]Training Epoch 1:   2%|▏         | 607/36984 [1:04:34<46:58:59,  4.65s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 608/36984 [1:04:34<66:02:28,  6.54s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 610/36984 [1:04:45<61:14:37,  6.06s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 611/36984 [1:04:45<46:36:05,  4.61s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 612/36984 [1:04:56<62:33:29,  6.19s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 613/36984 [1:04:56<46:08:04,  4.57s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 614/36984 [1:05:07<64:40:23,  6.40s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 615/36984 [1:05:07<46:49:30,  4.63s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 616/36984 [1:05:17<62:49:10,  6.22s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 617/36984 [1:05:18<45:04:11,  4.46s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 618/36984 [1:05:31<70:59:58,  7.03s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 619/36984 [1:05:31<50:36:05,  5.01s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 620/36984 [1:05:47<83:31:51,  8.27s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 621/36984 [1:05:47<59:16:05,  5.87s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 622/36984 [1:05:59<76:53:07,  7.61s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 623/36984 [1:05:59<54:32:40,  5.40s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 624/36984 [1:06:12<76:57:37,  7.62s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 625/36984 [1:06:12<54:33:14,  5.40s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 626/36984 [1:06:25<77:43:33,  7.70s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 627/36984 [1:06:25<55:04:38,  5.45s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 628/36984 [1:06:36<70:35:16,  6.99s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 629/36984 [1:06:36<50:03:57,  4.96s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 630/36984 [1:06:46<65:17:56,  6.47s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 631/36984 [1:06:46<46:22:00,  4.59s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 632/36984 [1:06:56<60:39:51,  6.01s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 633/36984 [1:06:56<43:06:59,  4.27s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 634/36984 [1:07:06<60:07:48,  5.96s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 635/36984 [1:07:06<42:44:49,  4.23s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 636/36984 [1:07:16<60:40:37,  6.01s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 637/36984 [1:07:16<43:07:58,  4.27s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 638/36984 [1:07:28<64:35:02,  6.40s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 639/36984 [1:07:28<45:52:04,  4.54s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 639/36984 [1:07:38<45:52:04,  4.54s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 640/36984 [1:07:38<63:54:35,  6.33s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 642/36984 [1:07:49<58:30:04,  5.80s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 643/36984 [1:07:49<44:32:14,  4.41s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 644/36984 [1:07:59<59:47:55,  5.92s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 645/36984 [1:07:59<44:07:49,  4.37s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 646/36984 [1:08:10<61:09:10,  6.06s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 647/36984 [1:08:10<44:18:59,  4.39s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 648/36984 [1:08:20<60:22:08,  5.98s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 649/36984 [1:08:20<43:20:05,  4.29s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 650/36984 [1:08:30<59:51:30,  5.93s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 651/36984 [1:08:30<42:45:49,  4.24s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 652/36984 [1:08:41<61:24:19,  6.08s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 653/36984 [1:08:41<43:44:49,  4.33s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 654/36984 [1:08:51<61:34:39,  6.10s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 655/36984 [1:08:51<43:48:51,  4.34s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 656/36984 [1:09:01<59:55:08,  5.94s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 657/36984 [1:09:01<42:37:32,  4.22s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 658/36984 [1:09:12<61:15:49,  6.07s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 659/36984 [1:09:12<43:33:15,  4.32s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 660/36984 [1:09:22<62:33:02,  6.20s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 661/36984 [1:09:23<44:26:58,  4.41s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 662/36984 [1:09:33<63:17:31,  6.27s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 663/36984 [1:09:33<44:57:56,  4.46s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 664/36984 [1:09:44<64:13:42,  6.37s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 665/36984 [1:09:45<45:37:04,  4.52s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 666/36984 [1:09:55<62:42:15,  6.22s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 667/36984 [1:09:55<44:32:59,  4.42s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 668/36984 [1:10:06<65:50:21,  6.53s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 669/36984 [1:10:07<46:44:41,  4.63s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 670/36984 [1:10:17<63:54:08,  6.33s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 671/36984 [1:10:17<45:23:15,  4.50s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 671/36984 [1:10:28<45:23:15,  4.50s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 672/36984 [1:10:28<65:51:49,  6.53s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 674/36984 [1:10:41<64:05:53,  6.36s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 675/36984 [1:10:41<48:44:55,  4.83s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 676/36984 [1:10:54<71:37:35,  7.10s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 677/36984 [1:10:55<52:44:16,  5.23s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 678/36984 [1:11:05<68:06:04,  6.75s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 679/36984 [1:11:05<49:16:15,  4.89s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 680/36984 [1:11:20<76:02:36,  7.54s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 681/36984 [1:11:20<54:25:06,  5.40s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 682/36984 [1:11:32<75:50:21,  7.52s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 683/36984 [1:11:33<54:00:36,  5.36s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 684/36984 [1:11:43<69:51:10,  6.93s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 685/36984 [1:11:43<49:40:26,  4.93s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 686/36984 [1:11:54<66:02:23,  6.55s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 687/36984 [1:11:54<46:56:30,  4.66s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 688/36984 [1:12:04<62:03:59,  6.16s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 689/36984 [1:12:04<44:07:26,  4.38s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 690/36984 [1:12:14<61:06:05,  6.06s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 691/36984 [1:12:14<43:26:25,  4.31s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 692/36984 [1:12:24<61:18:46,  6.08s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 693/36984 [1:12:25<43:34:36,  4.32s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 694/36984 [1:12:36<64:57:16,  6.44s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 695/36984 [1:12:36<46:07:44,  4.58s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 696/36984 [1:12:50<73:49:12,  7.32s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 697/36984 [1:12:50<52:19:26,  5.19s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 698/36984 [1:13:02<72:39:53,  7.21s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 699/36984 [1:13:02<51:31:02,  5.11s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 700/36984 [1:13:13<69:12:16,  6.87s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 701/36984 [1:13:13<49:05:45,  4.87s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 702/36984 [1:13:25<70:24:33,  6.99s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 703/36984 [1:13:26<49:56:37,  4.96s/batch, loss=0.0011]Training Epoch 1:   2%|▏         | 703/36984 [1:13:37<49:56:37,  4.96s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 704/36984 [1:13:37<68:59:03,  6.85s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 706/36984 [1:13:47<61:23:14,  6.09s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 707/36984 [1:13:47<46:42:39,  4.64s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 708/36984 [1:14:00<67:07:58,  6.66s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 709/36984 [1:14:00<49:27:46,  4.91s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 710/36984 [1:14:11<65:33:15,  6.51s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 711/36984 [1:14:11<47:27:20,  4.71s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 712/36984 [1:14:25<73:54:25,  7.34s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 713/36984 [1:14:25<52:54:32,  5.25s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 714/36984 [1:14:36<70:06:06,  6.96s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 715/36984 [1:14:36<49:58:15,  4.96s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 716/36984 [1:14:50<76:05:26,  7.55s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 717/36984 [1:14:50<54:02:49,  5.36s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 718/36984 [1:15:00<69:06:10,  6.86s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 719/36984 [1:15:01<49:04:58,  4.87s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 720/36984 [1:15:14<76:07:31,  7.56s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 721/36984 [1:15:15<53:58:14,  5.36s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 722/36984 [1:15:27<75:15:30,  7.47s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 723/36984 [1:15:27<53:21:04,  5.30s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 724/36984 [1:15:40<75:02:43,  7.45s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 725/36984 [1:15:40<53:11:30,  5.28s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 726/36984 [1:15:50<67:10:34,  6.67s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 727/36984 [1:15:50<47:40:57,  4.73s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 728/36984 [1:16:03<73:17:18,  7.28s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 729/36984 [1:16:04<51:57:31,  5.16s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 730/36984 [1:16:15<69:53:19,  6.94s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 731/36984 [1:16:15<49:34:34,  4.92s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 732/36984 [1:16:27<72:18:02,  7.18s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 733/36984 [1:16:28<51:15:53,  5.09s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 734/36984 [1:16:41<76:20:17,  7.58s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 735/36984 [1:16:41<54:05:28,  5.37s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 735/36984 [1:16:52<54:05:28,  5.37s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 736/36984 [1:16:52<69:45:18,  6.93s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 738/36984 [1:17:07<73:43:31,  7.32s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 739/36984 [1:17:07<55:59:01,  5.56s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 740/36984 [1:17:18<68:34:04,  6.81s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 741/36984 [1:17:18<50:30:31,  5.02s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 742/36984 [1:17:30<68:54:55,  6.85s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 743/36984 [1:17:30<49:51:20,  4.95s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 744/36984 [1:17:40<66:23:38,  6.60s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 745/36984 [1:17:41<47:35:52,  4.73s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 746/36984 [1:17:51<65:41:43,  6.53s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 747/36984 [1:17:52<46:52:13,  4.66s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 748/36984 [1:18:02<65:09:33,  6.47s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 749/36984 [1:18:03<46:22:37,  4.61s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 750/36984 [1:18:13<62:19:43,  6.19s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 751/36984 [1:18:13<44:20:00,  4.40s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 752/36984 [1:18:25<68:25:32,  6.80s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 753/36984 [1:18:25<48:34:40,  4.83s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 754/36984 [1:18:36<66:54:51,  6.65s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 755/36984 [1:18:37<47:30:21,  4.72s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 756/36984 [1:18:46<62:57:42,  6.26s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 757/36984 [1:18:47<44:44:13,  4.45s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 758/36984 [1:18:57<63:11:30,  6.28s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 759/36984 [1:18:57<44:53:23,  4.46s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 760/36984 [1:19:09<67:41:36,  6.73s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 761/36984 [1:19:10<48:02:30,  4.77s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 762/36984 [1:19:20<65:43:08,  6.53s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 763/36984 [1:19:20<46:39:47,  4.64s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 764/36984 [1:19:33<71:31:52,  7.11s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 765/36984 [1:19:34<50:43:40,  5.04s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 766/36984 [1:19:47<75:36:36,  7.52s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 767/36984 [1:19:47<53:34:23,  5.33s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 767/36984 [1:20:00<53:34:23,  5.33s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 768/36984 [1:20:00<76:30:29,  7.61s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 770/36984 [1:20:11<65:55:45,  6.55s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 771/36984 [1:20:11<50:07:11,  4.98s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 772/36984 [1:20:21<63:21:59,  6.30s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 773/36984 [1:20:21<46:43:21,  4.65s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 774/36984 [1:20:33<66:04:56,  6.57s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 775/36984 [1:20:33<47:49:56,  4.76s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 776/36984 [1:20:43<65:03:13,  6.47s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 777/36984 [1:20:44<46:38:30,  4.64s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 778/36984 [1:20:55<65:00:45,  6.46s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 779/36984 [1:20:55<46:23:14,  4.61s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 780/36984 [1:21:04<61:24:12,  6.11s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 781/36984 [1:21:05<43:44:34,  4.35s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 782/36984 [1:21:14<60:12:01,  5.99s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 783/36984 [1:21:15<42:50:29,  4.26s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 784/36984 [1:21:26<63:20:35,  6.30s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 785/36984 [1:21:26<45:01:23,  4.48s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 786/36984 [1:21:37<64:20:53,  6.40s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 787/36984 [1:21:37<45:42:40,  4.55s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 788/36984 [1:21:47<62:38:08,  6.23s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 789/36984 [1:21:47<44:30:20,  4.43s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 790/36984 [1:22:02<74:14:58,  7.39s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 791/36984 [1:22:02<52:37:43,  5.23s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 792/36984 [1:22:14<71:58:32,  7.16s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 793/36984 [1:22:14<51:02:13,  5.08s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 794/36984 [1:22:25<68:16:30,  6.79s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 795/36984 [1:22:25<48:26:54,  4.82s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 796/36984 [1:22:35<65:57:16,  6.56s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 797/36984 [1:22:36<46:49:17,  4.66s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 798/36984 [1:22:47<66:18:16,  6.60s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 799/36984 [1:22:47<47:03:54,  4.68s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 799/36984 [1:22:57<47:03:54,  4.68s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 800/36984 [1:22:57<63:58:28,  6.36s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 802/36984 [1:23:09<62:49:05,  6.25s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 803/36984 [1:23:10<47:46:57,  4.75s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 804/36984 [1:23:21<64:51:24,  6.45s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 805/36984 [1:23:21<47:48:31,  4.76s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 806/36984 [1:23:33<68:48:59,  6.85s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 807/36984 [1:23:34<49:46:34,  4.95s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 808/36984 [1:23:47<74:41:48,  7.43s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 809/36984 [1:23:47<53:27:51,  5.32s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 810/36984 [1:24:00<73:49:18,  7.35s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 811/36984 [1:24:00<52:35:14,  5.23s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 812/36984 [1:24:14<79:20:59,  7.90s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 813/36984 [1:24:14<56:47:34,  5.65s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 814/36984 [1:24:24<68:58:39,  6.87s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 815/36984 [1:24:24<48:58:54,  4.88s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 816/36984 [1:24:35<68:09:45,  6.78s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 817/36984 [1:24:36<48:23:18,  4.82s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 818/36984 [1:24:49<72:24:27,  7.21s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 819/36984 [1:24:49<51:20:52,  5.11s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 820/36984 [1:25:01<72:04:49,  7.18s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 821/36984 [1:25:01<51:07:08,  5.09s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 822/36984 [1:25:15<77:58:41,  7.76s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 823/36984 [1:25:15<55:14:23,  5.50s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 824/36984 [1:25:26<72:20:54,  7.20s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 825/36984 [1:25:27<51:17:56,  5.11s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 826/36984 [1:25:42<81:45:33,  8.14s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 827/36984 [1:25:42<57:53:10,  5.76s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 828/36984 [1:25:53<73:37:19,  7.33s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 829/36984 [1:25:53<52:11:11,  5.20s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 830/36984 [1:26:04<67:47:16,  6.75s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 831/36984 [1:26:04<48:06:07,  4.79s/batch, loss=0.0010]Training Epoch 1:   2%|▏         | 831/36984 [1:26:15<48:06:07,  4.79s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 832/36984 [1:26:15<67:11:07,  6.69s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 834/36984 [1:26:25<60:27:15,  6.02s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 835/36984 [1:26:26<46:54:33,  4.67s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 836/36984 [1:26:36<60:22:30,  6.01s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 837/36984 [1:26:36<45:55:26,  4.57s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 838/36984 [1:26:49<67:40:23,  6.74s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 839/36984 [1:26:50<51:29:20,  5.13s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 840/36984 [1:26:59<64:03:58,  6.38s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 841/36984 [1:27:01<48:53:25,  4.87s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 842/36984 [1:27:11<65:04:58,  6.48s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 843/36984 [1:27:11<46:26:05,  4.63s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 844/36984 [1:27:23<68:12:36,  6.79s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 845/36984 [1:27:23<48:31:08,  4.83s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 846/36984 [1:27:45<98:48:42,  9.84s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 847/36984 [1:27:45<69:54:09,  6.96s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 848/36984 [1:27:55<80:02:42,  7.97s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 849/36984 [1:27:56<56:43:01,  5.65s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 850/36984 [1:28:08<76:14:42,  7.60s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 851/36984 [1:28:08<54:02:14,  5.38s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 852/36984 [1:28:18<67:44:40,  6.75s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 853/36984 [1:28:18<48:04:46,  4.79s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 854/36984 [1:28:30<69:11:02,  6.89s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 855/36984 [1:28:30<49:05:07,  4.89s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 856/36984 [1:28:46<82:21:27,  8.21s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 857/36984 [1:28:46<58:18:15,  5.81s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 858/36984 [1:28:57<72:10:51,  7.19s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 859/36984 [1:28:57<51:10:43,  5.10s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 860/36984 [1:29:08<68:29:05,  6.82s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 861/36984 [1:29:08<48:35:22,  4.84s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 862/36984 [1:29:19<66:27:05,  6.62s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 863/36984 [1:29:19<47:09:59,  4.70s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 863/36984 [1:29:29<47:09:59,  4.70s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 864/36984 [1:29:29<63:21:31,  6.31s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 866/36984 [1:29:40<59:04:42,  5.89s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 867/36984 [1:29:40<44:58:14,  4.48s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 868/36984 [1:29:51<60:32:37,  6.03s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 869/36984 [1:29:51<44:39:39,  4.45s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 870/36984 [1:30:01<61:40:55,  6.15s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 871/36984 [1:30:01<44:41:14,  4.45s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 872/36984 [1:30:11<58:48:13,  5.86s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 873/36984 [1:30:11<42:13:18,  4.21s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 874/36984 [1:30:22<63:43:48,  6.35s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 875/36984 [1:30:23<45:29:02,  4.53s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 876/36984 [1:30:34<66:48:51,  6.66s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 877/36984 [1:30:35<47:32:02,  4.74s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 878/36984 [1:30:45<63:47:03,  6.36s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 879/36984 [1:30:45<45:20:47,  4.52s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 880/36984 [1:30:56<64:46:37,  6.46s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 881/36984 [1:30:56<46:01:26,  4.59s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 882/36984 [1:31:14<86:50:27,  8.66s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 883/36984 [1:31:15<61:27:23,  6.13s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 884/36984 [1:31:26<77:02:16,  7.68s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 885/36984 [1:31:26<54:35:15,  5.44s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 886/36984 [1:31:37<72:15:14,  7.21s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 887/36984 [1:31:38<51:13:54,  5.11s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 888/36984 [1:31:48<67:42:06,  6.75s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 889/36984 [1:31:48<48:02:23,  4.79s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 890/36984 [1:31:59<64:28:33,  6.43s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 891/36984 [1:31:59<45:47:06,  4.57s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 892/36984 [1:32:09<62:41:12,  6.25s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 893/36984 [1:32:09<44:31:54,  4.44s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 894/36984 [1:32:22<68:30:13,  6.83s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 895/36984 [1:32:22<48:36:14,  4.85s/batch, loss=0.0009]Training Epoch 1:   2%|▏         | 895/36984 [1:32:34<48:36:14,  4.85s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 896/36984 [1:32:34<69:42:43,  6.95s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 898/36984 [1:32:45<63:24:33,  6.33s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 899/36984 [1:32:45<48:13:35,  4.81s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 900/36984 [1:32:56<62:53:40,  6.27s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 901/36984 [1:32:56<46:22:35,  4.63s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 902/36984 [1:33:06<62:03:26,  6.19s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 903/36984 [1:33:06<44:57:08,  4.49s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 904/36984 [1:33:18<66:24:35,  6.63s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 905/36984 [1:33:18<47:36:13,  4.75s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 906/36984 [1:33:28<62:51:51,  6.27s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 907/36984 [1:33:28<44:52:36,  4.48s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 908/36984 [1:33:39<61:40:25,  6.15s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 909/36984 [1:33:39<43:55:33,  4.38s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 910/36984 [1:33:54<75:00:07,  7.48s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 911/36984 [1:33:54<53:12:41,  5.31s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 912/36984 [1:34:04<68:39:45,  6.85s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 913/36984 [1:34:04<48:44:47,  4.87s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 914/36984 [1:34:17<71:32:06,  7.14s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 915/36984 [1:34:17<50:44:26,  5.06s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 916/36984 [1:34:28<67:42:23,  6.76s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 917/36984 [1:34:28<48:03:09,  4.80s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 918/36984 [1:34:39<65:44:56,  6.56s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 919/36984 [1:34:39<46:40:56,  4.66s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 920/36984 [1:34:50<65:19:20,  6.52s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 921/36984 [1:34:50<46:22:45,  4.63s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 922/36984 [1:35:01<64:43:33,  6.46s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 923/36984 [1:35:01<45:57:41,  4.59s/batch, loss=0.0008]Training Epoch 1:   2%|▏         | 924/36984 [1:35:13<66:41:29,  6.66s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 925/36984 [1:35:13<47:20:01,  4.73s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 926/36984 [1:35:24<68:28:01,  6.84s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 927/36984 [1:35:25<48:34:42,  4.85s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 927/36984 [1:35:36<48:34:42,  4.85s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 928/36984 [1:35:36<69:16:55,  6.92s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 930/36984 [1:35:47<61:59:02,  6.19s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 931/36984 [1:35:47<47:09:06,  4.71s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 932/36984 [1:35:59<66:22:04,  6.63s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 933/36984 [1:36:00<48:54:22,  4.88s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 934/36984 [1:36:10<63:47:21,  6.37s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 935/36984 [1:36:10<46:11:11,  4.61s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 936/36984 [1:36:20<62:27:22,  6.24s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 937/36984 [1:36:20<44:48:21,  4.47s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 938/36984 [1:36:31<61:45:22,  6.17s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 939/36984 [1:36:31<44:05:23,  4.40s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 940/36984 [1:36:41<61:45:00,  6.17s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 941/36984 [1:36:41<43:58:35,  4.39s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 942/36984 [1:36:52<63:22:28,  6.33s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 943/36984 [1:36:53<45:04:10,  4.50s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 944/36984 [1:37:03<61:39:15,  6.16s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 945/36984 [1:37:03<43:50:01,  4.38s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 946/36984 [1:37:13<60:59:40,  6.09s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 947/36984 [1:37:13<43:21:44,  4.33s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 948/36984 [1:37:24<64:07:37,  6.41s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 949/36984 [1:37:25<45:32:50,  4.55s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 950/36984 [1:37:35<63:36:28,  6.35s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 951/36984 [1:37:35<45:10:55,  4.51s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 952/36984 [1:37:46<62:38:17,  6.26s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 953/36984 [1:37:46<44:29:47,  4.45s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 954/36984 [1:37:57<65:34:22,  6.55s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 955/36984 [1:37:58<46:33:11,  4.65s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 956/36984 [1:38:08<64:25:40,  6.44s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 957/36984 [1:38:08<45:44:56,  4.57s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 958/36984 [1:38:19<63:59:16,  6.39s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 959/36984 [1:38:19<45:26:39,  4.54s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 959/36984 [1:38:30<45:26:39,  4.54s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 960/36984 [1:38:30<63:20:51,  6.33s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 962/36984 [1:38:40<56:56:10,  5.69s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 963/36984 [1:38:40<43:21:26,  4.33s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 964/36984 [1:38:50<58:14:00,  5.82s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 965/36984 [1:38:50<42:59:05,  4.30s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 966/36984 [1:39:00<58:20:11,  5.83s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 967/36984 [1:39:00<42:17:40,  4.23s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 968/36984 [1:39:10<57:53:34,  5.79s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 969/36984 [1:39:10<41:34:35,  4.16s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 970/36984 [1:39:21<60:30:32,  6.05s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 971/36984 [1:39:21<43:12:53,  4.32s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 972/36984 [1:39:37<77:52:48,  7.79s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 973/36984 [1:39:37<55:18:02,  5.53s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 974/36984 [1:39:49<75:54:09,  7.59s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 975/36984 [1:39:50<53:50:38,  5.38s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 976/36984 [1:40:02<73:38:26,  7.36s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 977/36984 [1:40:02<52:13:48,  5.22s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 978/36984 [1:40:17<83:09:04,  8.31s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 979/36984 [1:40:18<58:52:18,  5.89s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 980/36984 [1:40:28<73:57:52,  7.40s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 981/36984 [1:40:29<52:25:59,  5.24s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 982/36984 [1:40:40<70:09:31,  7.02s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 983/36984 [1:40:40<49:46:09,  4.98s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 984/36984 [1:40:51<66:31:04,  6.65s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 985/36984 [1:40:51<47:12:49,  4.72s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 986/36984 [1:41:03<68:22:56,  6.84s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 987/36984 [1:41:03<48:31:00,  4.85s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 988/36984 [1:41:13<64:22:46,  6.44s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 989/36984 [1:41:13<45:42:53,  4.57s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 990/36984 [1:41:23<62:38:37,  6.27s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 991/36984 [1:41:24<44:30:21,  4.45s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 991/36984 [1:41:34<44:30:21,  4.45s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 992/36984 [1:41:34<63:31:38,  6.35s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 994/36984 [1:41:48<65:43:13,  6.57s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 995/36984 [1:41:48<49:57:49,  5.00s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 996/36984 [1:41:58<63:34:25,  6.36s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 997/36984 [1:41:59<46:52:15,  4.69s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 998/36984 [1:42:09<63:48:23,  6.38s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 999/36984 [1:42:10<46:12:05,  4.62s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1000/36984 [1:42:21<64:27:02,  6.45s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1001/36984 [1:42:21<46:13:05,  4.62s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1002/36984 [1:42:31<63:01:35,  6.31s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1003/36984 [1:42:31<44:58:43,  4.50s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1004/36984 [1:42:41<61:35:52,  6.16s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1005/36984 [1:42:42<43:52:30,  4.39s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1006/36984 [1:42:53<64:15:17,  6.43s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1007/36984 [1:42:53<45:40:50,  4.57s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1008/36984 [1:43:03<62:39:46,  6.27s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1009/36984 [1:43:04<44:31:48,  4.46s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1010/36984 [1:43:13<60:37:37,  6.07s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1011/36984 [1:43:14<43:05:59,  4.31s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1012/36984 [1:43:23<59:14:51,  5.93s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1013/36984 [1:43:23<42:07:55,  4.22s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1014/36984 [1:43:34<61:47:05,  6.18s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1015/36984 [1:43:34<43:54:07,  4.39s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1016/36984 [1:43:49<74:50:31,  7.49s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1017/36984 [1:43:49<53:02:29,  5.31s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1018/36984 [1:44:06<86:52:32,  8.70s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1019/36984 [1:44:06<61:27:37,  6.15s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1020/36984 [1:44:17<74:59:31,  7.51s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1021/36984 [1:44:17<53:08:28,  5.32s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1022/36984 [1:44:28<69:13:19,  6.93s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1023/36984 [1:44:28<49:06:25,  4.92s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1023/36984 [1:44:41<49:06:25,  4.92s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1024/36984 [1:44:41<72:54:55,  7.30s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1026/36984 [1:44:51<63:32:07,  6.36s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1027/36984 [1:44:52<48:19:10,  4.84s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1028/36984 [1:45:02<63:40:50,  6.38s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1029/36984 [1:45:03<46:56:45,  4.70s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1030/36984 [1:45:14<65:16:36,  6.54s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1031/36984 [1:45:14<47:15:04,  4.73s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1032/36984 [1:45:27<71:25:06,  7.15s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1033/36984 [1:45:27<51:08:33,  5.12s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1034/36984 [1:45:37<65:28:48,  6.56s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1035/36984 [1:45:38<46:42:45,  4.68s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1036/36984 [1:45:47<62:16:52,  6.24s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1037/36984 [1:45:48<44:21:17,  4.44s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1038/36984 [1:45:58<62:56:27,  6.30s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1039/36984 [1:45:59<44:45:41,  4.48s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1040/36984 [1:46:09<61:59:03,  6.21s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1041/36984 [1:46:09<44:03:51,  4.41s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1042/36984 [1:46:23<73:50:50,  7.40s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1043/36984 [1:46:24<52:21:11,  5.24s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1044/36984 [1:46:34<67:24:16,  6.75s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1045/36984 [1:46:34<47:50:16,  4.79s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1046/36984 [1:46:45<64:48:09,  6.49s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1047/36984 [1:46:45<46:00:39,  4.61s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1048/36984 [1:46:55<63:43:54,  6.38s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1049/36984 [1:46:56<45:15:31,  4.53s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1050/36984 [1:47:06<64:21:29,  6.45s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1051/36984 [1:47:07<45:41:55,  4.58s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1052/36984 [1:47:17<63:56:38,  6.41s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1053/36984 [1:47:18<45:24:44,  4.55s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1054/36984 [1:47:30<68:44:31,  6.89s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1055/36984 [1:47:30<48:45:59,  4.89s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1055/36984 [1:47:45<48:45:59,  4.89s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1056/36984 [1:47:45<78:34:20,  7.87s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1058/36984 [1:48:01<79:19:43,  7.95s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1059/36984 [1:48:01<60:11:46,  6.03s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1060/36984 [1:48:12<71:22:14,  7.15s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1061/36984 [1:48:12<52:32:40,  5.27s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1062/36984 [1:48:23<69:35:47,  6.97s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1063/36984 [1:48:23<50:19:59,  5.04s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1064/36984 [1:48:37<73:58:18,  7.41s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1065/36984 [1:48:37<52:56:41,  5.31s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1066/36984 [1:48:51<79:55:38,  8.01s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1067/36984 [1:48:52<56:52:23,  5.70s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1068/36984 [1:49:04<76:11:59,  7.64s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1069/36984 [1:49:04<54:07:15,  5.42s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1070/36984 [1:49:15<71:39:45,  7.18s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1071/36984 [1:49:15<50:52:19,  5.10s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1072/36984 [1:49:27<70:17:22,  7.05s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1073/36984 [1:49:27<49:52:43,  5.00s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1074/36984 [1:49:44<84:43:34,  8.49s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1075/36984 [1:49:44<59:58:20,  6.01s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1076/36984 [1:50:00<90:47:46,  9.10s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1077/36984 [1:50:01<64:12:53,  6.44s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1078/36984 [1:50:11<76:31:39,  7.67s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1079/36984 [1:50:11<54:13:10,  5.44s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1080/36984 [1:50:25<78:50:16,  7.90s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1081/36984 [1:50:25<55:50:11,  5.60s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1082/36984 [1:50:36<71:18:29,  7.15s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1083/36984 [1:50:36<50:33:44,  5.07s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1084/36984 [1:50:48<71:34:07,  7.18s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1085/36984 [1:50:49<50:44:54,  5.09s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1086/36984 [1:50:59<67:16:05,  6.75s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1087/36984 [1:50:59<47:44:02,  4.79s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1087/36984 [1:51:12<47:44:02,  4.79s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1088/36984 [1:51:12<70:29:06,  7.07s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1090/36984 [1:51:22<61:03:51,  6.12s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1091/36984 [1:51:22<46:26:51,  4.66s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1092/36984 [1:51:34<64:18:31,  6.45s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1093/36984 [1:51:34<47:24:17,  4.75s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1094/36984 [1:51:48<72:44:21,  7.30s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1095/36984 [1:51:48<52:34:47,  5.27s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1096/36984 [1:52:03<80:38:48,  8.09s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1097/36984 [1:52:03<57:40:03,  5.78s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1098/36984 [1:52:14<72:37:01,  7.28s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1099/36984 [1:52:14<51:43:59,  5.19s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1100/36984 [1:52:25<66:55:41,  6.71s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1101/36984 [1:52:25<47:36:31,  4.78s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1102/36984 [1:52:35<63:11:43,  6.34s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1103/36984 [1:52:35<44:55:56,  4.51s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1104/36984 [1:52:46<65:43:51,  6.60s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1105/36984 [1:52:47<46:41:14,  4.68s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1106/36984 [1:52:58<65:40:56,  6.59s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1107/36984 [1:52:58<46:38:07,  4.68s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1108/36984 [1:53:11<71:53:25,  7.21s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1109/36984 [1:53:11<50:58:17,  5.11s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1110/36984 [1:53:25<77:20:13,  7.76s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1111/36984 [1:53:25<54:47:03,  5.50s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1112/36984 [1:53:40<80:57:20,  8.12s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1113/36984 [1:53:40<57:18:54,  5.75s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1114/36984 [1:53:50<69:33:43,  6.98s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1115/36984 [1:53:50<49:20:17,  4.95s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1116/36984 [1:54:02<71:22:36,  7.16s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1117/36984 [1:54:02<50:36:29,  5.08s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1118/36984 [1:54:13<66:11:34,  6.64s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1119/36984 [1:54:13<46:58:42,  4.72s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1119/36984 [1:54:24<46:58:42,  4.72s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1120/36984 [1:54:24<65:58:10,  6.62s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1122/36984 [1:54:35<61:08:16,  6.14s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1123/36984 [1:54:35<46:30:46,  4.67s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1124/36984 [1:54:45<60:19:36,  6.06s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1125/36984 [1:54:46<44:30:13,  4.47s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1126/36984 [1:54:56<60:08:16,  6.04s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1127/36984 [1:54:56<43:34:47,  4.38s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1128/36984 [1:55:06<59:23:13,  5.96s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1129/36984 [1:55:06<42:37:47,  4.28s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1130/36984 [1:55:16<60:44:57,  6.10s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1131/36984 [1:55:17<43:22:59,  4.36s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1132/36984 [1:55:27<61:14:12,  6.15s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1133/36984 [1:55:27<43:36:49,  4.38s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1134/36984 [1:55:37<60:54:23,  6.12s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1135/36984 [1:55:38<43:19:57,  4.35s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1136/36984 [1:55:53<76:18:46,  7.66s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1137/36984 [1:55:53<54:05:49,  5.43s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1138/36984 [1:56:05<73:05:19,  7.34s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1139/36984 [1:56:05<51:49:11,  5.20s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1140/36984 [1:56:16<68:17:38,  6.86s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1141/36984 [1:56:16<48:27:00,  4.87s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1142/36984 [1:56:27<66:32:41,  6.68s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1143/36984 [1:56:27<47:13:47,  4.74s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1144/36984 [1:56:41<74:37:11,  7.50s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1145/36984 [1:56:42<52:52:55,  5.31s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1146/36984 [1:56:52<67:10:59,  6.75s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1147/36984 [1:56:52<47:40:33,  4.79s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1148/36984 [1:57:05<73:54:50,  7.43s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1149/36984 [1:57:06<52:22:46,  5.26s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1150/36984 [1:57:18<73:26:01,  7.38s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1151/36984 [1:57:18<52:02:56,  5.23s/batch, loss=0.0008]Training Epoch 1:   3%|▎         | 1151/36984 [1:57:31<52:02:56,  5.23s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1152/36984 [1:57:31<73:57:59,  7.43s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1154/36984 [1:57:44<69:37:41,  7.00s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1155/36984 [1:57:44<52:53:41,  5.31s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1156/36984 [1:57:55<66:54:12,  6.72s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1157/36984 [1:57:55<49:17:14,  4.95s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1158/36984 [1:58:05<64:01:33,  6.43s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1159/36984 [1:58:05<46:21:26,  4.66s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1160/36984 [1:58:16<63:29:34,  6.38s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1161/36984 [1:58:16<45:32:01,  4.58s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1162/36984 [1:58:28<66:48:02,  6.71s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1163/36984 [1:58:28<47:38:13,  4.79s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1164/36984 [1:58:39<65:36:56,  6.59s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1165/36984 [1:58:39<46:41:18,  4.69s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1166/36984 [1:58:51<66:36:10,  6.69s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1167/36984 [1:58:51<47:19:32,  4.76s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1168/36984 [1:59:00<61:51:01,  6.22s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1169/36984 [1:59:01<43:57:59,  4.42s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1170/36984 [1:59:12<65:39:26,  6.60s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1171/36984 [1:59:13<46:37:05,  4.69s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1172/36984 [1:59:23<63:30:30,  6.38s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1173/36984 [1:59:23<45:06:20,  4.53s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1174/36984 [1:59:33<61:47:33,  6.21s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1175/36984 [1:59:34<43:54:07,  4.41s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1176/36984 [1:59:44<60:38:53,  6.10s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1177/36984 [1:59:44<43:06:12,  4.33s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1178/36984 [1:59:53<59:12:27,  5.95s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1179/36984 [1:59:54<42:05:41,  4.23s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1180/36984 [2:00:04<58:55:07,  5.92s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1181/36984 [2:00:04<41:53:21,  4.21s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1182/36984 [2:00:14<59:51:28,  6.02s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1183/36984 [2:00:14<42:32:53,  4.28s/batch, loss=0.0007]Training Epoch 1:   3%|▎         | 1183/36984 [2:00:28<42:32:53,  4.28s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1184/36984 [2:00:28<69:35:20,  7.00s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1186/36984 [2:00:37<60:08:50,  6.05s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1187/36984 [2:00:38<45:46:02,  4.60s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1188/36984 [2:00:48<59:32:25,  5.99s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1189/36984 [2:00:48<43:55:48,  4.42s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1190/36984 [2:01:01<67:56:44,  6.83s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1191/36984 [2:01:01<49:09:06,  4.94s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1192/36984 [2:01:11<64:12:21,  6.46s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1193/36984 [2:01:11<46:02:18,  4.63s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1194/36984 [2:01:22<62:56:33,  6.33s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1195/36984 [2:01:22<44:55:30,  4.52s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1196/36984 [2:01:33<64:04:38,  6.45s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1197/36984 [2:01:33<45:36:42,  4.59s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1198/36984 [2:01:44<62:47:01,  6.32s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1199/36984 [2:01:44<44:38:43,  4.49s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1200/36984 [2:01:55<63:23:09,  6.38s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1201/36984 [2:01:55<45:02:09,  4.53s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1202/36984 [2:02:06<63:38:44,  6.40s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1203/36984 [2:02:06<45:12:44,  4.55s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1204/36984 [2:02:16<62:20:30,  6.27s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1205/36984 [2:02:16<44:17:24,  4.46s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1206/36984 [2:02:30<70:29:07,  7.09s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1207/36984 [2:02:30<49:59:19,  5.03s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1208/36984 [2:02:41<69:05:13,  6.95s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1209/36984 [2:02:41<49:00:29,  4.93s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1210/36984 [2:02:51<63:55:45,  6.43s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1211/36984 [2:02:52<45:23:56,  4.57s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1212/36984 [2:03:02<62:36:23,  6.30s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1213/36984 [2:03:02<44:28:15,  4.48s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1214/36984 [2:03:13<61:54:55,  6.23s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1215/36984 [2:03:13<43:59:15,  4.43s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1215/36984 [2:03:23<43:59:15,  4.43s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1216/36984 [2:03:23<61:20:13,  6.17s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1218/36984 [2:03:34<58:28:04,  5.89s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1219/36984 [2:03:34<44:30:15,  4.48s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1220/36984 [2:03:45<61:30:31,  6.19s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1221/36984 [2:03:46<45:21:46,  4.57s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1222/36984 [2:04:00<71:33:05,  7.20s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1223/36984 [2:04:00<51:43:36,  5.21s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1224/36984 [2:04:13<75:47:27,  7.63s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1225/36984 [2:04:14<54:13:52,  5.46s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1226/36984 [2:04:27<76:56:47,  7.75s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1227/36984 [2:04:27<54:46:30,  5.51s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1228/36984 [2:04:41<79:16:21,  7.98s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1229/36984 [2:04:41<56:16:18,  5.67s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1230/36984 [2:04:51<70:35:14,  7.11s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1231/36984 [2:04:52<50:06:56,  5.05s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1232/36984 [2:05:04<70:41:44,  7.12s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1233/36984 [2:05:04<50:09:42,  5.05s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1234/36984 [2:05:20<84:01:36,  8.46s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1235/36984 [2:05:21<59:28:50,  5.99s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1236/36984 [2:05:33<78:35:34,  7.91s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1237/36984 [2:05:33<55:39:57,  5.61s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1238/36984 [2:05:43<69:35:08,  7.01s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1239/36984 [2:05:44<49:21:17,  4.97s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1240/36984 [2:05:56<71:13:58,  7.17s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1241/36984 [2:05:56<50:30:26,  5.09s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1242/36984 [2:06:07<66:08:52,  6.66s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1243/36984 [2:06:07<48:47:39,  4.91s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1244/36984 [2:06:17<62:46:23,  6.32s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1245/36984 [2:06:17<44:34:44,  4.49s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1246/36984 [2:06:29<65:05:47,  6.56s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1247/36984 [2:06:29<46:12:26,  4.65s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1247/36984 [2:06:41<46:12:26,  4.65s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1248/36984 [2:06:41<70:06:34,  7.06s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1250/36984 [2:06:58<76:12:33,  7.68s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1251/36984 [2:06:58<57:50:31,  5.83s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1252/36984 [2:07:09<69:44:21,  7.03s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1253/36984 [2:07:09<51:21:10,  5.17s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1254/36984 [2:07:19<64:57:52,  6.55s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1255/36984 [2:07:19<47:01:52,  4.74s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1256/36984 [2:07:31<67:49:14,  6.83s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1257/36984 [2:07:32<49:47:33,  5.02s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1258/36984 [2:07:42<63:04:58,  6.36s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1259/36984 [2:07:43<48:15:19,  4.86s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1260/36984 [2:07:57<75:11:51,  7.58s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1261/36984 [2:07:57<53:24:22,  5.38s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1262/36984 [2:08:08<69:26:07,  7.00s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1263/36984 [2:08:08<49:18:15,  4.97s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1264/36984 [2:08:22<76:25:50,  7.70s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1265/36984 [2:08:22<54:10:32,  5.46s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1266/36984 [2:08:34<73:14:36,  7.38s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1267/36984 [2:08:34<51:55:59,  5.23s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1268/36984 [2:08:47<74:46:32,  7.54s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1269/36984 [2:08:48<52:59:29,  5.34s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1270/36984 [2:08:59<69:28:42,  7.00s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1271/36984 [2:08:59<49:16:54,  4.97s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1272/36984 [2:09:11<69:39:02,  7.02s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1273/36984 [2:09:11<49:24:00,  4.98s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1274/36984 [2:09:22<67:58:57,  6.85s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1275/36984 [2:09:22<48:13:54,  4.86s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1276/36984 [2:09:35<70:33:53,  7.11s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1277/36984 [2:09:35<50:02:16,  5.04s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1278/36984 [2:09:46<69:46:34,  7.04s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1279/36984 [2:09:47<49:28:58,  4.99s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1279/36984 [2:09:57<49:28:58,  4.99s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1280/36984 [2:09:57<65:47:34,  6.63s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1282/36984 [2:10:11<67:06:53,  6.77s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1283/36984 [2:10:11<51:00:12,  5.14s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1284/36984 [2:10:29<84:00:41,  8.47s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1285/36984 [2:10:29<61:44:34,  6.23s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1286/36984 [2:10:43<82:50:19,  8.35s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1287/36984 [2:10:43<59:47:25,  6.03s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1288/36984 [2:10:55<75:22:10,  7.60s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1289/36984 [2:10:55<53:55:56,  5.44s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1290/36984 [2:11:06<70:39:36,  7.13s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1291/36984 [2:11:06<50:21:06,  5.08s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1292/36984 [2:11:18<68:18:31,  6.89s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1293/36984 [2:11:18<48:34:34,  4.90s/batch, loss=0.0006]Training Epoch 1:   3%|▎         | 1294/36984 [2:11:30<70:52:09,  7.15s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1295/36984 [2:11:30<50:18:23,  5.07s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1296/36984 [2:11:47<84:54:41,  8.57s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1297/36984 [2:11:47<60:07:02,  6.06s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1298/36984 [2:12:03<89:15:58,  9.01s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1299/36984 [2:12:03<63:08:56,  6.37s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1300/36984 [2:12:13<73:08:04,  7.38s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1301/36984 [2:12:13<51:50:36,  5.23s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1302/36984 [2:12:24<67:43:47,  6.83s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1303/36984 [2:12:24<48:03:18,  4.85s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1304/36984 [2:12:36<69:24:46,  7.00s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1305/36984 [2:12:36<49:14:13,  4.97s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1306/36984 [2:12:48<67:33:10,  6.82s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1307/36984 [2:12:48<47:55:46,  4.84s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1308/36984 [2:12:59<66:46:44,  6.74s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1309/36984 [2:12:59<47:23:10,  4.78s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1310/36984 [2:13:13<73:29:22,  7.42s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1311/36984 [2:13:13<52:05:01,  5.26s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1311/36984 [2:13:25<52:05:01,  5.26s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1312/36984 [2:13:25<72:35:13,  7.33s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1314/36984 [2:13:41<74:53:18,  7.56s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1315/36984 [2:13:41<56:51:14,  5.74s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1316/36984 [2:13:51<67:36:54,  6.82s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1317/36984 [2:13:51<49:48:25,  5.03s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1318/36984 [2:14:07<81:18:05,  8.21s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1319/36984 [2:14:08<58:41:37,  5.92s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1320/36984 [2:14:21<79:23:47,  8.01s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1321/36984 [2:14:21<56:46:57,  5.73s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1322/36984 [2:14:33<75:37:58,  7.63s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1323/36984 [2:14:33<53:50:48,  5.44s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1324/36984 [2:14:44<67:30:31,  6.82s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1325/36984 [2:14:44<48:00:45,  4.85s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1326/36984 [2:14:54<64:38:44,  6.53s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1327/36984 [2:14:54<45:56:59,  4.64s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1328/36984 [2:15:05<64:16:36,  6.49s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1329/36984 [2:15:05<45:38:58,  4.61s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1330/36984 [2:15:16<63:01:50,  6.36s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1331/36984 [2:15:16<44:46:34,  4.52s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1332/36984 [2:15:26<59:57:05,  6.05s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1333/36984 [2:15:26<42:37:01,  4.30s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1334/36984 [2:15:36<59:34:12,  6.02s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1335/36984 [2:15:36<42:20:30,  4.28s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1336/36984 [2:15:46<60:07:37,  6.07s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1337/36984 [2:15:47<42:44:09,  4.32s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1338/36984 [2:15:56<57:25:31,  5.80s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1339/36984 [2:15:56<40:50:11,  4.12s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1340/36984 [2:16:06<57:07:51,  5.77s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1341/36984 [2:16:06<40:37:58,  4.10s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1342/36984 [2:16:16<59:31:51,  6.01s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1343/36984 [2:16:17<42:18:49,  4.27s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1343/36984 [2:16:27<42:18:49,  4.27s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1344/36984 [2:16:27<59:33:13,  6.02s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1346/36984 [2:16:37<56:14:35,  5.68s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1347/36984 [2:16:38<42:49:52,  4.33s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1348/36984 [2:16:48<58:22:41,  5.90s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1349/36984 [2:16:48<43:04:37,  4.35s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1350/36984 [2:16:58<58:16:14,  5.89s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1351/36984 [2:16:58<42:14:35,  4.27s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1352/36984 [2:17:09<60:59:16,  6.16s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1353/36984 [2:17:09<43:45:41,  4.42s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1354/36984 [2:17:20<60:56:03,  6.16s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1355/36984 [2:17:20<43:30:22,  4.40s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1356/36984 [2:17:33<68:24:35,  6.91s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1357/36984 [2:17:33<48:38:48,  4.92s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1358/36984 [2:17:43<65:41:19,  6.64s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1359/36984 [2:17:44<46:41:00,  4.72s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1360/36984 [2:17:54<62:47:46,  6.35s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1361/36984 [2:17:54<44:37:36,  4.51s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1362/36984 [2:18:04<60:03:14,  6.07s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1363/36984 [2:18:04<42:41:30,  4.31s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1364/36984 [2:18:15<62:17:02,  6.29s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1365/36984 [2:18:15<44:14:52,  4.47s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1366/36984 [2:18:25<61:36:41,  6.23s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1367/36984 [2:18:26<43:46:26,  4.42s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1368/36984 [2:18:36<62:41:10,  6.34s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1369/36984 [2:18:37<44:31:19,  4.50s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1370/36984 [2:18:47<62:22:24,  6.30s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1371/36984 [2:18:47<44:18:14,  4.48s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1372/36984 [2:18:57<60:54:52,  6.16s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1373/36984 [2:18:58<43:16:58,  4.38s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1374/36984 [2:19:07<59:03:16,  5.97s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1375/36984 [2:19:08<41:58:56,  4.24s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1375/36984 [2:19:19<41:58:56,  4.24s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1376/36984 [2:19:19<61:56:13,  6.26s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1378/36984 [2:19:29<57:49:26,  5.85s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1379/36984 [2:19:30<44:01:03,  4.45s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1380/36984 [2:19:40<59:35:21,  6.03s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1381/36984 [2:19:40<43:57:47,  4.45s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1382/36984 [2:19:50<59:12:55,  5.99s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1383/36984 [2:19:50<42:54:51,  4.34s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1384/36984 [2:20:00<59:23:15,  6.01s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1385/36984 [2:20:01<42:37:27,  4.31s/batch, loss=0.0006]Training Epoch 1:   4%|▎         | 1386/36984 [2:20:13<67:00:44,  6.78s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1387/36984 [2:20:14<47:47:03,  4.83s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1388/36984 [2:20:24<65:05:47,  6.58s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1389/36984 [2:20:25<46:19:15,  4.68s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1390/36984 [2:20:35<64:32:15,  6.53s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1391/36984 [2:20:36<45:52:24,  4.64s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1392/36984 [2:20:48<70:17:36,  7.11s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1393/36984 [2:20:49<49:52:40,  5.05s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1394/36984 [2:21:02<74:46:11,  7.56s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1395/36984 [2:21:02<52:59:48,  5.36s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1396/36984 [2:21:13<69:14:34,  7.00s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1397/36984 [2:21:13<49:07:13,  4.97s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1398/36984 [2:21:26<71:16:27,  7.21s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1399/36984 [2:21:26<50:32:22,  5.11s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1400/36984 [2:21:37<68:03:35,  6.89s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1401/36984 [2:21:37<48:17:11,  4.89s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1402/36984 [2:21:49<69:32:05,  7.04s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1403/36984 [2:21:50<49:19:02,  4.99s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1404/36984 [2:22:00<65:29:47,  6.63s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1405/36984 [2:22:00<46:29:30,  4.70s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1406/36984 [2:22:11<63:28:11,  6.42s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1407/36984 [2:22:11<45:04:25,  4.56s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1407/36984 [2:22:22<45:04:25,  4.56s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1408/36984 [2:22:22<63:35:09,  6.43s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1410/36984 [2:22:32<57:52:45,  5.86s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1411/36984 [2:22:32<44:03:31,  4.46s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1412/36984 [2:22:43<59:14:18,  6.00s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1413/36984 [2:22:43<43:42:17,  4.42s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1414/36984 [2:22:53<60:51:10,  6.16s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1415/36984 [2:22:54<44:05:10,  4.46s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1416/36984 [2:23:04<60:30:31,  6.12s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1417/36984 [2:23:04<43:24:53,  4.39s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1418/36984 [2:23:15<61:10:27,  6.19s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1419/36984 [2:23:15<43:40:12,  4.42s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1420/36984 [2:23:26<62:28:27,  6.32s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1421/36984 [2:23:26<44:28:42,  4.50s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1422/36984 [2:23:35<59:30:50,  6.02s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1423/36984 [2:23:36<42:21:10,  4.29s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1424/36984 [2:23:46<60:46:59,  6.15s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1425/36984 [2:23:46<43:12:56,  4.38s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1426/36984 [2:23:57<61:25:43,  6.22s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1427/36984 [2:23:57<43:39:17,  4.42s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1428/36984 [2:24:07<60:55:59,  6.17s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1429/36984 [2:24:08<43:18:06,  4.38s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1430/36984 [2:24:18<61:57:14,  6.27s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1431/36984 [2:24:19<44:00:44,  4.46s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1432/36984 [2:24:28<60:10:33,  6.09s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1433/36984 [2:24:29<42:46:07,  4.33s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1434/36984 [2:24:39<62:06:01,  6.29s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1435/36984 [2:24:40<44:06:44,  4.47s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1436/36984 [2:24:55<75:18:53,  7.63s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1437/36984 [2:24:55<53:21:42,  5.40s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1438/36984 [2:25:05<66:34:26,  6.74s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1439/36984 [2:25:05<47:14:28,  4.78s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1439/36984 [2:25:16<47:14:28,  4.78s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1440/36984 [2:25:16<65:03:10,  6.59s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1442/36984 [2:25:31<69:12:33,  7.01s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1443/36984 [2:25:31<52:34:41,  5.33s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1444/36984 [2:25:44<71:14:41,  7.22s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1445/36984 [2:25:44<52:26:56,  5.31s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1446/36984 [2:25:55<67:42:21,  6.86s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1447/36984 [2:25:55<48:58:01,  4.96s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1448/36984 [2:26:05<64:58:34,  6.58s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1449/36984 [2:26:06<46:34:47,  4.72s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1450/36984 [2:26:20<74:03:27,  7.50s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1451/36984 [2:26:20<52:44:28,  5.34s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1452/36984 [2:26:30<66:29:01,  6.74s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1453/36984 [2:26:30<47:17:25,  4.79s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1454/36984 [2:26:41<64:17:43,  6.51s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1455/36984 [2:26:41<45:42:07,  4.63s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1456/36984 [2:26:53<67:31:03,  6.84s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1457/36984 [2:26:53<47:56:02,  4.86s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1458/36984 [2:27:05<69:23:13,  7.03s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1459/36984 [2:27:06<49:13:36,  4.99s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1460/36984 [2:27:17<68:21:27,  6.93s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1461/36984 [2:27:17<48:29:51,  4.91s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1462/36984 [2:27:28<65:46:57,  6.67s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1463/36984 [2:27:28<46:41:30,  4.73s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1464/36984 [2:27:39<64:54:34,  6.58s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1465/36984 [2:27:39<46:04:30,  4.67s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1466/36984 [2:27:53<73:15:14,  7.42s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1467/36984 [2:27:53<51:54:52,  5.26s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1468/36984 [2:28:05<69:12:28,  7.02s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1469/36984 [2:28:05<49:05:02,  4.98s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1470/36984 [2:28:20<78:38:25,  7.97s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1471/36984 [2:28:20<55:41:35,  5.65s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1471/36984 [2:28:32<55:41:35,  5.65s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1472/36984 [2:28:32<75:25:28,  7.65s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1474/36984 [2:28:44<68:10:42,  6.91s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1475/36984 [2:28:45<51:48:04,  5.25s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1476/36984 [2:28:55<64:02:07,  6.49s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1477/36984 [2:28:55<47:11:48,  4.79s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1478/36984 [2:29:06<64:12:49,  6.51s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1479/36984 [2:29:06<46:28:53,  4.71s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1480/36984 [2:29:16<61:55:44,  6.28s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1481/36984 [2:29:16<44:25:27,  4.50s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1482/36984 [2:29:26<61:03:47,  6.19s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1483/36984 [2:29:27<43:35:54,  4.42s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1484/36984 [2:29:37<60:42:36,  6.16s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1485/36984 [2:29:37<43:14:42,  4.39s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1486/36984 [2:29:48<62:34:53,  6.35s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1487/36984 [2:29:48<44:30:11,  4.51s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1488/36984 [2:30:00<65:17:55,  6.62s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1489/36984 [2:30:00<46:22:41,  4.70s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1490/36984 [2:30:10<62:15:51,  6.32s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1491/36984 [2:30:11<45:22:23,  4.60s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1492/36984 [2:30:21<61:33:04,  6.24s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1493/36984 [2:30:21<44:49:51,  4.55s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1494/36984 [2:30:34<68:29:32,  6.95s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1495/36984 [2:30:34<48:35:24,  4.93s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1496/36984 [2:30:46<69:50:45,  7.09s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1497/36984 [2:30:47<49:31:55,  5.02s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1498/36984 [2:30:57<66:08:16,  6.71s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1499/36984 [2:30:57<46:56:14,  4.76s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1500/36984 [2:31:09<67:41:00,  6.87s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1501/36984 [2:31:10<49:14:49,  5.00s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1502/36984 [2:31:22<71:02:27,  7.21s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1503/36984 [2:31:24<54:46:12,  5.56s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1503/36984 [2:31:34<54:46:12,  5.56s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1504/36984 [2:31:34<67:11:26,  6.82s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1505/36984 [2:31:35<51:29:00,  5.22s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1506/36984 [2:31:44<63:18:54,  6.42s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1507/36984 [2:31:46<48:40:00,  4.94s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1508/36984 [2:32:02<82:48:16,  8.40s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1509/36984 [2:32:03<60:31:50,  6.14s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1510/36984 [2:32:15<76:58:14,  7.81s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1511/36984 [2:32:16<57:45:04,  5.86s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1512/36984 [2:32:27<73:29:01,  7.46s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1513/36984 [2:32:29<56:39:12,  5.75s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1514/36984 [2:32:40<70:09:48,  7.12s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1515/36984 [2:32:41<54:44:26,  5.56s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1516/36984 [2:32:51<65:51:04,  6.68s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1517/36984 [2:32:52<49:50:07,  5.06s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1518/36984 [2:33:01<62:39:21,  6.36s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1519/36984 [2:33:03<49:54:04,  5.07s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1520/36984 [2:33:12<61:30:39,  6.24s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1521/36984 [2:33:14<47:31:04,  4.82s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1522/36984 [2:33:22<58:16:24,  5.92s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1523/36984 [2:33:34<75:22:05,  7.65s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1524/36984 [2:34:09<156:34:41, 15.90s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1525/36984 [2:34:12<116:44:04, 11.85s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1526/36984 [2:34:22<112:03:44, 11.38s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1527/36984 [2:34:24<84:57:54,  8.63s/batch, loss=0.0006] Training Epoch 1:   4%|▍         | 1528/36984 [2:34:38<101:51:57, 10.34s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1529/36984 [2:34:41<77:49:38,  7.90s/batch, loss=0.0006] Training Epoch 1:   4%|▍         | 1530/36984 [2:34:53<89:36:24,  9.10s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1531/36984 [2:34:54<66:31:19,  6.75s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1532/36984 [2:35:08<89:11:01,  9.06s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1533/36984 [2:35:11<69:31:34,  7.06s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1534/36984 [2:35:20<76:06:28,  7.73s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1535/36984 [2:35:22<60:03:12,  6.10s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1535/36984 [2:35:39<60:03:12,  6.10s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1536/36984 [2:35:39<90:35:49,  9.20s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1537/36984 [2:35:40<67:19:20,  6.84s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1538/36984 [2:35:53<84:46:20,  8.61s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1539/36984 [2:35:55<65:28:55,  6.65s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1540/36984 [2:36:07<81:57:59,  8.33s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1541/36984 [2:36:09<61:51:49,  6.28s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1542/36984 [2:36:21<80:52:37,  8.22s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1543/36984 [2:36:22<59:52:27,  6.08s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1544/36984 [2:36:32<71:07:02,  7.22s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1545/36984 [2:36:33<53:04:19,  5.39s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1546/36984 [2:36:44<68:03:03,  6.91s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1547/36984 [2:36:44<49:05:03,  4.99s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1548/36984 [2:36:54<62:23:57,  6.34s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1549/36984 [2:36:55<47:07:14,  4.79s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1550/36984 [2:37:04<58:39:56,  5.96s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1551/36984 [2:37:06<47:11:55,  4.80s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1552/36984 [2:37:15<58:47:05,  5.97s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1553/36984 [2:37:16<44:15:58,  4.50s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1554/36984 [2:37:26<60:26:52,  6.14s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1555/36984 [2:37:27<47:12:22,  4.80s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1556/36984 [2:37:39<67:12:23,  6.83s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1557/36984 [2:37:41<52:45:42,  5.36s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1558/36984 [2:37:50<65:34:14,  6.66s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1559/36984 [2:37:53<52:06:36,  5.30s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1560/36984 [2:38:01<62:27:20,  6.35s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1561/36984 [2:38:03<48:49:20,  4.96s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1562/36984 [2:38:16<71:49:22,  7.30s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1563/36984 [2:38:18<57:39:56,  5.86s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1564/36984 [2:38:26<64:16:30,  6.53s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1565/36984 [2:38:29<51:07:34,  5.20s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1566/36984 [2:38:38<64:41:20,  6.58s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1567/36984 [2:38:41<53:46:58,  5.47s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1567/36984 [2:38:50<53:46:58,  5.47s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1568/36984 [2:38:50<63:27:59,  6.45s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1569/36984 [2:38:52<49:34:08,  5.04s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1570/36984 [2:39:00<60:35:51,  6.16s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1571/36984 [2:39:03<48:42:48,  4.95s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1572/36984 [2:39:12<61:06:09,  6.21s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1573/36984 [2:39:13<47:02:47,  4.78s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1574/36984 [2:39:23<60:38:12,  6.16s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1575/36984 [2:39:25<50:04:09,  5.09s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1576/36984 [2:39:33<58:13:04,  5.92s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1577/36984 [2:39:39<59:18:59,  6.03s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1578/36984 [2:39:46<61:18:57,  6.23s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1579/36984 [2:39:50<53:22:50,  5.43s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1580/36984 [2:39:57<59:22:18,  6.04s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1581/36984 [2:40:00<51:11:04,  5.20s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1582/36984 [2:40:08<57:34:09,  5.85s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1583/36984 [2:40:12<51:37:49,  5.25s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1584/36984 [2:40:19<58:42:32,  5.97s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1585/36984 [2:40:23<51:59:53,  5.29s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1586/36984 [2:40:29<54:22:28,  5.53s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1587/36984 [2:40:33<51:19:46,  5.22s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1588/36984 [2:40:40<55:26:46,  5.64s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1589/36984 [2:40:44<50:34:58,  5.14s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1590/36984 [2:40:51<55:01:58,  5.60s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1591/36984 [2:40:55<51:11:59,  5.21s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1592/36984 [2:41:01<54:49:47,  5.58s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1593/36984 [2:41:05<49:33:22,  5.04s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1594/36984 [2:41:13<56:32:19,  5.75s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1595/36984 [2:41:16<50:10:22,  5.10s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1596/36984 [2:41:24<57:19:31,  5.83s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1597/36984 [2:41:27<49:24:49,  5.03s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1598/36984 [2:41:34<56:29:09,  5.75s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1599/36984 [2:41:38<49:28:43,  5.03s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1599/36984 [2:41:45<49:28:43,  5.03s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1600/36984 [2:41:45<55:41:35,  5.67s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1601/36984 [2:41:48<47:31:34,  4.84s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1602/36984 [2:41:56<56:55:18,  5.79s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1603/36984 [2:42:00<50:53:46,  5.18s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1604/36984 [2:42:07<56:26:00,  5.74s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1605/36984 [2:42:10<50:18:51,  5.12s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1606/36984 [2:42:20<63:12:25,  6.43s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1607/36984 [2:42:25<59:30:38,  6.06s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1608/36984 [2:42:35<72:40:24,  7.40s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1609/36984 [2:42:39<61:16:12,  6.24s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1610/36984 [2:42:48<68:22:38,  6.96s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1611/36984 [2:42:53<62:43:13,  6.38s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1612/36984 [2:43:01<69:46:57,  7.10s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1613/36984 [2:43:05<60:13:51,  6.13s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1614/36984 [2:43:13<65:58:14,  6.71s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1615/36984 [2:43:16<53:41:50,  5.47s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1616/36984 [2:43:24<61:18:23,  6.24s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1617/36984 [2:43:28<53:51:51,  5.48s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1618/36984 [2:43:36<61:08:58,  6.22s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1619/36984 [2:43:39<51:25:49,  5.24s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1620/36984 [2:43:46<58:31:20,  5.96s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1621/36984 [2:43:50<51:20:57,  5.23s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1622/36984 [2:43:59<62:13:12,  6.33s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1623/36984 [2:44:00<48:24:58,  4.93s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1624/36984 [2:44:09<59:27:54,  6.05s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1625/36984 [2:44:11<47:19:36,  4.82s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1626/36984 [2:44:20<60:09:04,  6.12s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1627/36984 [2:44:21<45:42:25,  4.65s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1628/36984 [2:44:32<63:09:48,  6.43s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1629/36984 [2:44:33<46:37:11,  4.75s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1630/36984 [2:44:47<74:26:01,  7.58s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1631/36984 [2:44:47<52:43:21,  5.37s/batch, loss=0.0006]Training Epoch 1:   4%|▍         | 1631/36984 [2:44:59<52:43:21,  5.37s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1632/36984 [2:44:59<72:49:04,  7.42s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1634/36984 [2:45:13<71:06:46,  7.24s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1635/36984 [2:45:14<54:52:27,  5.59s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1636/36984 [2:45:27<73:14:39,  7.46s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1637/36984 [2:45:27<53:58:33,  5.50s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1638/36984 [2:45:41<76:51:12,  7.83s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1639/36984 [2:45:41<55:30:36,  5.65s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1640/36984 [2:45:54<76:17:38,  7.77s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1641/36984 [2:45:56<59:11:19,  6.03s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1642/36984 [2:46:05<67:18:01,  6.86s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1643/36984 [2:46:07<54:34:08,  5.56s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1644/36984 [2:46:17<68:31:25,  6.98s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1645/36984 [2:46:22<61:38:49,  6.28s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1646/36984 [2:46:32<71:33:40,  7.29s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1647/36984 [2:46:37<65:56:54,  6.72s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1648/36984 [2:46:46<72:26:37,  7.38s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1649/36984 [2:46:51<65:12:54,  6.64s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1650/36984 [2:47:07<92:49:00,  9.46s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1651/36984 [2:47:11<76:05:17,  7.75s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1652/36984 [2:47:20<81:25:32,  8.30s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1653/36984 [2:47:22<63:19:01,  6.45s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1654/36984 [2:47:32<71:37:13,  7.30s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1655/36984 [2:47:33<54:44:57,  5.58s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1656/36984 [2:47:43<68:15:43,  6.96s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1657/36984 [2:47:46<54:16:17,  5.53s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1658/36984 [2:47:59<77:34:55,  7.91s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1659/36984 [2:48:02<61:55:38,  6.31s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1660/36984 [2:48:14<78:07:29,  7.96s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1661/36984 [2:48:16<62:18:18,  6.35s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1662/36984 [2:48:25<70:36:44,  7.20s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1663/36984 [2:48:28<58:35:50,  5.97s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1663/36984 [2:48:37<58:35:50,  5.97s/batch, loss=0.0005]Training Epoch 1:   4%|▍         | 1664/36984 [2:48:37<66:54:47,  6.82s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1665/36984 [2:48:39<51:46:38,  5.28s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1666/36984 [2:48:50<68:38:09,  7.00s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1667/36984 [2:48:54<59:00:02,  6.01s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1668/36984 [2:49:02<65:04:46,  6.63s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1669/36984 [2:49:04<52:06:35,  5.31s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1670/36984 [2:49:12<60:44:54,  6.19s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1671/36984 [2:49:14<48:56:29,  4.99s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1672/36984 [2:49:28<74:44:53,  7.62s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1673/36984 [2:49:29<54:57:35,  5.60s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1674/36984 [2:49:40<70:17:17,  7.17s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1675/36984 [2:49:40<51:08:58,  5.22s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1676/36984 [2:49:51<67:28:01,  6.88s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1677/36984 [2:49:52<50:02:10,  5.10s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1678/36984 [2:50:03<67:13:32,  6.85s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1679/36984 [2:50:04<49:38:59,  5.06s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1680/36984 [2:50:14<64:54:03,  6.62s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1681/36984 [2:50:15<47:07:39,  4.81s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1682/36984 [2:50:28<72:09:43,  7.36s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1683/36984 [2:50:32<62:00:21,  6.32s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1684/36984 [2:50:40<67:36:24,  6.89s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1685/36984 [2:50:43<55:23:10,  5.65s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1686/36984 [2:50:52<64:52:24,  6.62s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1687/36984 [2:50:54<52:35:57,  5.36s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1688/36984 [2:51:03<61:39:09,  6.29s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1689/36984 [2:51:04<47:48:24,  4.88s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1690/36984 [2:51:18<73:46:08,  7.52s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1691/36984 [2:51:22<64:37:36,  6.59s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1692/36984 [2:51:33<76:11:45,  7.77s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1693/36984 [2:51:37<66:20:16,  6.77s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1694/36984 [2:51:47<75:11:05,  7.67s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1695/36984 [2:51:50<60:42:23,  6.19s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1695/36984 [2:51:59<60:42:23,  6.19s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1696/36984 [2:51:59<69:37:45,  7.10s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1697/36984 [2:52:03<60:05:33,  6.13s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1698/36984 [2:52:13<72:06:30,  7.36s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1699/36984 [2:52:15<56:27:48,  5.76s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1700/36984 [2:52:24<66:12:56,  6.76s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1701/36984 [2:52:26<51:58:16,  5.30s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1702/36984 [2:52:35<61:03:35,  6.23s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1703/36984 [2:52:37<49:36:11,  5.06s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1704/36984 [2:52:46<60:31:12,  6.18s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1705/36984 [2:52:48<48:06:21,  4.91s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1706/36984 [2:52:59<67:51:41,  6.93s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1707/36984 [2:53:00<50:17:15,  5.13s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1708/36984 [2:53:11<66:39:43,  6.80s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1709/36984 [2:53:11<47:17:37,  4.83s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1710/36984 [2:53:25<72:10:23,  7.37s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1711/36984 [2:53:25<51:08:41,  5.22s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1712/36984 [2:53:38<76:10:11,  7.77s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1713/36984 [2:53:39<53:57:10,  5.51s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1714/36984 [2:53:51<75:16:07,  7.68s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1715/36984 [2:53:52<54:10:47,  5.53s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1716/36984 [2:54:05<74:58:02,  7.65s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1717/36984 [2:54:05<53:06:48,  5.42s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1718/36984 [2:54:17<73:36:44,  7.51s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1719/36984 [2:54:17<52:09:45,  5.32s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1720/36984 [2:54:35<87:35:38,  8.94s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1721/36984 [2:54:35<61:57:07,  6.32s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1722/36984 [2:54:52<94:41:45,  9.67s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1723/36984 [2:54:53<66:55:20,  6.83s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1724/36984 [2:55:04<80:41:02,  8.24s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1725/36984 [2:55:04<57:06:52,  5.83s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1726/36984 [2:55:15<69:38:13,  7.11s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1727/36984 [2:55:17<56:22:26,  5.76s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1727/36984 [2:55:28<56:22:26,  5.76s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1728/36984 [2:55:28<71:49:28,  7.33s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1729/36984 [2:55:31<59:10:43,  6.04s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1730/36984 [2:55:40<67:23:00,  6.88s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1731/36984 [2:55:42<54:12:44,  5.54s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1732/36984 [2:55:56<76:54:55,  7.85s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1733/36984 [2:55:56<54:58:06,  5.61s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1734/36984 [2:56:10<80:20:24,  8.20s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1735/36984 [2:56:11<59:40:23,  6.09s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1736/36984 [2:56:25<81:57:46,  8.37s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1737/36984 [2:56:28<64:22:23,  6.57s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1738/36984 [2:56:38<76:27:51,  7.81s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1739/36984 [2:56:41<60:55:13,  6.22s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1740/36984 [2:56:49<66:14:02,  6.77s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1741/36984 [2:56:52<55:16:31,  5.65s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1742/36984 [2:56:59<60:48:42,  6.21s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1743/36984 [2:57:02<51:40:57,  5.28s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1744/36984 [2:57:10<59:14:54,  6.05s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1745/36984 [2:57:14<51:02:36,  5.21s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1746/36984 [2:57:21<58:00:02,  5.93s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1747/36984 [2:57:24<49:44:17,  5.08s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1748/36984 [2:57:32<57:58:48,  5.92s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1749/36984 [2:57:34<47:22:09,  4.84s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1750/36984 [2:57:42<55:34:16,  5.68s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1751/36984 [2:57:45<47:05:45,  4.81s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1752/36984 [2:57:52<53:16:45,  5.44s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1753/36984 [2:57:57<52:35:44,  5.37s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1754/36984 [2:58:04<56:42:49,  5.80s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1755/36984 [2:58:07<50:13:01,  5.13s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1756/36984 [2:58:15<56:33:27,  5.78s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1757/36984 [2:58:19<51:01:54,  5.22s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1758/36984 [2:58:25<55:27:07,  5.67s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1759/36984 [2:58:29<48:25:01,  4.95s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1759/36984 [2:58:35<48:25:01,  4.95s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1760/36984 [2:58:35<53:58:30,  5.52s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1761/36984 [2:58:39<47:09:35,  4.82s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1762/36984 [2:58:46<53:23:57,  5.46s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1763/36984 [2:58:49<47:57:30,  4.90s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1764/36984 [2:58:58<58:53:50,  6.02s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1765/36984 [2:59:02<52:30:01,  5.37s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1766/36984 [2:59:08<54:13:23,  5.54s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1767/36984 [2:59:12<50:48:47,  5.19s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1768/36984 [2:59:17<50:07:55,  5.12s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1769/36984 [2:59:26<61:19:18,  6.27s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1770/36984 [2:59:31<59:24:14,  6.07s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1771/36984 [2:59:41<69:55:56,  7.15s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1772/36984 [2:59:49<72:00:32,  7.36s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1773/36984 [2:59:55<68:39:46,  7.02s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1774/36984 [3:00:02<68:33:36,  7.01s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1775/36984 [3:00:11<72:38:38,  7.43s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1776/36984 [3:00:17<68:46:53,  7.03s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1777/36984 [3:00:22<64:21:12,  6.58s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1778/36984 [3:00:29<63:35:20,  6.50s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1779/36984 [3:00:35<64:20:17,  6.58s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1780/36984 [3:00:44<69:35:07,  7.12s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1781/36984 [3:00:53<75:33:25,  7.73s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1782/36984 [3:00:58<69:11:52,  7.08s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1783/36984 [3:01:03<62:26:38,  6.39s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1784/36984 [3:01:09<60:39:56,  6.20s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1785/36984 [3:01:13<55:20:30,  5.66s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1786/36984 [3:01:29<83:30:00,  8.54s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1787/36984 [3:01:34<75:31:43,  7.73s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1788/36984 [3:01:39<66:20:55,  6.79s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1789/36984 [3:01:45<62:54:03,  6.43s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1790/36984 [3:01:49<57:30:03,  5.88s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1791/36984 [3:01:57<64:09:03,  6.56s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1791/36984 [3:02:01<64:09:03,  6.56s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1792/36984 [3:02:01<56:33:16,  5.79s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1793/36984 [3:02:09<61:27:51,  6.29s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1794/36984 [3:02:13<54:53:49,  5.62s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1795/36984 [3:02:19<56:41:32,  5.80s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1796/36984 [3:02:24<54:39:38,  5.59s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1797/36984 [3:02:30<55:01:24,  5.63s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1798/36984 [3:02:34<51:32:13,  5.27s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1799/36984 [3:02:40<52:33:11,  5.38s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1800/36984 [3:02:45<50:13:23,  5.14s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1801/36984 [3:02:51<54:02:14,  5.53s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1802/36984 [3:02:55<50:46:44,  5.20s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1803/36984 [3:03:01<52:24:48,  5.36s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1804/36984 [3:03:06<49:49:49,  5.10s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1805/36984 [3:03:12<52:16:18,  5.35s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1806/36984 [3:03:16<50:16:43,  5.15s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1807/36984 [3:03:22<52:40:56,  5.39s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1808/36984 [3:03:27<50:05:11,  5.13s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1809/36984 [3:03:33<52:06:37,  5.33s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1810/36984 [3:03:37<50:02:48,  5.12s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1811/36984 [3:03:43<51:24:11,  5.26s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1812/36984 [3:03:47<49:29:59,  5.07s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1813/36984 [3:03:53<51:31:41,  5.27s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1814/36984 [3:03:57<48:27:21,  4.96s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1815/36984 [3:04:03<51:07:23,  5.23s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1816/36984 [3:04:08<49:02:51,  5.02s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1817/36984 [3:04:13<50:18:04,  5.15s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1818/36984 [3:04:18<48:38:41,  4.98s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1819/36984 [3:04:24<51:20:26,  5.26s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1820/36984 [3:04:28<49:07:52,  5.03s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1821/36984 [3:04:34<50:46:49,  5.20s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1822/36984 [3:04:39<50:31:57,  5.17s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1823/36984 [3:04:44<49:57:29,  5.12s/batch, loss=0.0006]Training Epoch 1:   5%|▍         | 1823/36984 [3:04:50<49:57:29,  5.12s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1824/36984 [3:04:50<52:01:42,  5.33s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1825/36984 [3:04:55<50:34:35,  5.18s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1826/36984 [3:04:59<48:57:03,  5.01s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1827/36984 [3:05:05<52:26:49,  5.37s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1828/36984 [3:05:11<52:38:38,  5.39s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1829/36984 [3:05:15<49:54:05,  5.11s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1830/36984 [3:05:21<52:36:11,  5.39s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1831/36984 [3:05:26<49:18:21,  5.05s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1832/36984 [3:05:32<52:08:52,  5.34s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1833/36984 [3:05:36<50:06:59,  5.13s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1834/36984 [3:05:45<59:27:00,  6.09s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1835/36984 [3:05:50<56:58:22,  5.84s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1836/36984 [3:05:55<55:19:10,  5.67s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1837/36984 [3:06:00<53:03:00,  5.43s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1838/36984 [3:06:05<52:56:42,  5.42s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1839/36984 [3:06:11<53:04:22,  5.44s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1840/36984 [3:06:16<52:58:13,  5.43s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1841/36984 [3:06:22<54:33:22,  5.59s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1842/36984 [3:06:27<51:14:35,  5.25s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1843/36984 [3:06:33<54:29:28,  5.58s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1844/36984 [3:06:37<49:28:56,  5.07s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1845/36984 [3:06:44<54:39:46,  5.60s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1846/36984 [3:06:47<47:26:24,  4.86s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1847/36984 [3:06:54<54:39:49,  5.60s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1848/36984 [3:06:58<48:35:32,  4.98s/batch, loss=0.0005]Training Epoch 1:   5%|▍         | 1849/36984 [3:07:05<55:33:34,  5.69s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1850/36984 [3:07:08<46:17:10,  4.74s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1851/36984 [3:07:15<55:26:58,  5.68s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1852/36984 [3:07:18<46:33:04,  4.77s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1853/36984 [3:07:26<56:06:38,  5.75s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1854/36984 [3:07:30<49:28:25,  5.07s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1855/36984 [3:07:37<55:55:26,  5.73s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1855/36984 [3:07:40<55:55:26,  5.73s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1856/36984 [3:07:40<49:19:53,  5.06s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1857/36984 [3:07:47<52:49:50,  5.41s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1858/36984 [3:07:51<48:46:06,  5.00s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1859/36984 [3:07:57<52:07:19,  5.34s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1860/36984 [3:08:01<48:23:11,  4.96s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1861/36984 [3:08:07<51:50:23,  5.31s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1862/36984 [3:08:11<48:49:38,  5.00s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1863/36984 [3:08:19<56:32:07,  5.80s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1864/36984 [3:08:23<52:35:11,  5.39s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1865/36984 [3:08:29<54:26:43,  5.58s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1866/36984 [3:08:34<50:24:47,  5.17s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1867/36984 [3:08:42<59:08:32,  6.06s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1868/36984 [3:08:47<57:44:54,  5.92s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1869/36984 [3:08:52<54:46:33,  5.62s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1870/36984 [3:09:00<59:53:26,  6.14s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1871/36984 [3:09:03<53:19:17,  5.47s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1872/36984 [3:09:15<71:15:51,  7.31s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1873/36984 [3:09:19<60:17:06,  6.18s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1874/36984 [3:09:27<67:14:37,  6.89s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1875/36984 [3:09:32<62:28:06,  6.41s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1876/36984 [3:09:39<62:06:37,  6.37s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1877/36984 [3:09:42<53:58:10,  5.53s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1878/36984 [3:09:49<58:00:15,  5.95s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1879/36984 [3:09:52<48:39:11,  4.99s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1880/36984 [3:10:00<56:11:01,  5.76s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1881/36984 [3:10:02<45:34:29,  4.67s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1882/36984 [3:10:10<55:34:24,  5.70s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1883/36984 [3:10:12<46:16:26,  4.75s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1884/36984 [3:10:20<56:13:36,  5.77s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1885/36984 [3:10:22<43:32:05,  4.47s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1886/36984 [3:10:31<58:18:31,  5.98s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1887/36984 [3:10:33<45:03:44,  4.62s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1887/36984 [3:10:43<45:03:44,  4.62s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1888/36984 [3:10:43<60:11:56,  6.17s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1889/36984 [3:10:44<45:52:22,  4.71s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1890/36984 [3:10:54<60:04:31,  6.16s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1891/36984 [3:10:55<45:14:49,  4.64s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1892/36984 [3:11:03<57:12:01,  5.87s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1893/36984 [3:11:04<42:40:07,  4.38s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1894/36984 [3:11:15<60:33:51,  6.21s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1895/36984 [3:11:15<43:59:15,  4.51s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1896/36984 [3:11:26<61:59:15,  6.36s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1897/36984 [3:11:26<44:01:33,  4.52s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1898/36984 [3:11:36<60:46:54,  6.24s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1899/36984 [3:11:37<43:10:44,  4.43s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1900/36984 [3:11:46<58:31:26,  6.01s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1901/36984 [3:11:47<41:35:55,  4.27s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1902/36984 [3:11:58<62:04:14,  6.37s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1903/36984 [3:11:58<44:04:49,  4.52s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1904/36984 [3:12:08<60:55:06,  6.25s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1905/36984 [3:12:09<43:16:15,  4.44s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1906/36984 [3:12:19<60:21:23,  6.19s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1907/36984 [3:12:19<43:16:01,  4.44s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1908/36984 [3:12:31<64:05:32,  6.58s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1909/36984 [3:12:32<47:48:26,  4.91s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1910/36984 [3:12:41<61:53:50,  6.35s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1911/36984 [3:12:42<46:19:45,  4.76s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1912/36984 [3:12:51<58:18:28,  5.99s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1913/36984 [3:12:52<44:14:53,  4.54s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1914/36984 [3:13:02<57:23:37,  5.89s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1915/36984 [3:13:03<45:14:20,  4.64s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1916/36984 [3:13:12<57:14:02,  5.88s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1917/36984 [3:13:14<46:22:48,  4.76s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1918/36984 [3:13:23<57:12:11,  5.87s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1919/36984 [3:13:24<44:15:00,  4.54s/batch, loss=0.0004]Training Epoch 1:   5%|▌         | 1919/36984 [3:13:34<44:15:00,  4.54s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1920/36984 [3:13:34<59:46:19,  6.14s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1921/36984 [3:13:35<45:19:36,  4.65s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1922/36984 [3:13:45<60:25:42,  6.20s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1923/36984 [3:13:46<45:16:48,  4.65s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1924/36984 [3:13:55<58:35:37,  6.02s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1925/36984 [3:13:56<43:20:27,  4.45s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1926/36984 [3:14:05<57:56:28,  5.95s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1927/36984 [3:14:06<41:33:00,  4.27s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1928/36984 [3:14:16<58:57:15,  6.05s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1929/36984 [3:14:17<44:11:35,  4.54s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1930/36984 [3:14:26<57:54:01,  5.95s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1931/36984 [3:14:28<45:14:37,  4.65s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1932/36984 [3:14:38<62:05:33,  6.38s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1933/36984 [3:14:39<46:18:39,  4.76s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1934/36984 [3:14:48<59:15:37,  6.09s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1935/36984 [3:14:49<44:16:58,  4.55s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1936/36984 [3:14:59<58:32:46,  6.01s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1937/36984 [3:15:00<45:35:36,  4.68s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1938/36984 [3:15:10<59:04:48,  6.07s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1939/36984 [3:15:11<45:57:13,  4.72s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1940/36984 [3:15:20<58:38:19,  6.02s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1941/36984 [3:15:22<46:51:32,  4.81s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1942/36984 [3:15:31<59:22:53,  6.10s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1943/36984 [3:15:34<48:05:13,  4.94s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1944/36984 [3:15:42<57:25:21,  5.90s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1945/36984 [3:15:43<44:55:34,  4.62s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1946/36984 [3:15:52<55:19:43,  5.68s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1947/36984 [3:15:54<45:04:10,  4.63s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1948/36984 [3:16:01<53:11:23,  5.47s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1949/36984 [3:16:04<46:04:51,  4.74s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1950/36984 [3:16:11<53:19:50,  5.48s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1951/36984 [3:16:15<47:31:12,  4.88s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1951/36984 [3:16:23<47:31:12,  4.88s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1952/36984 [3:16:23<57:16:07,  5.89s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1953/36984 [3:16:26<49:50:07,  5.12s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1954/36984 [3:16:34<57:58:34,  5.96s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1955/36984 [3:16:36<46:21:34,  4.76s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1956/36984 [3:16:45<58:41:24,  6.03s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1957/36984 [3:16:46<44:24:20,  4.56s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1958/36984 [3:16:55<56:59:11,  5.86s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1959/36984 [3:16:57<43:52:34,  4.51s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1960/36984 [3:17:07<59:44:09,  6.14s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1961/36984 [3:17:07<43:57:57,  4.52s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1962/36984 [3:17:16<57:03:11,  5.86s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1963/36984 [3:17:18<44:34:21,  4.58s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1964/36984 [3:17:27<57:10:45,  5.88s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1965/36984 [3:17:28<43:03:57,  4.43s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1966/36984 [3:17:37<55:21:12,  5.69s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1967/36984 [3:17:38<42:45:39,  4.40s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1968/36984 [3:17:47<56:28:23,  5.81s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1969/36984 [3:17:48<41:27:23,  4.26s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1970/36984 [3:17:57<57:30:29,  5.91s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1971/36984 [3:17:58<42:48:11,  4.40s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1972/36984 [3:18:07<56:26:03,  5.80s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1973/36984 [3:18:09<43:31:57,  4.48s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1974/36984 [3:18:18<55:57:58,  5.75s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1975/36984 [3:18:18<41:26:54,  4.26s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1976/36984 [3:18:28<57:00:08,  5.86s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1977/36984 [3:18:29<42:39:44,  4.39s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1978/36984 [3:18:38<56:16:36,  5.79s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1979/36984 [3:18:39<42:36:19,  4.38s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1980/36984 [3:18:49<57:47:07,  5.94s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1981/36984 [3:18:52<49:28:38,  5.09s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1982/36984 [3:19:01<61:50:44,  6.36s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1983/36984 [3:19:02<47:00:37,  4.84s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1983/36984 [3:19:11<47:00:37,  4.84s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1984/36984 [3:19:11<59:03:41,  6.07s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1985/36984 [3:19:13<46:33:42,  4.79s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1986/36984 [3:19:22<59:47:51,  6.15s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1987/36984 [3:19:24<47:08:30,  4.85s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1988/36984 [3:19:33<58:30:56,  6.02s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1989/36984 [3:19:35<47:21:48,  4.87s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1990/36984 [3:19:44<57:51:20,  5.95s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1991/36984 [3:19:45<44:39:58,  4.60s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1992/36984 [3:19:54<57:46:58,  5.94s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1993/36984 [3:19:56<45:06:00,  4.64s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1994/36984 [3:20:04<56:30:15,  5.81s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1995/36984 [3:20:06<43:30:15,  4.48s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1996/36984 [3:20:15<58:11:23,  5.99s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1997/36984 [3:20:17<46:24:05,  4.77s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1998/36984 [3:20:25<56:49:59,  5.85s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 1999/36984 [3:20:27<44:17:02,  4.56s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2000/36984 [3:20:36<57:08:46,  5.88s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2001/36984 [3:20:42<57:16:01,  5.89s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2002/36984 [3:20:51<67:42:02,  6.97s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2003/36984 [3:20:54<54:13:53,  5.58s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2004/36984 [3:21:05<70:19:24,  7.24s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2005/36984 [3:21:07<54:16:56,  5.59s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2006/36984 [3:21:16<64:25:34,  6.63s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2007/36984 [3:21:18<51:18:40,  5.28s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2008/36984 [3:21:27<62:45:44,  6.46s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2009/36984 [3:21:30<51:47:06,  5.33s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2010/36984 [3:21:38<61:06:54,  6.29s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2011/36984 [3:21:40<49:17:13,  5.07s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2012/36984 [3:21:49<58:57:02,  6.07s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2013/36984 [3:21:52<50:31:45,  5.20s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2014/36984 [3:22:00<58:25:28,  6.01s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2015/36984 [3:22:03<48:58:23,  5.04s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2015/36984 [3:22:10<48:58:23,  5.04s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2016/36984 [3:22:10<56:20:40,  5.80s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2017/36984 [3:22:13<46:32:13,  4.79s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2018/36984 [3:22:22<58:21:09,  6.01s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2019/36984 [3:22:26<53:10:24,  5.47s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2020/36984 [3:22:33<58:07:33,  5.98s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2021/36984 [3:22:37<51:45:51,  5.33s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2022/36984 [3:22:46<64:19:36,  6.62s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2023/36984 [3:22:50<56:13:11,  5.79s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2024/36984 [3:22:57<58:14:27,  6.00s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2025/36984 [3:23:01<52:28:53,  5.40s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2026/36984 [3:23:07<54:51:16,  5.65s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2027/36984 [3:23:12<52:07:28,  5.37s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2028/36984 [3:23:20<60:10:26,  6.20s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2029/36984 [3:23:26<61:04:00,  6.29s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2030/36984 [3:23:39<80:02:05,  8.24s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2031/36984 [3:23:41<60:58:10,  6.28s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2032/36984 [3:23:49<67:32:37,  6.96s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2033/36984 [3:23:52<54:08:45,  5.58s/batch, loss=0.0005]Training Epoch 1:   5%|▌         | 2034/36984 [3:24:02<67:44:25,  6.98s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2035/36984 [3:24:11<72:46:23,  7.50s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2036/36984 [3:24:18<71:22:19,  7.35s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2037/36984 [3:24:24<67:45:16,  6.98s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2038/36984 [3:24:29<63:12:39,  6.51s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2039/36984 [3:24:35<61:34:46,  6.34s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2040/36984 [3:24:41<58:44:54,  6.05s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2041/36984 [3:24:46<55:52:33,  5.76s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2042/36984 [3:24:50<53:24:08,  5.50s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2043/36984 [3:24:56<53:31:12,  5.51s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2044/36984 [3:25:03<57:53:37,  5.96s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2045/36984 [3:25:08<54:49:11,  5.65s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2046/36984 [3:25:15<59:37:13,  6.14s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2047/36984 [3:25:20<56:11:27,  5.79s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2047/36984 [3:25:29<56:11:27,  5.79s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2048/36984 [3:25:29<64:09:47,  6.61s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2049/36984 [3:25:34<60:23:11,  6.22s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2050/36984 [3:25:42<65:59:17,  6.80s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2051/36984 [3:25:46<55:44:57,  5.75s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2052/36984 [3:25:54<63:16:39,  6.52s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2053/36984 [3:25:58<56:09:29,  5.79s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2054/36984 [3:26:08<69:02:58,  7.12s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2055/36984 [3:26:13<62:41:50,  6.46s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2056/36984 [3:26:20<65:25:26,  6.74s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2057/36984 [3:26:24<57:06:27,  5.89s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2058/36984 [3:26:32<62:53:24,  6.48s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2059/36984 [3:26:36<54:07:10,  5.58s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2060/36984 [3:26:44<61:08:24,  6.30s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2061/36984 [3:26:47<51:24:31,  5.30s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2062/36984 [3:26:54<58:27:08,  6.03s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2063/36984 [3:26:57<48:41:05,  5.02s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2064/36984 [3:27:05<56:18:45,  5.81s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2065/36984 [3:27:07<45:27:24,  4.69s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2066/36984 [3:27:15<55:27:11,  5.72s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2067/36984 [3:27:17<45:43:15,  4.71s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2068/36984 [3:27:27<59:03:00,  6.09s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2069/36984 [3:27:29<49:03:49,  5.06s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2070/36984 [3:27:37<56:40:18,  5.84s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2071/36984 [3:27:39<46:32:11,  4.80s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2072/36984 [3:27:47<56:35:40,  5.84s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2073/36984 [3:27:50<46:14:17,  4.77s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2074/36984 [3:27:57<54:51:56,  5.66s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2075/36984 [3:28:00<45:20:56,  4.68s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2076/36984 [3:28:08<55:33:02,  5.73s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2077/36984 [3:28:11<47:50:39,  4.93s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2078/36984 [3:28:20<58:12:03,  6.00s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2079/36984 [3:28:22<46:21:10,  4.78s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2079/36984 [3:28:30<46:21:10,  4.78s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2080/36984 [3:28:30<57:57:37,  5.98s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2081/36984 [3:28:31<43:12:19,  4.46s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2082/36984 [3:28:41<57:17:05,  5.91s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2083/36984 [3:28:43<46:10:15,  4.76s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2084/36984 [3:28:53<62:22:30,  6.43s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2085/36984 [3:28:54<46:09:47,  4.76s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2086/36984 [3:29:03<58:49:46,  6.07s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2087/36984 [3:29:04<43:18:07,  4.47s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2088/36984 [3:29:18<71:29:26,  7.38s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2089/36984 [3:29:19<54:38:32,  5.64s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2090/36984 [3:29:34<80:59:05,  8.36s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2091/36984 [3:29:38<67:42:58,  6.99s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2092/36984 [3:29:47<74:44:48,  7.71s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2093/36984 [3:29:49<56:50:23,  5.86s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2094/36984 [3:29:59<68:42:08,  7.09s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2095/36984 [3:29:59<49:47:23,  5.14s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2096/36984 [3:30:10<66:38:06,  6.88s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2097/36984 [3:30:11<48:20:22,  4.99s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2098/36984 [3:30:20<61:35:39,  6.36s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2099/36984 [3:30:21<44:53:12,  4.63s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2100/36984 [3:30:31<59:45:48,  6.17s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2101/36984 [3:30:31<43:08:53,  4.45s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2102/36984 [3:30:41<58:05:37,  6.00s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2103/36984 [3:30:43<45:42:25,  4.72s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2104/36984 [3:30:52<59:27:19,  6.14s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2105/36984 [3:30:53<45:07:36,  4.66s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2106/36984 [3:31:02<55:46:39,  5.76s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2107/36984 [3:31:04<47:06:31,  4.86s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2108/36984 [3:31:13<58:14:14,  6.01s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2109/36984 [3:31:14<44:41:29,  4.61s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2110/36984 [3:31:24<58:02:14,  5.99s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2111/36984 [3:31:25<44:51:45,  4.63s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2111/36984 [3:31:37<44:51:45,  4.63s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2112/36984 [3:31:37<66:03:14,  6.82s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2113/36984 [3:31:38<48:59:44,  5.06s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2114/36984 [3:31:47<61:13:03,  6.32s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2115/36984 [3:31:49<47:56:46,  4.95s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2116/36984 [3:32:03<73:18:40,  7.57s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2117/36984 [3:32:04<56:30:25,  5.83s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2118/36984 [3:32:14<66:55:34,  6.91s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2119/36984 [3:32:16<53:27:07,  5.52s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2120/36984 [3:32:25<61:54:44,  6.39s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2121/36984 [3:32:27<51:46:34,  5.35s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2122/36984 [3:32:35<59:20:02,  6.13s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2123/36984 [3:32:38<48:32:39,  5.01s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2124/36984 [3:32:46<56:24:35,  5.83s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2125/36984 [3:32:49<48:17:33,  4.99s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2126/36984 [3:32:56<54:17:31,  5.61s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2127/36984 [3:32:59<46:28:38,  4.80s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2128/36984 [3:33:05<51:42:38,  5.34s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2129/36984 [3:33:09<48:30:10,  5.01s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2130/36984 [3:33:15<51:36:09,  5.33s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2131/36984 [3:33:20<47:52:28,  4.95s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2132/36984 [3:33:26<52:11:58,  5.39s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2133/36984 [3:33:31<51:21:16,  5.30s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2134/36984 [3:33:37<52:27:51,  5.42s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2135/36984 [3:33:41<50:32:01,  5.22s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2136/36984 [3:33:48<53:02:50,  5.48s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2137/36984 [3:33:51<48:01:24,  4.96s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2138/36984 [3:33:59<55:58:08,  5.78s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2139/36984 [3:34:02<48:49:08,  5.04s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2140/36984 [3:34:10<56:31:31,  5.84s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2141/36984 [3:34:14<50:42:38,  5.24s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2142/36984 [3:34:20<52:25:06,  5.42s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2143/36984 [3:34:23<47:24:02,  4.90s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2143/36984 [3:34:29<47:24:02,  4.90s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2144/36984 [3:34:29<50:30:02,  5.22s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2145/36984 [3:34:34<47:39:45,  4.93s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2146/36984 [3:34:41<53:32:42,  5.53s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2147/36984 [3:34:44<46:48:41,  4.84s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2148/36984 [3:34:51<53:30:49,  5.53s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2149/36984 [3:34:53<44:58:09,  4.65s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2150/36984 [3:35:01<52:53:55,  5.47s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2151/36984 [3:35:04<45:58:25,  4.75s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2152/36984 [3:35:12<55:39:27,  5.75s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2153/36984 [3:35:15<46:45:23,  4.83s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2154/36984 [3:35:22<54:09:46,  5.60s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2155/36984 [3:35:25<44:55:33,  4.64s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2156/36984 [3:35:33<57:19:07,  5.92s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2157/36984 [3:35:37<49:51:36,  5.15s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2158/36984 [3:35:44<56:26:55,  5.84s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2159/36984 [3:35:47<46:26:00,  4.80s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2160/36984 [3:35:54<54:48:22,  5.67s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2161/36984 [3:35:56<44:11:11,  4.57s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2162/36984 [3:36:04<54:36:36,  5.65s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2163/36984 [3:36:07<44:48:57,  4.63s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2164/36984 [3:36:14<53:08:53,  5.49s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2165/36984 [3:36:17<44:44:16,  4.63s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2166/36984 [3:36:24<52:41:21,  5.45s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2167/36984 [3:36:27<44:15:58,  4.58s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2168/36984 [3:36:36<58:08:37,  6.01s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2169/36984 [3:36:39<48:00:28,  4.96s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2170/36984 [3:36:46<54:34:33,  5.64s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2171/36984 [3:36:50<48:54:22,  5.06s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2172/36984 [3:36:57<56:14:37,  5.82s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2173/36984 [3:37:00<48:54:18,  5.06s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2174/36984 [3:37:09<58:57:32,  6.10s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2175/36984 [3:37:13<53:04:42,  5.49s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2175/36984 [3:37:20<53:04:42,  5.49s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2176/36984 [3:37:20<56:42:04,  5.86s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2177/36984 [3:37:24<53:09:28,  5.50s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2178/36984 [3:37:30<54:02:42,  5.59s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2179/36984 [3:37:35<51:54:20,  5.37s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2180/36984 [3:37:41<53:19:45,  5.52s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2181/36984 [3:37:46<53:29:41,  5.53s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2182/36984 [3:37:54<59:09:56,  6.12s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2183/36984 [3:37:57<49:17:34,  5.10s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2184/36984 [3:38:07<63:43:16,  6.59s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2185/36984 [3:38:08<48:50:30,  5.05s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2186/36984 [3:38:17<58:36:21,  6.06s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2187/36984 [3:38:18<46:10:52,  4.78s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2188/36984 [3:38:28<60:27:42,  6.26s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2189/36984 [3:38:31<49:26:36,  5.12s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2190/36984 [3:38:38<56:25:07,  5.84s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2191/36984 [3:38:40<46:01:09,  4.76s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2192/36984 [3:38:51<63:25:41,  6.56s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2193/36984 [3:38:52<48:16:51,  5.00s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2194/36984 [3:39:02<62:22:27,  6.45s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2195/36984 [3:39:03<46:41:46,  4.83s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2196/36984 [3:39:12<58:25:58,  6.05s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2197/36984 [3:39:13<42:58:35,  4.45s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2198/36984 [3:39:23<58:10:42,  6.02s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2199/36984 [3:39:23<41:21:14,  4.28s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2200/36984 [3:39:33<59:29:53,  6.16s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2201/36984 [3:39:34<42:16:24,  4.38s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2202/36984 [3:39:44<59:38:42,  6.17s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2203/36984 [3:39:44<42:22:35,  4.39s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2204/36984 [3:39:56<64:56:04,  6.72s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2205/36984 [3:39:57<46:05:14,  4.77s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2206/36984 [3:40:07<61:27:45,  6.36s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2207/36984 [3:40:07<43:38:54,  4.52s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2207/36984 [3:40:17<43:38:54,  4.52s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2208/36984 [3:40:17<61:00:20,  6.32s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2210/36984 [3:40:29<58:59:14,  6.11s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2211/36984 [3:40:29<44:52:53,  4.65s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2212/36984 [3:40:39<56:52:40,  5.89s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2213/36984 [3:40:39<41:58:46,  4.35s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2214/36984 [3:40:58<81:31:38,  8.44s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2215/36984 [3:40:58<58:50:31,  6.09s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2216/36984 [3:41:09<71:57:02,  7.45s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2217/36984 [3:41:09<51:29:47,  5.33s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2218/36984 [3:41:19<65:09:15,  6.75s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2219/36984 [3:41:20<46:27:39,  4.81s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2220/36984 [3:41:40<90:59:46,  9.42s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2221/36984 [3:41:40<64:28:54,  6.68s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2222/36984 [3:41:50<73:27:51,  7.61s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2223/36984 [3:41:50<52:06:48,  5.40s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2224/36984 [3:42:03<73:01:36,  7.56s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2225/36984 [3:42:03<51:46:37,  5.36s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2226/36984 [3:42:13<65:16:50,  6.76s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2227/36984 [3:42:13<46:19:55,  4.80s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2228/36984 [3:42:28<75:44:13,  7.84s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2229/36984 [3:42:28<53:39:11,  5.56s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2230/36984 [3:42:39<68:33:08,  7.10s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2231/36984 [3:42:39<48:36:54,  5.04s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2232/36984 [3:42:51<69:23:46,  7.19s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2233/36984 [3:42:52<49:12:20,  5.10s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2234/36984 [3:43:01<60:04:28,  6.22s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2235/36984 [3:43:01<42:40:41,  4.42s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2236/36984 [3:43:13<65:20:29,  6.77s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2237/36984 [3:43:13<46:31:11,  4.82s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2238/36984 [3:43:30<80:41:36,  8.36s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2239/36984 [3:43:30<57:06:43,  5.92s/batch, loss=0.0003]Training Epoch 1:   6%|▌         | 2239/36984 [3:43:41<57:06:43,  5.92s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2240/36984 [3:43:41<70:33:02,  7.31s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2242/36984 [3:43:50<59:26:23,  6.16s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2243/36984 [3:43:51<45:13:14,  4.69s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2244/36984 [3:44:06<73:06:22,  7.58s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2245/36984 [3:44:06<53:47:20,  5.57s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2246/36984 [3:44:17<67:57:35,  7.04s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2247/36984 [3:44:17<49:08:54,  5.09s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2248/36984 [3:44:28<63:34:16,  6.59s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2249/36984 [3:44:28<45:34:16,  4.72s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2250/36984 [3:44:41<70:17:20,  7.29s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2251/36984 [3:44:42<50:04:12,  5.19s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2252/36984 [3:44:56<76:42:51,  7.95s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2253/36984 [3:44:56<54:27:22,  5.64s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2254/36984 [3:45:09<74:21:31,  7.71s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2255/36984 [3:45:09<52:44:14,  5.47s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2256/36984 [3:45:20<68:47:34,  7.13s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2257/36984 [3:45:20<48:48:34,  5.06s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2258/36984 [3:45:33<70:32:40,  7.31s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2259/36984 [3:45:33<50:01:30,  5.19s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2260/36984 [3:45:43<63:57:35,  6.63s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2261/36984 [3:45:43<45:24:19,  4.71s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2262/36984 [3:45:58<74:54:41,  7.77s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2263/36984 [3:45:58<53:04:12,  5.50s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2264/36984 [3:46:13<79:48:57,  8.28s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2265/36984 [3:46:13<56:30:00,  5.86s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2266/36984 [3:46:23<68:19:23,  7.08s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2267/36984 [3:46:24<48:27:11,  5.02s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2268/36984 [3:46:34<63:06:32,  6.54s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2269/36984 [3:46:34<44:48:12,  4.65s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2270/36984 [3:46:47<69:23:19,  7.20s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2271/36984 [3:46:47<49:11:48,  5.10s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2271/36984 [3:47:00<49:11:48,  5.10s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2272/36984 [3:47:00<72:34:32,  7.53s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2274/36984 [3:47:13<66:38:17,  6.91s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2275/36984 [3:47:13<50:37:53,  5.25s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2276/36984 [3:47:23<63:02:03,  6.54s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2277/36984 [3:47:23<46:27:20,  4.82s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2278/36984 [3:47:34<61:09:32,  6.34s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2279/36984 [3:47:34<44:17:14,  4.59s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2280/36984 [3:47:44<59:19:05,  6.15s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2281/36984 [3:47:44<42:33:51,  4.42s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2282/36984 [3:47:54<56:54:41,  5.90s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2283/36984 [3:47:54<40:39:40,  4.22s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2284/36984 [3:48:08<69:29:07,  7.21s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2285/36984 [3:48:08<49:23:03,  5.12s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2286/36984 [3:48:33<106:08:14, 11.01s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2287/36984 [3:48:33<75:00:45,  7.78s/batch, loss=0.0005] Training Epoch 1:   6%|▌         | 2288/36984 [3:48:44<84:04:35,  8.72s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2289/36984 [3:48:44<59:30:47,  6.18s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2290/36984 [3:48:55<70:51:49,  7.35s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2291/36984 [3:48:55<50:14:43,  5.21s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2292/36984 [3:49:09<75:18:51,  7.82s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2293/36984 [3:49:09<53:21:03,  5.54s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2294/36984 [3:49:21<73:43:02,  7.65s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2295/36984 [3:49:22<52:14:00,  5.42s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2296/36984 [3:49:32<65:51:01,  6.83s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2297/36984 [3:49:32<46:43:28,  4.85s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2298/36984 [3:49:42<61:36:27,  6.39s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2299/36984 [3:49:42<43:44:52,  4.54s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2300/36984 [3:49:52<59:25:13,  6.17s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2301/36984 [3:49:52<42:13:18,  4.38s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2302/36984 [3:50:03<60:23:17,  6.27s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2303/36984 [3:50:03<42:54:04,  4.45s/batch, loss=0.0005]Training Epoch 1:   6%|▌         | 2303/36984 [3:50:15<42:54:04,  4.45s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2304/36984 [3:50:15<64:46:14,  6.72s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2306/36984 [3:50:26<59:16:25,  6.15s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2307/36984 [3:50:27<45:05:11,  4.68s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2308/36984 [3:50:40<67:16:05,  6.98s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2309/36984 [3:50:40<49:32:16,  5.14s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2310/36984 [3:50:52<67:14:43,  6.98s/batch, loss=0.0004]Training Epoch 1:   6%|▌         | 2311/36984 [3:50:52<48:38:13,  5.05s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2312/36984 [3:51:07<75:44:44,  7.86s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2313/36984 [3:51:07<54:10:43,  5.63s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2314/36984 [3:51:18<67:39:48,  7.03s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2315/36984 [3:51:18<48:13:14,  5.01s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2316/36984 [3:51:31<71:00:12,  7.37s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2317/36984 [3:51:31<50:26:57,  5.24s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2318/36984 [3:51:41<64:26:08,  6.69s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2319/36984 [3:51:41<45:47:07,  4.75s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2320/36984 [3:51:52<63:58:27,  6.64s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2321/36984 [3:51:52<45:25:47,  4.72s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2322/36984 [3:52:04<64:56:24,  6.74s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2323/36984 [3:52:04<46:05:36,  4.79s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2324/36984 [3:52:15<62:51:41,  6.53s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2325/36984 [3:52:15<44:38:03,  4.64s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2326/36984 [3:52:25<61:14:43,  6.36s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2327/36984 [3:52:26<43:29:51,  4.52s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2328/36984 [3:52:37<62:03:14,  6.45s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2329/36984 [3:52:37<44:04:01,  4.58s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2330/36984 [3:52:48<63:05:32,  6.55s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2331/36984 [3:52:48<44:47:31,  4.65s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2332/36984 [3:52:59<61:31:28,  6.39s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2333/36984 [3:52:59<43:41:17,  4.54s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2334/36984 [3:53:11<64:26:44,  6.70s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2335/36984 [3:53:11<45:44:19,  4.75s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2335/36984 [3:53:21<45:44:19,  4.75s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2336/36984 [3:53:21<61:58:18,  6.44s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2338/36984 [3:53:33<59:44:46,  6.21s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2339/36984 [3:53:33<45:26:59,  4.72s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2340/36984 [3:53:44<59:29:03,  6.18s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2341/36984 [3:53:44<43:52:24,  4.56s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2342/36984 [3:53:55<62:36:42,  6.51s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2343/36984 [3:53:55<45:19:32,  4.71s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2344/36984 [3:54:05<59:32:12,  6.19s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2345/36984 [3:54:06<42:43:01,  4.44s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2346/36984 [3:54:18<66:37:33,  6.92s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2347/36984 [3:54:19<47:29:49,  4.94s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2348/36984 [3:54:32<72:14:42,  7.51s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2349/36984 [3:54:32<51:19:11,  5.33s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2350/36984 [3:54:42<64:44:13,  6.73s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2351/36984 [3:54:43<45:59:45,  4.78s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2352/36984 [3:54:53<62:52:29,  6.54s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2353/36984 [3:54:53<44:40:00,  4.64s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2354/36984 [3:55:09<75:26:13,  7.84s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2355/36984 [3:55:09<53:26:26,  5.56s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2356/36984 [3:55:20<68:00:39,  7.07s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2357/36984 [3:55:20<48:14:24,  5.02s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2358/36984 [3:55:30<62:44:03,  6.52s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2359/36984 [3:55:30<44:32:03,  4.63s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2360/36984 [3:55:40<60:37:04,  6.30s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2361/36984 [3:55:41<43:03:21,  4.48s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2362/36984 [3:55:50<58:37:12,  6.10s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2363/36984 [3:55:51<41:39:36,  4.33s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2364/36984 [3:56:00<56:29:07,  5.87s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2365/36984 [3:56:00<40:09:36,  4.18s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2366/36984 [3:56:10<56:20:14,  5.86s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2367/36984 [3:56:10<40:03:36,  4.17s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2367/36984 [3:56:21<40:03:36,  4.17s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2368/36984 [3:56:21<57:57:45,  6.03s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2370/36984 [3:56:31<53:33:43,  5.57s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2371/36984 [3:56:31<40:47:54,  4.24s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2372/36984 [3:56:41<55:03:59,  5.73s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2373/36984 [3:56:41<40:39:03,  4.23s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2374/36984 [3:56:51<55:16:29,  5.75s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2375/36984 [3:56:51<40:04:45,  4.17s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2376/36984 [3:57:01<56:32:55,  5.88s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2377/36984 [3:57:01<40:35:59,  4.22s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2378/36984 [3:57:12<60:24:12,  6.28s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2379/36984 [3:57:13<43:07:08,  4.49s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2380/36984 [3:57:22<58:13:55,  6.06s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2381/36984 [3:57:23<41:29:10,  4.32s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2382/36984 [3:57:34<62:21:53,  6.49s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2383/36984 [3:57:34<44:19:55,  4.61s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2384/36984 [3:57:45<60:29:50,  6.29s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2385/36984 [3:57:45<42:59:53,  4.47s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2386/36984 [3:57:55<58:28:18,  6.08s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2387/36984 [3:57:55<41:33:49,  4.32s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2388/36984 [3:58:05<58:22:11,  6.07s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2389/36984 [3:58:05<41:29:26,  4.32s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2390/36984 [3:58:15<57:27:58,  5.98s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2391/36984 [3:58:15<40:51:13,  4.25s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2392/36984 [3:58:26<58:16:44,  6.07s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2393/36984 [3:58:26<41:25:21,  4.31s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2394/36984 [3:58:36<58:16:56,  6.07s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2395/36984 [3:58:36<41:25:23,  4.31s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2396/36984 [3:58:49<64:37:24,  6.73s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2397/36984 [3:58:49<45:51:37,  4.77s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2398/36984 [3:59:01<66:55:45,  6.97s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2399/36984 [3:59:01<47:28:43,  4.94s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2399/36984 [3:59:15<47:28:43,  4.94s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2400/36984 [3:59:15<73:21:08,  7.64s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2402/36984 [3:59:25<62:15:54,  6.48s/batch, loss=0.0004]Training Epoch 1:   6%|▋         | 2403/36984 [3:59:26<47:20:34,  4.93s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2404/36984 [3:59:36<60:20:38,  6.28s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2405/36984 [3:59:36<44:29:44,  4.63s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2406/36984 [3:59:47<61:26:24,  6.40s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2407/36984 [3:59:47<44:29:18,  4.63s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2408/36984 [3:59:58<61:40:36,  6.42s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2409/36984 [3:59:58<44:13:47,  4.61s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2410/36984 [4:00:08<60:31:18,  6.30s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2411/36984 [4:00:09<43:11:45,  4.50s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2412/36984 [4:00:20<63:59:31,  6.66s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2413/36984 [4:00:21<45:31:41,  4.74s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2414/36984 [4:00:33<67:26:41,  7.02s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2415/36984 [4:00:33<47:53:16,  4.99s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2416/36984 [4:00:44<64:19:31,  6.70s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2417/36984 [4:00:44<45:40:21,  4.76s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2418/36984 [4:01:01<79:14:08,  8.25s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2419/36984 [4:01:01<56:06:20,  5.84s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2420/36984 [4:01:12<72:36:27,  7.56s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2421/36984 [4:01:13<51:27:22,  5.36s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2422/36984 [4:01:25<70:08:44,  7.31s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2423/36984 [4:01:25<49:43:44,  5.18s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2424/36984 [4:01:38<71:51:13,  7.48s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2425/36984 [4:01:38<50:55:19,  5.30s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2426/36984 [4:01:48<66:10:00,  6.89s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2427/36984 [4:01:49<46:56:31,  4.89s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2428/36984 [4:02:02<70:54:37,  7.39s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2429/36984 [4:02:02<50:15:40,  5.24s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2430/36984 [4:02:12<64:10:22,  6.69s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2431/36984 [4:02:12<45:32:41,  4.75s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2431/36984 [4:02:25<45:32:41,  4.75s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2432/36984 [4:02:25<66:55:45,  6.97s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2434/36984 [4:02:35<59:13:00,  6.17s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2435/36984 [4:02:35<45:03:00,  4.69s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2436/36984 [4:02:46<61:32:23,  6.41s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2437/36984 [4:02:47<45:21:54,  4.73s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2438/36984 [4:02:59<65:05:03,  6.78s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2439/36984 [4:02:59<47:05:26,  4.91s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2440/36984 [4:03:14<75:21:58,  7.85s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2441/36984 [4:03:14<53:54:47,  5.62s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2442/36984 [4:03:25<67:29:00,  7.03s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2443/36984 [4:03:25<48:05:54,  5.01s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2444/36984 [4:03:35<63:53:00,  6.66s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2445/36984 [4:03:36<45:27:02,  4.74s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2446/36984 [4:03:45<59:07:32,  6.16s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2447/36984 [4:03:45<42:03:31,  4.38s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2448/36984 [4:03:55<57:52:08,  6.03s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2449/36984 [4:03:55<41:09:08,  4.29s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2450/36984 [4:04:06<59:21:20,  6.19s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2451/36984 [4:04:06<42:11:17,  4.40s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2452/36984 [4:04:18<62:45:34,  6.54s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2453/36984 [4:04:18<44:33:39,  4.65s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2454/36984 [4:04:29<62:48:19,  6.55s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2455/36984 [4:04:29<44:35:29,  4.65s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2456/36984 [4:04:42<68:29:53,  7.14s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2457/36984 [4:04:42<48:34:27,  5.06s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2458/36984 [4:04:55<70:12:10,  7.32s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2459/36984 [4:04:55<49:45:50,  5.19s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2460/36984 [4:05:07<67:53:37,  7.08s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2461/36984 [4:05:07<48:08:55,  5.02s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2462/36984 [4:05:18<65:57:26,  6.88s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2463/36984 [4:05:18<46:46:49,  4.88s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2463/36984 [4:05:29<46:46:49,  4.88s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2464/36984 [4:05:29<62:19:27,  6.50s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2466/36984 [4:05:39<55:36:29,  5.80s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2467/36984 [4:05:39<42:20:02,  4.42s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2468/36984 [4:05:52<63:31:04,  6.62s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2469/36984 [4:05:52<46:48:17,  4.88s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2470/36984 [4:06:02<61:04:00,  6.37s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2471/36984 [4:06:02<44:13:13,  4.61s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2472/36984 [4:06:14<64:01:51,  6.68s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2473/36984 [4:06:14<45:53:33,  4.79s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2474/36984 [4:06:30<75:24:29,  7.87s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2475/36984 [4:06:30<53:40:19,  5.60s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2476/36984 [4:06:50<96:43:29, 10.09s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2477/36984 [4:06:51<68:29:48,  7.15s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2478/36984 [4:07:03<82:18:59,  8.59s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2479/36984 [4:07:03<58:18:46,  6.08s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2480/36984 [4:07:17<81:40:05,  8.52s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2481/36984 [4:07:17<57:49:17,  6.03s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2482/36984 [4:07:27<68:44:46,  7.17s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2483/36984 [4:07:27<48:45:38,  5.09s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2484/36984 [4:07:39<66:19:05,  6.92s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2485/36984 [4:07:39<47:03:19,  4.91s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2486/36984 [4:07:50<64:17:01,  6.71s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2487/36984 [4:07:50<45:37:19,  4.76s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2488/36984 [4:08:02<65:32:43,  6.84s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2489/36984 [4:08:02<46:30:29,  4.85s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2490/36984 [4:08:15<70:01:35,  7.31s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2491/36984 [4:08:15<49:38:16,  5.18s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2492/36984 [4:08:30<76:40:07,  8.00s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2493/36984 [4:08:30<54:17:33,  5.67s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2494/36984 [4:08:47<86:07:29,  8.99s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2495/36984 [4:08:47<60:54:31,  6.36s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2495/36984 [4:08:58<60:54:31,  6.36s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2496/36984 [4:08:58<75:17:16,  7.86s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2498/36984 [4:09:10<66:09:25,  6.91s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2499/36984 [4:09:10<50:16:14,  5.25s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2500/36984 [4:09:22<66:32:42,  6.95s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2501/36984 [4:09:22<49:00:31,  5.12s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2502/36984 [4:09:35<70:30:53,  7.36s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2503/36984 [4:09:35<50:58:02,  5.32s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2504/36984 [4:09:47<67:16:00,  7.02s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2505/36984 [4:09:47<48:11:02,  5.03s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2506/36984 [4:09:58<66:29:19,  6.94s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2507/36984 [4:09:58<47:23:34,  4.95s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2508/36984 [4:10:09<62:50:11,  6.56s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2509/36984 [4:10:09<44:42:59,  4.67s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2510/36984 [4:10:20<62:08:43,  6.49s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2511/36984 [4:10:20<44:10:34,  4.61s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2512/36984 [4:10:32<65:51:08,  6.88s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2513/36984 [4:10:32<46:44:37,  4.88s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2514/36984 [4:10:44<66:00:45,  6.89s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2515/36984 [4:10:44<46:50:56,  4.89s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2516/36984 [4:10:58<71:46:50,  7.50s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2517/36984 [4:10:58<50:52:18,  5.31s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2518/36984 [4:11:13<79:06:23,  8.26s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2519/36984 [4:11:13<55:59:41,  5.85s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2520/36984 [4:11:24<69:39:39,  7.28s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2521/36984 [4:11:24<49:22:55,  5.16s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2522/36984 [4:11:34<63:57:54,  6.68s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2523/36984 [4:11:35<45:23:53,  4.74s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2524/36984 [4:11:45<62:45:32,  6.56s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2525/36984 [4:11:46<44:33:02,  4.65s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2526/36984 [4:11:57<63:11:29,  6.60s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2527/36984 [4:11:57<44:51:12,  4.69s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2527/36984 [4:12:08<44:51:12,  4.69s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2528/36984 [4:12:08<61:38:10,  6.44s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2530/36984 [4:12:21<62:43:12,  6.55s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2531/36984 [4:12:21<47:41:04,  4.98s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2532/36984 [4:12:33<65:13:13,  6.82s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2533/36984 [4:12:33<48:02:38,  5.02s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2534/36984 [4:12:50<80:04:16,  8.37s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2535/36984 [4:12:51<57:47:44,  6.04s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2536/36984 [4:13:02<73:54:18,  7.72s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2537/36984 [4:13:03<52:52:18,  5.53s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2538/36984 [4:13:12<63:56:05,  6.68s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2539/36984 [4:13:12<45:35:23,  4.76s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2540/36984 [4:13:24<65:22:15,  6.83s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2541/36984 [4:13:24<46:29:35,  4.86s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2542/36984 [4:13:34<61:53:47,  6.47s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2543/36984 [4:13:35<44:00:06,  4.60s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2544/36984 [4:13:46<64:09:13,  6.71s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2545/36984 [4:13:47<45:33:32,  4.76s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2546/36984 [4:13:57<62:43:14,  6.56s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2547/36984 [4:13:58<44:32:13,  4.66s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2548/36984 [4:14:08<61:48:18,  6.46s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2549/36984 [4:14:08<43:53:23,  4.59s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2550/36984 [4:14:18<58:49:12,  6.15s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2551/36984 [4:14:18<41:47:44,  4.37s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2552/36984 [4:14:32<68:09:41,  7.13s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2553/36984 [4:14:32<48:20:18,  5.05s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2554/36984 [4:14:43<66:10:31,  6.92s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2555/36984 [4:14:44<46:56:50,  4.91s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2556/36984 [4:14:54<61:46:47,  6.46s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2557/36984 [4:14:54<43:52:00,  4.59s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2558/36984 [4:15:10<76:42:14,  8.02s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2559/36984 [4:15:10<54:18:48,  5.68s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2559/36984 [4:15:21<54:18:48,  5.68s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2560/36984 [4:15:21<68:55:27,  7.21s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2562/36984 [4:15:31<59:48:32,  6.26s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2563/36984 [4:15:31<45:29:35,  4.76s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2564/36984 [4:15:45<66:34:00,  6.96s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2565/36984 [4:15:45<49:01:24,  5.13s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2566/36984 [4:15:59<73:30:07,  7.69s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2567/36984 [4:15:59<53:05:53,  5.55s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2568/36984 [4:16:14<77:33:43,  8.11s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2569/36984 [4:16:14<55:27:12,  5.80s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2570/36984 [4:16:24<68:42:07,  7.19s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2571/36984 [4:16:25<48:56:46,  5.12s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2572/36984 [4:16:37<68:53:33,  7.21s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2573/36984 [4:16:37<48:57:46,  5.12s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2574/36984 [4:16:48<66:13:38,  6.93s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2575/36984 [4:16:48<47:02:09,  4.92s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2576/36984 [4:16:59<62:00:41,  6.49s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2577/36984 [4:16:59<44:03:12,  4.61s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2578/36984 [4:17:09<59:47:37,  6.26s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2579/36984 [4:17:09<42:29:13,  4.45s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2580/36984 [4:17:19<59:20:12,  6.21s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2581/36984 [4:17:20<42:09:39,  4.41s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2582/36984 [4:17:29<57:18:13,  6.00s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2583/36984 [4:17:30<40:44:15,  4.26s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2584/36984 [4:17:40<57:06:08,  5.98s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2585/36984 [4:17:40<40:35:42,  4.25s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2586/36984 [4:17:50<56:40:33,  5.93s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2587/36984 [4:17:50<40:17:37,  4.22s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2588/36984 [4:18:00<56:34:21,  5.92s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2589/36984 [4:18:00<40:13:17,  4.21s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2590/36984 [4:18:10<58:04:21,  6.08s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2591/36984 [4:18:11<41:16:23,  4.32s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2591/36984 [4:18:22<41:16:23,  4.32s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2592/36984 [4:18:22<60:14:52,  6.31s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2594/36984 [4:18:33<56:32:08,  5.92s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2595/36984 [4:18:33<43:01:57,  4.50s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2596/36984 [4:18:46<64:10:03,  6.72s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2597/36984 [4:18:46<47:16:25,  4.95s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2598/36984 [4:18:56<60:24:57,  6.33s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2599/36984 [4:18:56<43:44:58,  4.58s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2600/36984 [4:19:06<59:15:53,  6.21s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2601/36984 [4:19:06<42:31:12,  4.45s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2602/36984 [4:19:16<57:37:43,  6.03s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2603/36984 [4:19:16<41:09:28,  4.31s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2604/36984 [4:19:28<62:37:59,  6.56s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2605/36984 [4:19:29<44:34:14,  4.67s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2606/36984 [4:19:39<60:07:48,  6.30s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2607/36984 [4:19:39<42:45:39,  4.48s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2608/36984 [4:19:49<59:41:41,  6.25s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2609/36984 [4:19:49<42:25:41,  4.44s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2610/36984 [4:19:59<57:45:35,  6.05s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2611/36984 [4:19:59<41:03:39,  4.30s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2612/36984 [4:20:10<57:52:24,  6.06s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2613/36984 [4:20:10<41:08:10,  4.31s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2614/36984 [4:20:30<87:41:11,  9.18s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2615/36984 [4:20:31<62:00:25,  6.49s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2616/36984 [4:20:41<72:13:11,  7.56s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2617/36984 [4:20:41<51:10:29,  5.36s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2618/36984 [4:20:55<76:47:43,  8.04s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2619/36984 [4:20:55<54:22:15,  5.70s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2620/36984 [4:21:10<81:02:31,  8.49s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2621/36984 [4:21:11<57:20:51,  6.01s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2622/36984 [4:21:23<74:03:15,  7.76s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2623/36984 [4:21:23<52:27:31,  5.50s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2623/36984 [4:21:35<52:27:31,  5.50s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2624/36984 [4:21:35<71:29:16,  7.49s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2626/36984 [4:21:44<59:12:03,  6.20s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2627/36984 [4:21:45<45:02:01,  4.72s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2628/36984 [4:21:56<62:19:49,  6.53s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2629/36984 [4:21:56<45:56:21,  4.81s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2630/36984 [4:22:07<60:10:29,  6.31s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2631/36984 [4:22:07<43:34:49,  4.57s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2632/36984 [4:22:16<57:38:18,  6.04s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2633/36984 [4:22:17<41:22:05,  4.34s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2634/36984 [4:22:27<58:06:03,  6.09s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2635/36984 [4:22:27<41:29:41,  4.35s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2636/36984 [4:22:37<58:18:06,  6.11s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2637/36984 [4:22:38<41:31:50,  4.35s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2638/36984 [4:22:48<58:26:42,  6.13s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2639/36984 [4:22:48<41:34:53,  4.36s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2640/36984 [4:23:00<62:32:39,  6.56s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2641/36984 [4:23:00<44:25:47,  4.66s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2642/36984 [4:23:11<62:46:56,  6.58s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2643/36984 [4:23:11<44:34:46,  4.67s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2644/36984 [4:23:22<60:34:50,  6.35s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2645/36984 [4:23:22<43:01:54,  4.51s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2646/36984 [4:23:32<59:01:30,  6.19s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2647/36984 [4:23:32<41:56:29,  4.40s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2648/36984 [4:23:42<57:39:30,  6.05s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2649/36984 [4:23:42<40:59:07,  4.30s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2650/36984 [4:23:52<56:55:00,  5.97s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2651/36984 [4:23:52<40:27:44,  4.24s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2652/36984 [4:24:06<67:27:59,  7.07s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2653/36984 [4:24:06<47:50:33,  5.02s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2654/36984 [4:24:18<67:40:12,  7.10s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2655/36984 [4:24:18<47:59:22,  5.03s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2655/36984 [4:24:30<47:59:22,  5.03s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2656/36984 [4:24:30<67:45:10,  7.11s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2658/36984 [4:24:41<60:13:49,  6.32s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2659/36984 [4:24:41<45:48:35,  4.80s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2660/36984 [4:24:52<61:17:57,  6.43s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2661/36984 [4:24:53<45:11:11,  4.74s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2662/36984 [4:25:03<59:14:27,  6.21s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2663/36984 [4:25:03<42:54:47,  4.50s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2664/36984 [4:25:18<72:32:00,  7.61s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2665/36984 [4:25:18<51:54:01,  5.44s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2666/36984 [4:25:31<71:31:56,  7.50s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2667/36984 [4:25:31<50:56:34,  5.34s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2668/36984 [4:25:45<77:06:46,  8.09s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2669/36984 [4:25:46<54:43:34,  5.74s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2670/36984 [4:25:56<66:46:06,  7.00s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2671/36984 [4:25:56<47:24:40,  4.97s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2672/36984 [4:26:06<63:17:23,  6.64s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2673/36984 [4:26:07<44:57:05,  4.72s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2674/36984 [4:26:16<58:21:18,  6.12s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2675/36984 [4:26:16<41:28:43,  4.35s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2676/36984 [4:26:30<67:00:19,  7.03s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2677/36984 [4:26:30<47:31:32,  4.99s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2678/36984 [4:26:39<61:11:10,  6.42s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2679/36984 [4:26:40<43:27:06,  4.56s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2680/36984 [4:26:51<63:56:07,  6.71s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2681/36984 [4:26:52<45:22:29,  4.76s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2682/36984 [4:27:02<60:06:50,  6.31s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2683/36984 [4:27:02<42:41:52,  4.48s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2684/36984 [4:27:12<57:52:28,  6.07s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2685/36984 [4:27:12<41:07:35,  4.32s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2686/36984 [4:27:24<63:24:20,  6.66s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2687/36984 [4:27:24<45:00:04,  4.72s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2687/36984 [4:27:35<45:00:04,  4.72s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2688/36984 [4:27:35<61:49:23,  6.49s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2690/36984 [4:27:52<71:09:16,  7.47s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2691/36984 [4:27:52<54:01:11,  5.67s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2692/36984 [4:28:06<75:15:39,  7.90s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2693/36984 [4:28:07<55:20:53,  5.81s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2694/36984 [4:28:20<74:40:20,  7.84s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2695/36984 [4:28:20<53:56:07,  5.66s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2696/36984 [4:28:32<71:08:01,  7.47s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2697/36984 [4:28:32<50:54:40,  5.35s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2698/36984 [4:28:50<86:08:23,  9.04s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2699/36984 [4:28:50<61:12:55,  6.43s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2700/36984 [4:29:05<85:44:23,  9.00s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2701/36984 [4:29:05<60:46:59,  6.38s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2702/36984 [4:29:16<71:52:29,  7.55s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2703/36984 [4:29:16<50:59:26,  5.35s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2704/36984 [4:29:26<64:34:45,  6.78s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2705/36984 [4:29:26<45:50:59,  4.82s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2706/36984 [4:29:40<72:04:02,  7.57s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2707/36984 [4:29:40<51:04:52,  5.36s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2708/36984 [4:30:27<167:35:26, 17.60s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2709/36984 [4:30:27<117:56:38, 12.39s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2710/36984 [4:30:37<111:14:33, 11.68s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2711/36984 [4:30:37<78:29:38,  8.24s/batch, loss=0.0004] Training Epoch 1:   7%|▋         | 2712/36984 [4:30:48<86:42:25,  9.11s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2713/36984 [4:30:48<61:19:05,  6.44s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2714/36984 [4:31:00<74:48:04,  7.86s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2715/36984 [4:31:00<52:58:48,  5.57s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2716/36984 [4:31:11<69:20:05,  7.28s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2717/36984 [4:31:11<49:09:06,  5.16s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2718/36984 [4:31:23<68:34:59,  7.21s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2719/36984 [4:31:24<48:37:16,  5.11s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2719/36984 [4:31:34<48:37:16,  5.11s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2720/36984 [4:31:34<63:45:30,  6.70s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2722/36984 [4:31:46<61:56:46,  6.51s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2723/36984 [4:31:47<47:05:46,  4.95s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2724/36984 [4:31:58<62:11:19,  6.53s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2725/36984 [4:31:58<45:49:43,  4.82s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2726/36984 [4:32:12<70:43:10,  7.43s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2727/36984 [4:32:12<51:06:40,  5.37s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2728/36984 [4:32:28<79:23:03,  8.34s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2729/36984 [4:32:28<56:44:45,  5.96s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2730/36984 [4:32:40<72:42:58,  7.64s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2731/36984 [4:32:40<51:46:17,  5.44s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2732/36984 [4:32:56<82:00:36,  8.62s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2733/36984 [4:32:56<58:09:56,  6.11s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2734/36984 [4:33:07<70:55:08,  7.45s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2735/36984 [4:33:07<50:19:09,  5.29s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2736/36984 [4:33:20<70:29:10,  7.41s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2737/36984 [4:33:20<49:59:05,  5.25s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2738/36984 [4:33:32<71:06:13,  7.47s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2739/36984 [4:33:33<50:24:13,  5.30s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2740/36984 [4:33:53<91:57:28,  9.67s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2741/36984 [4:33:53<64:59:56,  6.83s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2742/36984 [4:34:13<103:45:42, 10.91s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2743/36984 [4:34:13<73:15:20,  7.70s/batch, loss=0.0004] Training Epoch 1:   7%|▋         | 2744/36984 [4:34:27<89:18:09,  9.39s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2745/36984 [4:34:27<63:07:43,  6.64s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2746/36984 [4:34:37<72:35:53,  7.63s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2747/36984 [4:34:37<51:26:07,  5.41s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2748/36984 [4:34:49<69:41:01,  7.33s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2749/36984 [4:34:49<49:23:45,  5.19s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2750/36984 [4:34:59<63:51:25,  6.72s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2751/36984 [4:35:00<45:19:12,  4.77s/batch, loss=0.0004]Training Epoch 1:   7%|▋         | 2751/36984 [4:35:10<45:19:12,  4.77s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2752/36984 [4:35:10<62:48:57,  6.61s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2754/36984 [4:35:21<56:01:01,  5.89s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2755/36984 [4:35:21<42:38:12,  4.48s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2756/36984 [4:35:33<62:31:18,  6.58s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2757/36984 [4:35:34<46:04:17,  4.85s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2758/36984 [4:35:45<63:21:02,  6.66s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2759/36984 [4:35:45<45:50:26,  4.82s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2760/36984 [4:35:55<59:43:45,  6.28s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2761/36984 [4:35:55<42:50:44,  4.51s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2762/36984 [4:36:06<59:12:36,  6.23s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2763/36984 [4:36:06<42:16:23,  4.45s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2764/36984 [4:36:15<57:12:45,  6.02s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2765/36984 [4:36:16<40:45:50,  4.29s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2766/36984 [4:36:27<61:04:12,  6.43s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2767/36984 [4:36:27<43:25:09,  4.57s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2768/36984 [4:36:40<66:50:05,  7.03s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2769/36984 [4:36:40<47:25:55,  4.99s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2770/36984 [4:36:52<65:15:46,  6.87s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2771/36984 [4:36:52<46:18:41,  4.87s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2772/36984 [4:37:02<60:47:28,  6.40s/batch, loss=0.0003]Training Epoch 1:   7%|▋         | 2773/36984 [4:37:02<43:10:35,  4.54s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2774/36984 [4:37:18<74:46:25,  7.87s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2775/36984 [4:37:18<52:57:44,  5.57s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2776/36984 [4:37:28<64:44:26,  6.81s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2777/36984 [4:37:28<45:56:14,  4.83s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2778/36984 [4:37:42<72:01:10,  7.58s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2779/36984 [4:37:42<51:02:01,  5.37s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2780/36984 [4:37:52<63:57:22,  6.73s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2781/36984 [4:37:52<45:23:14,  4.78s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2782/36984 [4:38:02<60:26:27,  6.36s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2783/36984 [4:38:02<42:55:29,  4.52s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2783/36984 [4:38:13<42:55:29,  4.52s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2784/36984 [4:38:13<61:45:55,  6.50s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2786/36984 [4:38:24<56:29:45,  5.95s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2787/36984 [4:38:24<42:59:58,  4.53s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2788/36984 [4:38:36<60:17:18,  6.35s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2789/36984 [4:38:36<44:27:11,  4.68s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2790/36984 [4:38:48<64:07:13,  6.75s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2791/36984 [4:38:48<46:23:38,  4.88s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2792/36984 [4:39:03<73:12:49,  7.71s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2793/36984 [4:39:03<52:22:36,  5.51s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2794/36984 [4:39:17<75:17:10,  7.93s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2795/36984 [4:39:17<53:34:55,  5.64s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2796/36984 [4:39:27<66:40:10,  7.02s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2797/36984 [4:39:28<47:23:32,  4.99s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2798/36984 [4:39:37<61:15:14,  6.45s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2799/36984 [4:39:38<43:32:47,  4.59s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2800/36984 [4:39:50<66:24:19,  6.99s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2801/36984 [4:39:50<47:07:35,  4.96s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2802/36984 [4:40:01<62:17:20,  6.56s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2803/36984 [4:40:01<44:13:47,  4.66s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2804/36984 [4:40:15<72:08:20,  7.60s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2805/36984 [4:40:16<51:07:13,  5.38s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2806/36984 [4:40:27<67:52:16,  7.15s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2807/36984 [4:40:27<48:07:41,  5.07s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2808/36984 [4:40:41<72:48:51,  7.67s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2809/36984 [4:40:41<51:35:16,  5.43s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2810/36984 [4:40:56<78:25:39,  8.26s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2811/36984 [4:40:56<55:30:53,  5.85s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2812/36984 [4:41:07<70:08:23,  7.39s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2813/36984 [4:41:07<49:42:46,  5.24s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2814/36984 [4:41:18<64:30:07,  6.80s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2815/36984 [4:41:18<45:46:06,  4.82s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2815/36984 [4:41:29<45:46:06,  4.82s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2816/36984 [4:41:29<64:13:29,  6.77s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2818/36984 [4:41:43<63:56:13,  6.74s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2819/36984 [4:41:43<48:35:39,  5.12s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2820/36984 [4:41:53<60:30:01,  6.38s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2821/36984 [4:41:53<44:36:06,  4.70s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2822/36984 [4:42:03<57:50:52,  6.10s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2823/36984 [4:42:03<41:54:33,  4.42s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2824/36984 [4:42:14<59:42:22,  6.29s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2825/36984 [4:42:14<42:49:30,  4.51s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2826/36984 [4:42:24<58:25:25,  6.16s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2827/36984 [4:42:24<41:42:50,  4.40s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2828/36984 [4:42:35<59:32:14,  6.28s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2829/36984 [4:42:35<42:23:35,  4.47s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2830/36984 [4:42:45<58:26:04,  6.16s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2831/36984 [4:42:46<41:34:00,  4.38s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2832/36984 [4:42:56<56:59:12,  6.01s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2833/36984 [4:42:56<40:31:56,  4.27s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2834/36984 [4:43:08<63:39:02,  6.71s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2835/36984 [4:43:08<45:11:07,  4.76s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2836/36984 [4:43:18<59:15:41,  6.25s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2837/36984 [4:43:18<42:05:33,  4.44s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2838/36984 [4:43:29<59:02:32,  6.22s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2839/36984 [4:43:29<41:56:51,  4.42s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2840/36984 [4:43:38<56:36:17,  5.97s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2841/36984 [4:43:39<40:14:34,  4.24s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2842/36984 [4:43:49<58:01:29,  6.12s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2843/36984 [4:43:49<41:14:08,  4.35s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2844/36984 [4:44:01<63:08:07,  6.66s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2845/36984 [4:44:02<44:48:39,  4.73s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2846/36984 [4:44:14<67:11:42,  7.09s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2847/36984 [4:44:14<47:38:59,  5.03s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2847/36984 [4:44:26<47:38:59,  5.03s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2848/36984 [4:44:26<66:08:57,  6.98s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2850/36984 [4:44:41<69:31:44,  7.33s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2851/36984 [4:44:42<52:47:56,  5.57s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2852/36984 [4:44:59<80:58:11,  8.54s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2853/36984 [4:44:59<59:30:09,  6.28s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2854/36984 [4:45:10<73:28:14,  7.75s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2855/36984 [4:45:11<53:04:19,  5.60s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2856/36984 [4:45:21<66:30:48,  7.02s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2857/36984 [4:45:21<47:38:27,  5.03s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2858/36984 [4:45:33<67:33:05,  7.13s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2859/36984 [4:45:34<48:08:17,  5.08s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2860/36984 [4:45:45<66:42:52,  7.04s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2861/36984 [4:45:46<47:25:50,  5.00s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2862/36984 [4:45:56<63:03:04,  6.65s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2863/36984 [4:45:56<44:48:20,  4.73s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2864/36984 [4:46:10<71:09:58,  7.51s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2865/36984 [4:46:11<50:27:47,  5.32s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2866/36984 [4:46:21<64:08:54,  6.77s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2867/36984 [4:46:21<45:31:54,  4.80s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2868/36984 [4:46:33<65:38:42,  6.93s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2869/36984 [4:46:33<46:34:25,  4.91s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2870/36984 [4:46:54<91:18:19,  9.64s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2871/36984 [4:46:54<64:31:57,  6.81s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2872/36984 [4:47:07<82:58:20,  8.76s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2873/36984 [4:47:07<58:41:45,  6.19s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2874/36984 [4:47:19<73:26:46,  7.75s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2875/36984 [4:47:19<52:01:06,  5.49s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2876/36984 [4:47:29<65:52:35,  6.95s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2877/36984 [4:47:30<46:43:46,  4.93s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2878/36984 [4:47:40<63:17:35,  6.68s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2879/36984 [4:47:41<44:55:07,  4.74s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2879/36984 [4:47:51<44:55:07,  4.74s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2880/36984 [4:47:51<61:13:30,  6.46s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2882/36984 [4:48:01<55:46:38,  5.89s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2883/36984 [4:48:02<42:27:31,  4.48s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2884/36984 [4:48:13<59:21:10,  6.27s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2885/36984 [4:48:13<43:46:10,  4.62s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2886/36984 [4:48:23<57:51:19,  6.11s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2887/36984 [4:48:23<41:54:48,  4.43s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2888/36984 [4:48:33<57:08:16,  6.03s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2889/36984 [4:48:34<41:00:37,  4.33s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2890/36984 [4:48:44<57:13:41,  6.04s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2891/36984 [4:48:44<40:52:18,  4.32s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2892/36984 [4:48:58<69:41:58,  7.36s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2893/36984 [4:48:59<49:31:22,  5.23s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2894/36984 [4:49:11<69:51:14,  7.38s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2895/36984 [4:49:11<49:34:00,  5.23s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2896/36984 [4:49:21<63:02:29,  6.66s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2897/36984 [4:49:21<44:46:01,  4.73s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2898/36984 [4:49:35<70:01:21,  7.40s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2899/36984 [4:49:35<49:38:37,  5.24s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2900/36984 [4:49:47<67:35:05,  7.14s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2901/36984 [4:49:47<47:55:34,  5.06s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2902/36984 [4:49:57<62:06:38,  6.56s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2903/36984 [4:49:57<44:05:50,  4.66s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2904/36984 [4:50:08<62:01:36,  6.55s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2905/36984 [4:50:09<44:02:16,  4.65s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2906/36984 [4:50:19<59:29:09,  6.28s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2907/36984 [4:50:19<42:23:13,  4.48s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2908/36984 [4:50:29<57:45:17,  6.10s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2909/36984 [4:50:29<41:44:35,  4.41s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2910/36984 [4:50:43<68:58:35,  7.29s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2911/36984 [4:50:44<48:53:55,  5.17s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2911/36984 [4:50:53<48:53:55,  5.17s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2912/36984 [4:50:53<62:16:41,  6.58s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2914/36984 [4:51:06<60:43:28,  6.42s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2915/36984 [4:51:08<50:04:39,  5.29s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2916/36984 [4:51:19<64:46:10,  6.84s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2917/36984 [4:51:21<52:06:45,  5.51s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2918/36984 [4:51:31<65:24:44,  6.91s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2919/36984 [4:51:32<48:42:17,  5.15s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2920/36984 [4:51:44<67:03:11,  7.09s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2921/36984 [4:51:45<51:26:51,  5.44s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2922/36984 [4:51:56<64:24:26,  6.81s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2923/36984 [4:51:56<47:51:53,  5.06s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2924/36984 [4:52:08<67:15:59,  7.11s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2925/36984 [4:52:10<51:07:51,  5.40s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2926/36984 [4:52:18<59:12:08,  6.26s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2927/36984 [4:52:20<47:41:46,  5.04s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2928/36984 [4:52:29<57:11:52,  6.05s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2929/36984 [4:52:31<45:32:47,  4.81s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2930/36984 [4:52:39<55:11:15,  5.83s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2931/36984 [4:52:41<43:37:24,  4.61s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2932/36984 [4:52:50<56:16:36,  5.95s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2933/36984 [4:52:51<43:47:56,  4.63s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2934/36984 [4:53:01<59:19:04,  6.27s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2935/36984 [4:53:02<44:52:21,  4.74s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2936/36984 [4:53:13<60:23:32,  6.39s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2937/36984 [4:53:14<45:05:50,  4.77s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2938/36984 [4:53:24<60:05:11,  6.35s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2939/36984 [4:53:24<43:37:16,  4.61s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2940/36984 [4:53:44<87:52:01,  9.29s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2941/36984 [4:53:45<62:37:28,  6.62s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2942/36984 [4:53:59<84:03:42,  8.89s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2943/36984 [4:53:59<59:27:32,  6.29s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2943/36984 [4:54:10<59:27:32,  6.29s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2944/36984 [4:54:10<70:48:31,  7.49s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2946/36984 [4:54:19<59:20:55,  6.28s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2947/36984 [4:54:21<48:16:21,  5.11s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2948/36984 [4:54:35<70:14:46,  7.43s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2949/36984 [4:54:36<53:04:04,  5.61s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2950/36984 [4:54:45<63:56:36,  6.76s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2951/36984 [4:54:46<48:12:56,  5.10s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2952/36984 [4:55:01<74:55:52,  7.93s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2953/36984 [4:55:03<57:03:00,  6.04s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2954/36984 [4:55:12<67:30:54,  7.14s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2955/36984 [4:55:13<50:10:49,  5.31s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2956/36984 [4:55:25<67:59:41,  7.19s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2957/36984 [4:55:26<50:59:29,  5.39s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2958/36984 [4:55:35<61:33:10,  6.51s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2959/36984 [4:55:37<47:31:11,  5.03s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2960/36984 [4:55:51<74:04:20,  7.84s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2961/36984 [4:55:52<53:35:51,  5.67s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2962/36984 [4:56:06<78:20:27,  8.29s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2963/36984 [4:56:06<55:28:08,  5.87s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2964/36984 [4:56:17<68:23:23,  7.24s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2965/36984 [4:56:17<48:29:32,  5.13s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2966/36984 [4:56:36<87:42:13,  9.28s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2967/36984 [4:56:36<62:00:27,  6.56s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2968/36984 [4:56:50<83:26:50,  8.83s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2969/36984 [4:56:51<59:01:45,  6.25s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2970/36984 [4:57:01<70:20:44,  7.45s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2971/36984 [4:57:01<49:51:20,  5.28s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2972/36984 [4:57:13<67:41:11,  7.16s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2973/36984 [4:57:13<47:59:48,  5.08s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2974/36984 [4:57:30<81:32:47,  8.63s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2975/36984 [4:57:30<57:41:41,  6.11s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 2975/36984 [4:57:43<57:41:41,  6.11s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2976/36984 [4:57:43<75:57:08,  8.04s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2978/36984 [4:57:54<66:51:16,  7.08s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2979/36984 [4:57:55<50:47:06,  5.38s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2980/36984 [4:58:07<67:28:27,  7.14s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2981/36984 [4:58:07<49:39:51,  5.26s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2982/36984 [4:58:17<62:45:42,  6.64s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2983/36984 [4:58:17<45:24:53,  4.81s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2984/36984 [4:58:28<59:53:40,  6.34s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2985/36984 [4:58:28<42:57:26,  4.55s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2986/36984 [4:58:37<56:10:00,  5.95s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2987/36984 [4:58:37<40:07:23,  4.25s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2988/36984 [4:58:47<55:25:18,  5.87s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2989/36984 [4:58:47<39:30:11,  4.18s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2990/36984 [4:58:57<55:21:27,  5.86s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2991/36984 [4:58:57<39:59:35,  4.24s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2992/36984 [4:59:11<66:26:03,  7.04s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2993/36984 [4:59:12<50:08:27,  5.31s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2994/36984 [4:59:30<86:10:24,  9.13s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2995/36984 [4:59:33<67:20:14,  7.13s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2996/36984 [4:59:49<92:49:44,  9.83s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2997/36984 [4:59:51<69:48:39,  7.39s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2998/36984 [5:00:02<81:22:25,  8.62s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 2999/36984 [5:00:04<61:02:25,  6.47s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3000/36984 [5:00:17<79:40:14,  8.44s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3001/36984 [5:00:17<58:02:59,  6.15s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3002/36984 [5:00:30<75:58:26,  8.05s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3003/36984 [5:00:31<56:58:53,  6.04s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3004/36984 [5:00:41<67:03:28,  7.10s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3005/36984 [5:00:41<48:42:45,  5.16s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3006/36984 [5:00:52<62:47:45,  6.65s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3007/36984 [5:00:54<49:46:39,  5.27s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3007/36984 [5:01:04<49:46:39,  5.27s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3008/36984 [5:01:04<63:11:36,  6.70s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3010/36984 [5:01:14<56:40:44,  6.01s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3011/36984 [5:01:14<43:07:52,  4.57s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3012/36984 [5:01:26<59:57:54,  6.35s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3013/36984 [5:01:26<44:12:22,  4.68s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3014/36984 [5:01:36<58:40:23,  6.22s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3015/36984 [5:01:36<42:30:01,  4.50s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3016/36984 [5:01:46<58:12:46,  6.17s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3017/36984 [5:01:47<41:45:41,  4.43s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3018/36984 [5:01:59<63:36:02,  6.74s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3019/36984 [5:01:59<45:21:06,  4.81s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3020/36984 [5:02:09<59:25:44,  6.30s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3021/36984 [5:02:09<42:18:53,  4.49s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3022/36984 [5:02:19<56:06:15,  5.95s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3023/36984 [5:02:19<39:55:47,  4.23s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3024/36984 [5:02:32<64:23:30,  6.83s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3025/36984 [5:02:32<45:42:42,  4.85s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3026/36984 [5:02:42<60:59:46,  6.47s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3027/36984 [5:02:42<43:19:14,  4.59s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3028/36984 [5:02:58<74:26:01,  7.89s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3029/36984 [5:02:58<52:43:23,  5.59s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3030/36984 [5:03:09<68:22:25,  7.25s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3031/36984 [5:03:10<48:28:35,  5.14s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3032/36984 [5:03:21<65:26:29,  6.94s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3033/36984 [5:03:21<46:25:15,  4.92s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3034/36984 [5:03:41<89:41:17,  9.51s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3035/36984 [5:03:41<63:23:37,  6.72s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3036/36984 [5:03:54<79:51:15,  8.47s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3037/36984 [5:03:54<56:30:43,  5.99s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3038/36984 [5:04:06<72:37:57,  7.70s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3039/36984 [5:04:06<51:42:47,  5.48s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3039/36984 [5:04:16<51:42:47,  5.48s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3040/36984 [5:04:16<65:01:29,  6.90s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3041/36984 [5:04:18<49:15:56,  5.23s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3042/36984 [5:04:28<63:39:53,  6.75s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3043/36984 [5:04:29<46:36:37,  4.94s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3044/36984 [5:04:42<69:46:50,  7.40s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3045/36984 [5:04:43<51:24:48,  5.45s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3046/36984 [5:04:52<61:31:54,  6.53s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3047/36984 [5:04:53<47:10:50,  5.00s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3048/36984 [5:05:04<64:35:28,  6.85s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3049/36984 [5:05:08<54:29:00,  5.78s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3050/36984 [5:05:17<65:13:49,  6.92s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3051/36984 [5:05:18<48:39:37,  5.16s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3052/36984 [5:05:29<65:19:22,  6.93s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3053/36984 [5:05:31<51:41:39,  5.48s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3054/36984 [5:05:41<62:40:48,  6.65s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3055/36984 [5:05:41<45:04:40,  4.78s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3056/36984 [5:05:51<59:40:05,  6.33s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3057/36984 [5:05:51<42:22:44,  4.50s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3058/36984 [5:06:04<64:23:17,  6.83s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3059/36984 [5:06:04<45:40:59,  4.85s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3060/36984 [5:06:15<62:31:24,  6.63s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3061/36984 [5:06:15<44:22:42,  4.71s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3062/36984 [5:06:25<59:10:23,  6.28s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3063/36984 [5:06:25<42:01:55,  4.46s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3064/36984 [5:06:35<58:38:54,  6.22s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3065/36984 [5:06:36<41:39:52,  4.42s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3066/36984 [5:06:51<71:13:48,  7.56s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3067/36984 [5:06:51<50:28:18,  5.36s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3068/36984 [5:07:03<71:20:33,  7.57s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3069/36984 [5:07:04<50:32:59,  5.37s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3070/36984 [5:07:18<75:25:38,  8.01s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3071/36984 [5:07:18<53:24:35,  5.67s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3071/36984 [5:07:29<53:24:35,  5.67s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3072/36984 [5:07:29<69:11:07,  7.34s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3074/36984 [5:07:39<59:07:50,  6.28s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3075/36984 [5:07:40<44:58:28,  4.77s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3076/36984 [5:07:53<66:38:41,  7.08s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3077/36984 [5:07:53<49:04:18,  5.21s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3078/36984 [5:08:05<64:53:24,  6.89s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3079/36984 [5:08:05<47:23:10,  5.03s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3080/36984 [5:08:15<60:17:40,  6.40s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3081/36984 [5:08:15<43:14:23,  4.59s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3082/36984 [5:08:25<58:47:15,  6.24s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3083/36984 [5:08:25<41:58:02,  4.46s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3084/36984 [5:08:39<68:36:20,  7.29s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3085/36984 [5:08:40<50:01:53,  5.31s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3086/36984 [5:08:55<78:13:53,  8.31s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3087/36984 [5:08:56<56:18:35,  5.98s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3088/36984 [5:09:06<68:38:25,  7.29s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3089/36984 [5:09:08<52:47:43,  5.61s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3090/36984 [5:09:17<62:02:59,  6.59s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3091/36984 [5:09:18<47:13:51,  5.02s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3092/36984 [5:09:31<68:04:11,  7.23s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3093/36984 [5:09:32<53:05:37,  5.64s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3094/36984 [5:09:46<75:15:13,  7.99s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3095/36984 [5:09:47<56:25:04,  5.99s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3096/36984 [5:09:58<69:08:48,  7.35s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3097/36984 [5:09:59<51:22:10,  5.46s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3098/36984 [5:10:09<64:04:29,  6.81s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3099/36984 [5:10:10<47:41:31,  5.07s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3100/36984 [5:10:21<64:43:33,  6.88s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3101/36984 [5:10:24<52:48:36,  5.61s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3102/36984 [5:10:32<62:01:31,  6.59s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3103/36984 [5:10:34<48:13:51,  5.12s/batch, loss=0.0004]Training Epoch 1:   8%|▊         | 3103/36984 [5:10:44<48:13:51,  5.12s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3104/36984 [5:10:44<60:18:36,  6.41s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3105/36984 [5:10:45<45:12:34,  4.80s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3106/36984 [5:10:55<62:23:43,  6.63s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3107/36984 [5:10:56<45:20:08,  4.82s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3108/36984 [5:11:07<61:37:25,  6.55s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3109/36984 [5:11:07<43:44:38,  4.65s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3110/36984 [5:11:20<66:19:20,  7.05s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3111/36984 [5:11:20<47:02:03,  5.00s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3112/36984 [5:11:40<90:02:17,  9.57s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3113/36984 [5:11:40<63:38:16,  6.76s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3114/36984 [5:11:53<79:15:42,  8.42s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3115/36984 [5:11:53<56:05:09,  5.96s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3116/36984 [5:12:03<68:01:10,  7.23s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3117/36984 [5:12:03<48:13:26,  5.13s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3118/36984 [5:12:13<62:14:34,  6.62s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3119/36984 [5:12:13<44:10:41,  4.70s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3120/36984 [5:12:23<56:59:21,  6.06s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3121/36984 [5:12:23<40:29:56,  4.31s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3122/36984 [5:12:33<55:48:58,  5.93s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3123/36984 [5:12:33<39:40:54,  4.22s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3124/36984 [5:12:44<58:33:28,  6.23s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3125/36984 [5:12:44<41:36:04,  4.42s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3126/36984 [5:12:54<58:36:32,  6.23s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3127/36984 [5:12:55<41:38:03,  4.43s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3128/36984 [5:13:05<58:22:07,  6.21s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3129/36984 [5:13:05<41:27:53,  4.41s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3130/36984 [5:13:19<66:44:52,  7.10s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3131/36984 [5:13:19<47:20:00,  5.03s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3132/36984 [5:13:29<60:37:49,  6.45s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3133/36984 [5:13:29<43:03:16,  4.58s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3134/36984 [5:13:41<65:18:54,  6.95s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3135/36984 [5:13:41<46:19:56,  4.93s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3135/36984 [5:13:56<46:19:56,  4.93s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3136/36984 [5:13:56<72:42:32,  7.73s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3138/36984 [5:14:10<70:46:01,  7.53s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3139/36984 [5:14:11<53:43:38,  5.71s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3140/36984 [5:14:26<77:57:33,  8.29s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3141/36984 [5:14:26<57:18:22,  6.10s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3142/36984 [5:14:37<69:47:33,  7.42s/batch, loss=0.0003]Training Epoch 1:   8%|▊         | 3143/36984 [5:14:37<50:26:34,  5.37s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3144/36984 [5:14:50<69:28:25,  7.39s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3145/36984 [5:14:50<49:43:43,  5.29s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3146/36984 [5:15:06<80:55:27,  8.61s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3147/36984 [5:15:07<57:32:20,  6.12s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3148/36984 [5:15:19<74:10:56,  7.89s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3149/36984 [5:15:19<52:39:40,  5.60s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3150/36984 [5:15:40<95:12:42, 10.13s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3151/36984 [5:15:40<67:20:15,  7.17s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3152/36984 [5:15:52<81:35:24,  8.68s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3153/36984 [5:15:52<57:45:24,  6.15s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3154/36984 [5:16:11<93:44:02,  9.97s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3155/36984 [5:16:12<66:14:31,  7.05s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3156/36984 [5:16:22<74:38:17,  7.94s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3157/36984 [5:16:22<52:51:50,  5.63s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3158/36984 [5:16:31<63:18:09,  6.74s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3159/36984 [5:16:31<44:55:24,  4.78s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3160/36984 [5:16:43<65:26:59,  6.97s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3161/36984 [5:16:44<47:47:02,  5.09s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3162/36984 [5:16:55<63:06:49,  6.72s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3163/36984 [5:16:55<44:47:17,  4.77s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3164/36984 [5:17:09<69:57:35,  7.45s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3165/36984 [5:17:09<49:34:52,  5.28s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3166/36984 [5:17:22<70:50:12,  7.54s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3167/36984 [5:17:22<50:11:45,  5.34s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3167/36984 [5:17:38<50:11:45,  5.34s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3168/36984 [5:17:38<79:50:05,  8.50s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3170/36984 [5:17:49<67:11:34,  7.15s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3171/36984 [5:17:49<51:02:11,  5.43s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3172/36984 [5:17:59<61:46:28,  6.58s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3173/36984 [5:17:59<45:31:23,  4.85s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3174/36984 [5:18:10<60:54:31,  6.49s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3175/36984 [5:18:10<44:05:29,  4.69s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3176/36984 [5:18:20<58:12:42,  6.20s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3177/36984 [5:18:20<41:45:45,  4.45s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3178/36984 [5:18:32<61:38:01,  6.56s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3179/36984 [5:18:32<43:57:54,  4.68s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3180/36984 [5:18:43<62:51:02,  6.69s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3181/36984 [5:18:44<44:42:03,  4.76s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3182/36984 [5:18:54<60:16:25,  6.42s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3183/36984 [5:18:54<42:51:07,  4.56s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3184/36984 [5:19:04<57:59:16,  6.18s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3185/36984 [5:19:04<41:13:21,  4.39s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3186/36984 [5:19:14<56:19:15,  6.00s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3187/36984 [5:19:14<40:02:37,  4.27s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3188/36984 [5:19:25<59:22:06,  6.32s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3189/36984 [5:19:26<42:10:24,  4.49s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3190/36984 [5:19:37<61:42:17,  6.57s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3191/36984 [5:19:37<43:48:28,  4.67s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3192/36984 [5:19:47<58:32:34,  6.24s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3193/36984 [5:19:47<41:35:27,  4.43s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3194/36984 [5:19:57<57:17:57,  6.10s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3195/36984 [5:19:58<40:42:57,  4.34s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3196/36984 [5:20:08<57:26:48,  6.12s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3197/36984 [5:20:08<40:49:10,  4.35s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3198/36984 [5:20:23<70:08:25,  7.47s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3199/36984 [5:20:23<49:42:33,  5.30s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3199/36984 [5:20:34<49:42:33,  5.30s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3200/36984 [5:20:34<64:59:55,  6.93s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3202/36984 [5:20:49<67:33:28,  7.20s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3203/36984 [5:20:51<55:58:28,  5.97s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3204/36984 [5:21:00<64:29:34,  6.87s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3205/36984 [5:21:01<48:38:25,  5.18s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3206/36984 [5:21:10<58:32:46,  6.24s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3207/36984 [5:21:11<43:49:40,  4.67s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3208/36984 [5:21:22<62:10:24,  6.63s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3209/36984 [5:21:22<44:33:55,  4.75s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3210/36984 [5:21:34<62:35:16,  6.67s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3211/36984 [5:21:34<44:38:03,  4.76s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3212/36984 [5:21:44<58:57:30,  6.28s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3213/36984 [5:21:44<41:58:48,  4.48s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3214/36984 [5:21:56<61:41:04,  6.58s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3215/36984 [5:21:56<45:46:39,  4.88s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3216/36984 [5:22:10<70:38:07,  7.53s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3217/36984 [5:22:10<50:04:34,  5.34s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3218/36984 [5:22:22<68:39:11,  7.32s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3219/36984 [5:22:23<48:40:10,  5.19s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3220/36984 [5:22:33<64:02:26,  6.83s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3221/36984 [5:22:33<45:26:38,  4.85s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3222/36984 [5:22:43<58:43:39,  6.26s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3223/36984 [5:22:43<41:43:19,  4.45s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3224/36984 [5:22:55<62:43:41,  6.69s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3225/36984 [5:22:56<45:59:19,  4.90s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3226/36984 [5:23:11<74:44:37,  7.97s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3227/36984 [5:23:13<58:31:55,  6.24s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3228/36984 [5:23:21<63:06:52,  6.73s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3229/36984 [5:23:23<49:47:00,  5.31s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3230/36984 [5:23:31<56:44:26,  6.05s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3231/36984 [5:23:36<53:14:10,  5.68s/batch, loss=0.0003]Training Epoch 1:   9%|▊         | 3231/36984 [5:23:44<53:14:10,  5.68s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3232/36984 [5:23:44<59:50:43,  6.38s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3233/36984 [5:23:46<49:15:31,  5.25s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3234/36984 [5:23:53<54:11:44,  5.78s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3235/36984 [5:23:57<47:30:41,  5.07s/batch, loss=0.0004]Training Epoch 1:   9%|▊         | 3236/36984 [5:24:05<57:26:13,  6.13s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3237/36984 [5:24:10<53:12:52,  5.68s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3238/36984 [5:24:16<54:57:02,  5.86s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3239/36984 [5:24:22<53:39:50,  5.73s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3240/36984 [5:24:33<68:47:02,  7.34s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3241/36984 [5:24:37<58:56:06,  6.29s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3242/36984 [5:24:44<63:10:05,  6.74s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3243/36984 [5:24:46<49:43:25,  5.31s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3244/36984 [5:24:54<56:09:33,  5.99s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3245/36984 [5:24:58<51:42:29,  5.52s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3246/36984 [5:25:04<51:48:35,  5.53s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3247/36984 [5:25:08<48:57:02,  5.22s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3248/36984 [5:25:14<49:39:15,  5.30s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3249/36984 [5:25:44<119:57:05, 12.80s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3250/36984 [5:26:01<131:32:10, 14.04s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3251/36984 [5:26:05<103:36:35, 11.06s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3252/36984 [5:26:11<88:17:01,  9.42s/batch, loss=0.0004] Training Epoch 1:   9%|▉         | 3253/36984 [5:26:19<83:42:24,  8.93s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3254/36984 [5:26:27<82:48:05,  8.84s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3255/36984 [5:26:32<71:23:31,  7.62s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3256/36984 [5:26:38<66:39:33,  7.11s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3257/36984 [5:26:42<58:06:26,  6.20s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3258/36984 [5:26:48<57:54:39,  6.18s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3259/36984 [5:26:52<51:13:54,  5.47s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3260/36984 [5:27:03<66:00:47,  7.05s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3261/36984 [5:27:08<60:14:36,  6.43s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3262/36984 [5:27:14<59:58:30,  6.40s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3263/36984 [5:27:18<52:27:28,  5.60s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3263/36984 [5:27:25<52:27:28,  5.60s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3264/36984 [5:27:25<55:37:39,  5.94s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3265/36984 [5:27:28<47:56:02,  5.12s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3266/36984 [5:27:35<54:13:59,  5.79s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3267/36984 [5:27:38<45:23:05,  4.85s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3268/36984 [5:27:47<57:05:46,  6.10s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3269/36984 [5:27:49<47:01:47,  5.02s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3270/36984 [5:27:56<52:56:35,  5.65s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3271/36984 [5:27:59<43:16:57,  4.62s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3272/36984 [5:28:09<59:51:02,  6.39s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3273/36984 [5:28:10<43:08:47,  4.61s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3274/36984 [5:28:22<65:19:02,  6.98s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3275/36984 [5:28:22<46:19:29,  4.95s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3276/36984 [5:28:32<61:02:50,  6.52s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3277/36984 [5:28:34<48:27:11,  5.17s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3278/36984 [5:28:47<69:15:27,  7.40s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3279/36984 [5:28:49<52:42:07,  5.63s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3280/36984 [5:28:59<65:12:11,  6.96s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3281/36984 [5:29:00<49:01:51,  5.24s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3282/36984 [5:29:10<62:02:45,  6.63s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3283/36984 [5:29:10<45:09:28,  4.82s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3284/36984 [5:29:22<64:15:38,  6.86s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3285/36984 [5:29:22<45:34:41,  4.87s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3286/36984 [5:29:32<59:59:57,  6.41s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3287/36984 [5:29:32<42:36:23,  4.55s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3288/36984 [5:29:43<58:50:53,  6.29s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3289/36984 [5:29:43<41:47:57,  4.47s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3290/36984 [5:29:54<59:47:12,  6.39s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3291/36984 [5:29:54<42:36:16,  4.55s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3292/36984 [5:30:05<61:16:48,  6.55s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3293/36984 [5:30:06<45:32:35,  4.87s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3294/36984 [5:30:17<62:15:07,  6.65s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3295/36984 [5:30:17<44:11:02,  4.72s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3295/36984 [5:30:27<44:11:02,  4.72s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3296/36984 [5:30:27<59:28:11,  6.36s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3298/36984 [5:30:37<52:58:52,  5.66s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3299/36984 [5:30:38<41:49:27,  4.47s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3300/36984 [5:30:47<53:24:36,  5.71s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3301/36984 [5:30:48<41:47:28,  4.47s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3302/36984 [5:30:59<57:13:49,  6.12s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3303/36984 [5:31:00<45:07:20,  4.82s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3304/36984 [5:31:09<56:24:31,  6.03s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3305/36984 [5:31:11<43:34:55,  4.66s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3306/36984 [5:31:19<55:02:43,  5.88s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3307/36984 [5:31:22<44:50:37,  4.79s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3308/36984 [5:31:32<59:13:03,  6.33s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3309/36984 [5:31:33<46:41:56,  4.99s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3310/36984 [5:31:43<58:10:57,  6.22s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3311/36984 [5:31:44<45:51:31,  4.90s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3312/36984 [5:31:54<57:54:16,  6.19s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3313/36984 [5:31:57<50:13:21,  5.37s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3314/36984 [5:32:05<58:40:30,  6.27s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3315/36984 [5:32:06<43:58:29,  4.70s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3316/36984 [5:32:15<55:30:05,  5.93s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3317/36984 [5:32:16<41:36:41,  4.45s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3318/36984 [5:32:25<54:56:29,  5.88s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3319/36984 [5:32:26<40:25:16,  4.32s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3320/36984 [5:32:36<55:53:58,  5.98s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3321/36984 [5:32:37<42:22:50,  4.53s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3322/36984 [5:32:50<66:47:19,  7.14s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3323/36984 [5:32:51<49:00:26,  5.24s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3324/36984 [5:33:01<61:52:03,  6.62s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3325/36984 [5:33:02<45:38:52,  4.88s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3326/36984 [5:33:12<59:25:40,  6.36s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3327/36984 [5:33:12<43:45:18,  4.68s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3327/36984 [5:33:22<43:45:18,  4.68s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3328/36984 [5:33:22<57:38:15,  6.17s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3329/36984 [5:33:23<41:57:06,  4.49s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3330/36984 [5:33:32<55:27:54,  5.93s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3331/36984 [5:33:34<44:32:42,  4.77s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3332/36984 [5:33:43<57:22:17,  6.14s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3333/36984 [5:33:47<49:26:32,  5.29s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3334/36984 [5:33:59<68:12:30,  7.30s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3335/36984 [5:34:01<55:29:20,  5.94s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3336/36984 [5:34:08<58:45:28,  6.29s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3337/36984 [5:34:12<50:23:57,  5.39s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3338/36984 [5:34:19<55:44:09,  5.96s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3339/36984 [5:34:22<46:19:51,  4.96s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3340/36984 [5:34:36<73:29:08,  7.86s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3341/36984 [5:34:40<62:35:26,  6.70s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3342/36984 [5:34:48<65:15:47,  6.98s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3343/36984 [5:34:50<52:16:26,  5.59s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3344/36984 [5:34:59<61:36:42,  6.59s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3345/36984 [5:35:01<49:17:00,  5.27s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3346/36984 [5:35:12<64:09:03,  6.87s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3347/36984 [5:35:14<50:04:12,  5.36s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3348/36984 [5:35:22<58:13:59,  6.23s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3349/36984 [5:35:24<46:29:47,  4.98s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3350/36984 [5:35:32<55:03:33,  5.89s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3351/36984 [5:35:36<47:58:08,  5.13s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3352/36984 [5:35:43<54:15:56,  5.81s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3353/36984 [5:35:46<45:08:59,  4.83s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3354/36984 [5:35:53<52:05:37,  5.58s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3355/36984 [5:35:55<43:36:14,  4.67s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3356/36984 [5:36:05<57:44:07,  6.18s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3357/36984 [5:36:07<44:57:57,  4.81s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3358/36984 [5:36:15<54:25:01,  5.83s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3359/36984 [5:36:18<46:16:20,  4.95s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3359/36984 [5:36:32<46:16:20,  4.95s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3360/36984 [5:36:32<73:12:49,  7.84s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3361/36984 [5:36:34<56:37:41,  6.06s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3362/36984 [5:36:42<60:45:24,  6.51s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3363/36984 [5:36:44<49:32:14,  5.30s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3364/36984 [5:36:52<57:31:55,  6.16s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3365/36984 [5:36:56<50:24:30,  5.40s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3366/36984 [5:37:04<56:46:46,  6.08s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3367/36984 [5:37:06<45:52:46,  4.91s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3368/36984 [5:37:14<53:20:02,  5.71s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3369/36984 [5:37:17<47:04:35,  5.04s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3370/36984 [5:37:30<69:01:19,  7.39s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3371/36984 [5:37:33<55:47:30,  5.98s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3372/36984 [5:37:42<66:40:23,  7.14s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3373/36984 [5:37:49<63:51:49,  6.84s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3374/36984 [5:37:56<65:26:52,  7.01s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3375/36984 [5:37:59<53:58:44,  5.78s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3376/36984 [5:38:07<59:55:48,  6.42s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3377/36984 [5:38:10<50:41:09,  5.43s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3378/36984 [5:38:17<54:57:10,  5.89s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3379/36984 [5:38:20<46:53:04,  5.02s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3380/36984 [5:38:35<74:41:35,  8.00s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3381/36984 [5:38:42<73:44:00,  7.90s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3382/36984 [5:38:53<80:03:41,  8.58s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3383/36984 [5:38:58<70:44:16,  7.58s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3384/36984 [5:39:04<67:48:12,  7.26s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3385/36984 [5:39:08<56:08:24,  6.02s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3386/36984 [5:39:15<59:41:19,  6.40s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3387/36984 [5:39:18<50:07:09,  5.37s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3388/36984 [5:39:26<57:49:44,  6.20s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3389/36984 [5:39:28<47:14:20,  5.06s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3390/36984 [5:39:35<52:40:07,  5.64s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3391/36984 [5:39:38<43:14:33,  4.63s/batch, loss=0.0004]Training Epoch 1:   9%|▉         | 3391/36984 [5:39:46<43:14:33,  4.63s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3392/36984 [5:39:46<52:54:15,  5.67s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3393/36984 [5:39:48<43:31:17,  4.66s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3394/36984 [5:39:55<50:48:23,  5.45s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3395/36984 [5:39:57<41:36:39,  4.46s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3396/36984 [5:40:10<63:21:54,  6.79s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3397/36984 [5:40:11<48:32:58,  5.20s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3398/36984 [5:40:20<59:57:06,  6.43s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3399/36984 [5:40:22<45:41:17,  4.90s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3400/36984 [5:40:30<55:53:17,  5.99s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3401/36984 [5:40:31<42:17:40,  4.53s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3402/36984 [5:40:46<69:57:49,  7.50s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3403/36984 [5:40:46<49:48:40,  5.34s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3404/36984 [5:40:56<62:54:19,  6.74s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3405/36984 [5:40:59<50:42:53,  5.44s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3406/36984 [5:41:07<59:25:16,  6.37s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3407/36984 [5:41:09<47:43:44,  5.12s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3408/36984 [5:41:17<54:40:16,  5.86s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3409/36984 [5:41:19<44:33:47,  4.78s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3410/36984 [5:41:28<56:25:51,  6.05s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3411/36984 [5:41:30<43:14:03,  4.64s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3412/36984 [5:41:41<62:47:58,  6.73s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3413/36984 [5:41:43<48:03:43,  5.15s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3414/36984 [5:41:52<60:08:10,  6.45s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3415/36984 [5:41:53<45:53:48,  4.92s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3416/36984 [5:42:02<57:19:37,  6.15s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3417/36984 [5:42:03<42:13:24,  4.53s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3418/36984 [5:42:12<54:59:31,  5.90s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3419/36984 [5:42:14<41:58:33,  4.50s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3420/36984 [5:42:23<56:30:23,  6.06s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3421/36984 [5:42:24<42:39:51,  4.58s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3422/36984 [5:42:34<57:52:58,  6.21s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3423/36984 [5:42:36<44:03:19,  4.73s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3423/36984 [5:42:45<44:03:19,  4.73s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3424/36984 [5:42:45<56:24:54,  6.05s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3425/36984 [5:42:46<43:43:58,  4.69s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3426/36984 [5:42:54<51:37:48,  5.54s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3427/36984 [5:42:56<43:03:20,  4.62s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3428/36984 [5:43:04<50:52:39,  5.46s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3429/36984 [5:43:06<42:00:32,  4.51s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3430/36984 [5:43:14<50:46:13,  5.45s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3431/36984 [5:43:16<43:29:30,  4.67s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3432/36984 [5:43:25<53:12:05,  5.71s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3433/36984 [5:43:28<45:21:25,  4.87s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3434/36984 [5:43:35<52:58:33,  5.68s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3435/36984 [5:43:37<42:58:44,  4.61s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3436/36984 [5:43:45<51:57:26,  5.58s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3437/36984 [5:43:47<42:05:48,  4.52s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3438/36984 [5:43:54<49:36:04,  5.32s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3439/36984 [5:43:57<41:11:55,  4.42s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3440/36984 [5:44:04<49:12:36,  5.28s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3441/36984 [5:44:07<41:46:26,  4.48s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3442/36984 [5:44:16<55:26:20,  5.95s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3443/36984 [5:44:18<43:47:14,  4.70s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3444/36984 [5:44:27<57:10:23,  6.14s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3445/36984 [5:44:30<47:06:28,  5.06s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3446/36984 [5:44:39<60:04:32,  6.45s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3447/36984 [5:44:42<48:06:28,  5.16s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3448/36984 [5:44:53<65:20:40,  7.01s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3449/36984 [5:44:55<50:54:05,  5.46s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3450/36984 [5:45:03<59:39:18,  6.40s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3451/36984 [5:45:05<46:33:41,  5.00s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3452/36984 [5:45:13<55:19:08,  5.94s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3453/36984 [5:45:16<45:07:42,  4.85s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3454/36984 [5:45:26<59:34:32,  6.40s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3455/36984 [5:45:27<47:03:29,  5.05s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3455/36984 [5:45:39<47:03:29,  5.05s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3456/36984 [5:45:39<64:56:00,  6.97s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3457/36984 [5:45:40<47:58:04,  5.15s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3458/36984 [5:45:53<69:25:25,  7.45s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3459/36984 [5:45:53<50:41:20,  5.44s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3460/36984 [5:46:08<75:48:25,  8.14s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3461/36984 [5:46:10<58:02:38,  6.23s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3462/36984 [5:46:19<65:38:52,  7.05s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3463/36984 [5:46:19<48:29:41,  5.21s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3464/36984 [5:46:29<60:38:12,  6.51s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3465/36984 [5:46:30<44:07:41,  4.74s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3466/36984 [5:46:39<56:42:34,  6.09s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3467/36984 [5:46:40<42:05:24,  4.52s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3468/36984 [5:46:50<57:11:36,  6.14s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3469/36984 [5:46:50<41:18:57,  4.44s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3470/36984 [5:47:01<59:29:57,  6.39s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3471/36984 [5:47:01<42:15:14,  4.54s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3472/36984 [5:47:10<55:17:55,  5.94s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3473/36984 [5:47:11<40:18:10,  4.33s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3474/36984 [5:47:21<54:59:32,  5.91s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3475/36984 [5:47:21<39:06:03,  4.20s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3476/36984 [5:47:33<62:06:46,  6.67s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3477/36984 [5:47:34<44:05:11,  4.74s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3478/36984 [5:47:43<58:18:08,  6.26s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3479/36984 [5:47:44<42:31:07,  4.57s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3480/36984 [5:47:54<58:21:07,  6.27s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3481/36984 [5:47:55<41:55:41,  4.51s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3482/36984 [5:48:10<72:12:07,  7.76s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3483/36984 [5:48:10<51:18:51,  5.51s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3484/36984 [5:48:21<67:13:44,  7.22s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3485/36984 [5:48:22<47:55:28,  5.15s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3486/36984 [5:48:38<77:35:09,  8.34s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3487/36984 [5:48:38<54:54:52,  5.90s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3487/36984 [5:48:50<54:54:52,  5.90s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3488/36984 [5:48:50<72:46:14,  7.82s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3490/36984 [5:49:01<63:32:23,  6.83s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3491/36984 [5:49:02<48:17:03,  5.19s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3492/36984 [5:49:12<59:59:59,  6.45s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3493/36984 [5:49:12<44:13:11,  4.75s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3494/36984 [5:49:23<60:18:41,  6.48s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3495/36984 [5:49:23<43:39:50,  4.69s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3496/36984 [5:49:35<62:39:34,  6.74s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3497/36984 [5:49:35<44:54:18,  4.83s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3498/36984 [5:49:46<62:53:55,  6.76s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3499/36984 [5:49:48<47:32:16,  5.11s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3500/36984 [5:49:57<60:49:53,  6.54s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3501/36984 [5:49:58<44:27:07,  4.78s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3502/36984 [5:50:07<57:11:47,  6.15s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3503/36984 [5:50:08<42:28:04,  4.57s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3504/36984 [5:50:18<55:45:09,  5.99s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3505/36984 [5:50:19<43:03:00,  4.63s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3506/36984 [5:50:32<66:45:56,  7.18s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3507/36984 [5:50:36<56:50:20,  6.11s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3508/36984 [5:50:46<67:35:35,  7.27s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3509/36984 [5:50:47<49:41:41,  5.34s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3510/36984 [5:50:56<60:07:02,  6.47s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3511/36984 [5:50:57<44:41:49,  4.81s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3512/36984 [5:51:07<60:37:38,  6.52s/batch, loss=0.0003]Training Epoch 1:   9%|▉         | 3513/36984 [5:51:08<44:07:42,  4.75s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3514/36984 [5:51:18<60:43:57,  6.53s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3515/36984 [5:51:19<43:20:57,  4.66s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3516/36984 [5:51:29<57:43:25,  6.21s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3517/36984 [5:51:29<41:00:28,  4.41s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3518/36984 [5:51:39<55:51:39,  6.01s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3519/36984 [5:51:39<39:43:21,  4.27s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3519/36984 [5:51:54<39:43:21,  4.27s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3520/36984 [5:51:54<69:22:01,  7.46s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3522/36984 [5:52:03<57:41:49,  6.21s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3523/36984 [5:52:04<45:57:29,  4.94s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3524/36984 [5:52:14<58:20:06,  6.28s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3525/36984 [5:52:16<46:19:00,  4.98s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3526/36984 [5:52:25<55:59:05,  6.02s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3527/36984 [5:52:26<44:41:45,  4.81s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3528/36984 [5:52:37<61:18:16,  6.60s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3529/36984 [5:52:39<47:42:33,  5.13s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3530/36984 [5:52:49<60:18:04,  6.49s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3531/36984 [5:52:49<44:44:00,  4.81s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3532/36984 [5:52:59<57:28:49,  6.19s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3533/36984 [5:53:00<42:09:57,  4.54s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3534/36984 [5:53:10<59:02:08,  6.35s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3535/36984 [5:53:10<42:16:14,  4.55s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3536/36984 [5:53:20<56:34:18,  6.09s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3537/36984 [5:53:20<40:31:11,  4.36s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3538/36984 [5:53:34<64:43:27,  6.97s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3539/36984 [5:53:34<46:57:11,  5.05s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3540/36984 [5:53:43<58:36:25,  6.31s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3541/36984 [5:53:44<42:37:45,  4.59s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3542/36984 [5:53:53<56:17:02,  6.06s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3543/36984 [5:53:54<40:00:14,  4.31s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3544/36984 [5:54:04<56:53:40,  6.13s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3545/36984 [5:54:04<40:25:44,  4.35s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3546/36984 [5:54:14<56:47:17,  6.11s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3547/36984 [5:54:15<40:21:18,  4.34s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3548/36984 [5:54:25<56:16:52,  6.06s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3549/36984 [5:54:25<39:59:59,  4.31s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3550/36984 [5:54:35<55:19:01,  5.96s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3551/36984 [5:54:35<39:19:34,  4.23s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3551/36984 [5:54:46<39:19:34,  4.23s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3552/36984 [5:54:46<59:12:23,  6.38s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3554/36984 [5:54:57<55:17:20,  5.95s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3555/36984 [5:54:57<42:04:47,  4.53s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3556/36984 [5:55:11<62:49:03,  6.77s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3557/36984 [5:55:11<46:16:41,  4.98s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3558/36984 [5:55:21<59:21:59,  6.39s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3559/36984 [5:55:21<42:59:06,  4.63s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3560/36984 [5:55:31<57:10:53,  6.16s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3561/36984 [5:55:31<41:01:42,  4.42s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3562/36984 [5:55:42<59:30:36,  6.41s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3563/36984 [5:55:43<42:28:12,  4.57s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3564/36984 [5:55:52<56:33:08,  6.09s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3565/36984 [5:55:52<40:17:22,  4.34s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3566/36984 [5:56:03<58:53:09,  6.34s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3567/36984 [5:56:04<41:52:19,  4.51s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3568/36984 [5:56:13<56:06:32,  6.04s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3569/36984 [5:56:14<40:45:26,  4.39s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3570/36984 [5:56:24<55:37:05,  5.99s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3571/36984 [5:56:24<39:33:02,  4.26s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3572/36984 [5:56:34<55:36:26,  5.99s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3573/36984 [5:56:34<39:31:59,  4.26s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3574/36984 [5:56:44<54:54:47,  5.92s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3575/36984 [5:56:44<39:02:29,  4.21s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3576/36984 [5:56:57<62:05:24,  6.69s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3577/36984 [5:56:58<47:45:32,  5.15s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3578/36984 [5:57:15<80:05:54,  8.63s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3579/36984 [5:57:16<59:29:34,  6.41s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3580/36984 [5:57:33<87:28:53,  9.43s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3581/36984 [5:57:33<61:50:31,  6.67s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3582/36984 [5:57:49<89:01:05,  9.59s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3583/36984 [5:57:49<62:54:51,  6.78s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3583/36984 [5:58:01<62:54:51,  6.78s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3584/36984 [5:58:01<76:56:59,  8.29s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3585/36984 [5:58:03<58:19:52,  6.29s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3586/36984 [5:58:14<70:53:37,  7.64s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3587/36984 [5:58:14<50:13:47,  5.41s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3588/36984 [5:58:24<63:33:34,  6.85s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3589/36984 [5:58:24<45:05:33,  4.86s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3590/36984 [5:58:34<57:22:22,  6.19s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3591/36984 [5:58:34<40:45:52,  4.39s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3592/36984 [5:58:44<56:54:41,  6.14s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3593/36984 [5:58:44<40:26:38,  4.36s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3594/36984 [5:58:54<55:07:35,  5.94s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3595/36984 [5:58:54<39:11:21,  4.23s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3596/36984 [5:59:04<56:02:02,  6.04s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3597/36984 [5:59:05<39:49:35,  4.29s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3598/36984 [5:59:15<56:36:28,  6.10s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3599/36984 [5:59:15<40:13:40,  4.34s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3600/36984 [5:59:25<56:19:12,  6.07s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3601/36984 [5:59:25<40:01:38,  4.32s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3602/36984 [5:59:35<55:30:25,  5.99s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3603/36984 [5:59:36<39:27:26,  4.26s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3604/36984 [5:59:45<53:10:28,  5.73s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3605/36984 [5:59:45<37:49:10,  4.08s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3606/36984 [5:59:56<58:11:24,  6.28s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3607/36984 [5:59:57<41:20:01,  4.46s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3608/36984 [6:00:06<56:33:12,  6.10s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3609/36984 [6:00:07<40:11:27,  4.34s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3610/36984 [6:00:17<56:32:05,  6.10s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3611/36984 [6:00:17<40:10:25,  4.33s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3612/36984 [6:00:29<60:42:18,  6.55s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3613/36984 [6:00:29<43:05:40,  4.65s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3614/36984 [6:00:39<56:57:25,  6.14s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3615/36984 [6:00:39<40:28:31,  4.37s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3615/36984 [6:00:53<40:28:31,  4.37s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3616/36984 [6:00:53<68:25:25,  7.38s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3618/36984 [6:01:04<60:01:02,  6.48s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3619/36984 [6:01:04<45:38:01,  4.92s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3620/36984 [6:01:14<57:02:14,  6.15s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3621/36984 [6:01:14<42:03:28,  4.54s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3622/36984 [6:01:24<56:28:27,  6.09s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3623/36984 [6:01:25<40:55:14,  4.42s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3624/36984 [6:01:38<64:50:46,  7.00s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3625/36984 [6:01:38<46:26:25,  5.01s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3626/36984 [6:01:48<61:03:03,  6.59s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3627/36984 [6:01:49<43:32:37,  4.70s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3628/36984 [6:01:58<56:21:11,  6.08s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3629/36984 [6:01:58<40:43:36,  4.40s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3630/36984 [6:02:08<54:42:09,  5.90s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3631/36984 [6:02:08<38:56:22,  4.20s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3632/36984 [6:02:19<56:54:40,  6.14s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3633/36984 [6:02:19<40:27:38,  4.37s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3634/36984 [6:02:29<56:02:28,  6.05s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3635/36984 [6:02:29<39:50:26,  4.30s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3636/36984 [6:02:43<65:25:57,  7.06s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3637/36984 [6:02:43<47:20:46,  5.11s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3638/36984 [6:02:52<58:26:59,  6.31s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3639/36984 [6:02:53<42:42:11,  4.61s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3640/36984 [6:03:02<56:13:57,  6.07s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3641/36984 [6:03:03<40:42:57,  4.40s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3642/36984 [6:03:12<53:26:04,  5.77s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3643/36984 [6:03:13<40:49:00,  4.41s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3644/36984 [6:03:22<52:29:13,  5.67s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3645/36984 [6:03:24<41:42:03,  4.50s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3646/36984 [6:03:34<56:49:42,  6.14s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3647/36984 [6:03:37<48:47:50,  5.27s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3647/36984 [6:03:44<48:47:50,  5.27s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3648/36984 [6:03:44<55:31:46,  6.00s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3649/36984 [6:03:47<45:48:29,  4.95s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3650/36984 [6:03:56<56:43:26,  6.13s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3651/36984 [6:03:58<45:17:09,  4.89s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3652/36984 [6:04:06<54:02:04,  5.84s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3653/36984 [6:04:08<43:18:37,  4.68s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3654/36984 [6:04:16<52:55:02,  5.72s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3655/36984 [6:04:18<42:16:17,  4.57s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3656/36984 [6:04:26<53:05:47,  5.74s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3657/36984 [6:04:28<41:24:40,  4.47s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3658/36984 [6:04:37<54:41:07,  5.91s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3659/36984 [6:04:40<45:19:47,  4.90s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3660/36984 [6:04:46<50:33:25,  5.46s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3661/36984 [6:04:50<44:25:45,  4.80s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3662/36984 [6:04:57<50:32:45,  5.46s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3663/36984 [6:05:00<44:58:20,  4.86s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3664/36984 [6:05:07<50:53:07,  5.50s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3665/36984 [6:05:11<47:13:11,  5.10s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3666/36984 [6:05:18<51:16:45,  5.54s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3667/36984 [6:05:22<46:40:17,  5.04s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3668/36984 [6:05:28<49:09:48,  5.31s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3669/36984 [6:05:31<43:45:42,  4.73s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3670/36984 [6:05:37<48:02:19,  5.19s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3671/36984 [6:05:42<46:33:47,  5.03s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3672/36984 [6:05:47<47:48:55,  5.17s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3673/36984 [6:05:52<45:05:29,  4.87s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3674/36984 [6:05:57<46:53:52,  5.07s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3675/36984 [6:06:01<43:47:06,  4.73s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3676/36984 [6:06:07<48:10:34,  5.21s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3677/36984 [6:06:11<43:27:33,  4.70s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3678/36984 [6:06:18<48:46:40,  5.27s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3679/36984 [6:06:21<42:27:35,  4.59s/batch, loss=0.0003]Training Epoch 1:  10%|▉         | 3679/36984 [6:06:29<42:27:35,  4.59s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3680/36984 [6:06:29<51:48:02,  5.60s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3681/36984 [6:06:34<51:22:40,  5.55s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3682/36984 [6:06:39<50:13:40,  5.43s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3683/36984 [6:06:45<50:33:27,  5.47s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3684/36984 [6:06:50<49:46:21,  5.38s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3685/36984 [6:06:56<50:40:26,  5.48s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3686/36984 [6:07:00<48:28:09,  5.24s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3687/36984 [6:07:05<48:21:52,  5.23s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3688/36984 [6:07:10<46:59:50,  5.08s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3689/36984 [6:07:16<47:58:56,  5.19s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3690/36984 [6:07:23<52:49:49,  5.71s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3691/36984 [6:07:32<62:10:19,  6.72s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3692/36984 [6:07:37<58:03:44,  6.28s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3693/36984 [6:07:45<62:44:59,  6.79s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3694/36984 [6:07:48<53:16:45,  5.76s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3695/36984 [6:07:55<56:10:17,  6.07s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3696/36984 [6:07:59<50:02:16,  5.41s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3697/36984 [6:08:06<55:02:51,  5.95s/batch, loss=0.0004]Training Epoch 1:  10%|▉         | 3698/36984 [6:08:11<50:51:05,  5.50s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3699/36984 [6:08:17<52:52:12,  5.72s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3700/36984 [6:08:21<49:39:07,  5.37s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3701/36984 [6:08:27<50:09:59,  5.43s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3702/36984 [6:08:32<48:12:32,  5.21s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3703/36984 [6:08:37<48:46:11,  5.28s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3704/36984 [6:08:42<46:49:15,  5.06s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3705/36984 [6:08:47<47:26:57,  5.13s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3706/36984 [6:08:52<47:12:40,  5.11s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3707/36984 [6:08:58<48:50:48,  5.28s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3708/36984 [6:09:02<46:39:36,  5.05s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3709/36984 [6:09:10<55:47:41,  6.04s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3710/36984 [6:09:18<59:00:26,  6.38s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3711/36984 [6:09:23<57:25:16,  6.21s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3711/36984 [6:09:28<57:25:16,  6.21s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3712/36984 [6:09:28<51:53:30,  5.61s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3713/36984 [6:09:35<55:22:56,  5.99s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3714/36984 [6:09:39<51:01:37,  5.52s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3715/36984 [6:09:47<57:09:59,  6.19s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3716/36984 [6:09:51<52:00:48,  5.63s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3717/36984 [6:09:59<59:00:13,  6.39s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3718/36984 [6:10:03<51:22:18,  5.56s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3719/36984 [6:10:10<54:51:04,  5.94s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3720/36984 [6:10:18<61:00:15,  6.60s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3721/36984 [6:10:25<63:26:16,  6.87s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3722/36984 [6:10:29<53:24:11,  5.78s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3723/36984 [6:10:39<65:00:05,  7.04s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3724/36984 [6:10:43<57:09:38,  6.19s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3725/36984 [6:10:50<59:42:00,  6.46s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3726/36984 [6:10:53<50:18:08,  5.44s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3727/36984 [6:11:00<55:44:07,  6.03s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3728/36984 [6:11:04<48:14:40,  5.22s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3729/36984 [6:11:10<52:02:30,  5.63s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3730/36984 [6:11:14<47:15:58,  5.12s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3731/36984 [6:11:22<55:01:08,  5.96s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3732/36984 [6:11:26<48:12:31,  5.22s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3733/36984 [6:11:32<50:59:38,  5.52s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3734/36984 [6:11:36<46:14:23,  5.01s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3735/36984 [6:11:44<54:41:15,  5.92s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3736/36984 [6:11:47<48:41:09,  5.27s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3737/36984 [6:11:59<67:05:48,  7.27s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3738/36984 [6:12:05<62:49:16,  6.80s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3739/36984 [6:12:14<69:26:19,  7.52s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3740/36984 [6:12:17<56:42:49,  6.14s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3741/36984 [6:12:26<63:20:58,  6.86s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3742/36984 [6:12:29<53:11:39,  5.76s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3743/36984 [6:12:36<57:40:26,  6.25s/batch, loss=0.0004]Training Epoch 1:  10%|█         | 3743/36984 [6:12:39<57:40:26,  6.25s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3744/36984 [6:12:39<48:23:42,  5.24s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3745/36984 [6:12:47<54:30:59,  5.90s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3746/36984 [6:12:49<45:28:51,  4.93s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3747/36984 [6:12:57<53:19:37,  5.78s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3748/36984 [6:13:00<44:19:18,  4.80s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3749/36984 [6:13:08<53:34:49,  5.80s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3750/36984 [6:13:10<44:21:13,  4.80s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3751/36984 [6:13:18<51:54:38,  5.62s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3752/36984 [6:13:22<47:04:44,  5.10s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3753/36984 [6:13:30<55:38:30,  6.03s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3754/36984 [6:13:31<43:17:33,  4.69s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3755/36984 [6:13:40<53:11:01,  5.76s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3756/36984 [6:13:42<43:29:23,  4.71s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3757/36984 [6:13:52<59:43:51,  6.47s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3758/36984 [6:13:53<42:24:46,  4.60s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3759/36984 [6:14:07<68:14:11,  7.39s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3760/36984 [6:14:07<48:22:03,  5.24s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3761/36984 [6:14:19<66:44:47,  7.23s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3762/36984 [6:14:19<48:58:51,  5.31s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3763/36984 [6:14:29<61:25:23,  6.66s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3764/36984 [6:14:29<43:35:16,  4.72s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3765/36984 [6:14:40<60:35:36,  6.57s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3766/36984 [6:14:43<48:32:23,  5.26s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3767/36984 [6:14:52<59:08:50,  6.41s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3768/36984 [6:14:53<46:05:32,  5.00s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3769/36984 [6:15:06<67:46:46,  7.35s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3770/36984 [6:15:07<49:37:35,  5.38s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3771/36984 [6:15:20<71:48:23,  7.78s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3772/36984 [6:15:21<52:12:53,  5.66s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3773/36984 [6:15:31<63:21:38,  6.87s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3774/36984 [6:15:31<45:24:02,  4.92s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3775/36984 [6:15:44<68:36:43,  7.44s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3775/36984 [6:15:46<68:36:43,  7.44s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3776/36984 [6:15:46<53:07:39,  5.76s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3777/36984 [6:15:58<69:41:29,  7.56s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3778/36984 [6:15:59<52:16:02,  5.67s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3779/36984 [6:16:08<61:52:18,  6.71s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3780/36984 [6:16:09<45:18:27,  4.91s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3781/36984 [6:16:18<55:52:33,  6.06s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3782/36984 [6:16:19<43:05:34,  4.67s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3783/36984 [6:16:29<56:59:19,  6.18s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3784/36984 [6:16:30<42:45:31,  4.64s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3785/36984 [6:16:39<55:33:39,  6.02s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3786/36984 [6:16:40<41:29:41,  4.50s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3787/36984 [6:16:50<56:04:20,  6.08s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3788/36984 [6:16:51<41:00:21,  4.45s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3789/36984 [6:17:00<54:48:57,  5.94s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3790/36984 [6:17:00<38:58:09,  4.23s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3791/36984 [6:17:11<56:56:16,  6.18s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3792/36984 [6:17:12<41:23:42,  4.49s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3793/36984 [6:17:22<57:17:30,  6.21s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3794/36984 [6:17:22<40:42:08,  4.41s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3795/36984 [6:17:35<65:02:42,  7.06s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3796/36984 [6:17:36<46:07:50,  5.00s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3797/36984 [6:17:46<60:13:41,  6.53s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3798/36984 [6:17:46<42:45:28,  4.64s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3799/36984 [6:17:56<58:23:46,  6.33s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3800/36984 [6:17:56<41:28:35,  4.50s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3801/36984 [6:18:08<60:42:52,  6.59s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3802/36984 [6:18:08<43:05:56,  4.68s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3803/36984 [6:18:19<59:36:47,  6.47s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3804/36984 [6:18:19<42:19:48,  4.59s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3805/36984 [6:18:30<59:14:43,  6.43s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3806/36984 [6:18:30<42:04:16,  4.56s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3807/36984 [6:18:41<60:20:22,  6.55s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3807/36984 [6:18:41<60:20:22,  6.55s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3808/36984 [6:18:41<43:21:14,  4.70s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3809/36984 [6:18:53<61:22:17,  6.66s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3810/36984 [6:18:53<43:33:38,  4.73s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3811/36984 [6:19:11<80:37:00,  8.75s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3812/36984 [6:19:11<57:01:51,  6.19s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3813/36984 [6:19:21<67:04:11,  7.28s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3814/36984 [6:19:21<47:33:01,  5.16s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3815/36984 [6:19:31<59:25:45,  6.45s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3816/36984 [6:19:31<42:11:50,  4.58s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3817/36984 [6:19:49<80:37:01,  8.75s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3818/36984 [6:19:50<57:01:44,  6.19s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3819/36984 [6:19:59<66:59:03,  7.27s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3820/36984 [6:20:00<47:29:23,  5.16s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3821/36984 [6:20:09<59:55:51,  6.51s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3822/36984 [6:20:09<42:32:56,  4.62s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3823/36984 [6:20:19<55:39:56,  6.04s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3824/36984 [6:20:19<39:33:51,  4.30s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3825/36984 [6:20:29<54:35:37,  5.93s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3826/36984 [6:20:29<38:48:52,  4.21s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3827/36984 [6:20:38<52:48:39,  5.73s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3828/36984 [6:20:38<37:34:03,  4.08s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3829/36984 [6:20:50<58:10:00,  6.32s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3830/36984 [6:20:50<41:18:55,  4.49s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3831/36984 [6:21:00<56:04:57,  6.09s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3832/36984 [6:21:00<39:51:22,  4.33s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3833/36984 [6:21:14<64:53:09,  7.05s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3834/36984 [6:21:14<46:01:00,  5.00s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3835/36984 [6:21:23<58:21:07,  6.34s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3836/36984 [6:21:24<41:26:36,  4.50s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3837/36984 [6:21:36<63:57:12,  6.95s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3838/36984 [6:21:36<45:22:02,  4.93s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3839/36984 [6:21:47<61:09:03,  6.64s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3839/36984 [6:21:47<61:09:03,  6.64s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3840/36984 [6:21:47<43:55:11,  4.77s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3841/36984 [6:21:59<62:12:13,  6.76s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3842/36984 [6:21:59<44:08:27,  4.79s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3843/36984 [6:22:09<57:45:58,  6.27s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3844/36984 [6:22:09<41:02:09,  4.46s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3845/36984 [6:22:24<69:49:54,  7.59s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3846/36984 [6:22:24<49:28:48,  5.38s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3847/36984 [6:22:33<60:18:43,  6.55s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3848/36984 [6:22:34<42:48:56,  4.65s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3849/36984 [6:22:44<59:22:57,  6.45s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3850/36984 [6:22:45<42:09:50,  4.58s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3851/36984 [6:22:55<57:13:39,  6.22s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3852/36984 [6:22:55<40:39:15,  4.42s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3853/36984 [6:23:06<59:06:59,  6.42s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3854/36984 [6:23:06<41:59:02,  4.56s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3855/36984 [6:23:16<57:50:20,  6.29s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3856/36984 [6:23:17<41:05:11,  4.46s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3857/36984 [6:23:27<56:05:10,  6.10s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3858/36984 [6:23:27<39:51:27,  4.33s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3859/36984 [6:23:41<67:52:28,  7.38s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3860/36984 [6:23:41<48:06:35,  5.23s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3861/36984 [6:23:54<68:56:23,  7.49s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3862/36984 [6:23:54<48:51:27,  5.31s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3863/36984 [6:24:05<62:51:37,  6.83s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3864/36984 [6:24:05<44:36:00,  4.85s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3865/36984 [6:24:17<63:58:07,  6.95s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3866/36984 [6:24:17<45:22:31,  4.93s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3867/36984 [6:24:32<71:52:52,  7.81s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3868/36984 [6:24:32<50:54:57,  5.54s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3869/36984 [6:24:43<66:01:08,  7.18s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3870/36984 [6:24:43<46:48:32,  5.09s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3871/36984 [6:24:54<63:40:24,  6.92s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3871/36984 [6:24:55<63:40:24,  6.92s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3872/36984 [6:24:55<45:40:54,  4.97s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3873/36984 [6:25:04<58:58:27,  6.41s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3874/36984 [6:25:05<41:52:41,  4.55s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3875/36984 [6:25:14<55:44:11,  6.06s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3876/36984 [6:25:15<39:36:46,  4.31s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3877/36984 [6:25:30<71:37:18,  7.79s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3878/36984 [6:25:31<50:43:48,  5.52s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3879/36984 [6:25:42<65:50:23,  7.16s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3880/36984 [6:25:42<46:40:47,  5.08s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3881/36984 [6:25:52<59:26:50,  6.46s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3882/36984 [6:25:52<42:12:32,  4.59s/batch, loss=0.0003]Training Epoch 1:  10%|█         | 3883/36984 [6:26:02<56:54:26,  6.19s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3884/36984 [6:26:02<40:25:56,  4.40s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3885/36984 [6:26:12<56:10:17,  6.11s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3886/36984 [6:26:12<39:54:34,  4.34s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3887/36984 [6:26:22<54:16:12,  5.90s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3888/36984 [6:26:22<38:34:50,  4.20s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3889/36984 [6:26:32<54:36:00,  5.94s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3890/36984 [6:26:32<38:48:53,  4.22s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3891/36984 [6:26:42<52:53:58,  5.75s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3892/36984 [6:26:42<37:36:58,  4.09s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3893/36984 [6:26:53<56:59:17,  6.20s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3894/36984 [6:26:53<40:28:59,  4.40s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3895/36984 [6:27:03<54:57:12,  5.98s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3896/36984 [6:27:03<39:03:55,  4.25s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3897/36984 [6:27:13<54:58:18,  5.98s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3898/36984 [6:27:13<39:04:39,  4.25s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3899/36984 [6:27:23<54:44:31,  5.96s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3900/36984 [6:27:23<38:55:06,  4.23s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3901/36984 [6:27:33<53:17:11,  5.80s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3902/36984 [6:27:33<38:17:22,  4.17s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3903/36984 [6:27:47<63:38:48,  6.93s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3903/36984 [6:27:47<63:38:48,  6.93s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3904/36984 [6:27:47<45:40:01,  4.97s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3905/36984 [6:27:57<60:59:49,  6.64s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3906/36984 [6:27:58<43:17:48,  4.71s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3907/36984 [6:28:07<56:56:07,  6.20s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3908/36984 [6:28:08<41:06:59,  4.48s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3909/36984 [6:28:20<61:41:03,  6.71s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3910/36984 [6:28:21<46:13:55,  5.03s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3911/36984 [6:28:31<61:13:40,  6.66s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3912/36984 [6:28:32<44:57:01,  4.89s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3913/36984 [6:28:43<61:28:45,  6.69s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3914/36984 [6:28:44<45:18:34,  4.93s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3915/36984 [6:28:53<57:33:25,  6.27s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3916/36984 [6:28:54<41:52:38,  4.56s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3917/36984 [6:29:03<55:40:12,  6.06s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3918/36984 [6:29:04<40:15:22,  4.38s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3919/36984 [6:29:13<53:32:25,  5.83s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3920/36984 [6:29:14<39:33:59,  4.31s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3921/36984 [6:29:25<58:58:01,  6.42s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3922/36984 [6:29:27<47:19:58,  5.15s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3923/36984 [6:29:38<63:50:20,  6.95s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3924/36984 [6:29:40<48:37:10,  5.29s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3925/36984 [6:29:48<56:52:43,  6.19s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3926/36984 [6:29:50<45:09:39,  4.92s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3927/36984 [6:29:58<54:05:47,  5.89s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3928/36984 [6:30:00<43:29:23,  4.74s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3929/36984 [6:30:09<53:53:11,  5.87s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3930/36984 [6:30:12<46:18:16,  5.04s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3931/36984 [6:30:21<56:50:56,  6.19s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3932/36984 [6:30:23<45:31:31,  4.96s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3933/36984 [6:30:30<52:39:33,  5.74s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3934/36984 [6:30:33<42:51:54,  4.67s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3935/36984 [6:30:40<49:41:58,  5.41s/batch, loss=0.0002]Training Epoch 1:  11%|█         | 3935/36984 [6:30:42<49:41:58,  5.41s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3936/36984 [6:30:42<42:20:27,  4.61s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3937/36984 [6:30:49<47:53:55,  5.22s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3938/36984 [6:30:52<41:39:51,  4.54s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3939/36984 [6:30:59<47:02:34,  5.12s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3940/36984 [6:31:02<41:08:28,  4.48s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3941/36984 [6:31:08<47:12:51,  5.14s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3942/36984 [6:31:11<40:16:22,  4.39s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3943/36984 [6:31:19<51:54:45,  5.66s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3944/36984 [6:31:21<41:37:26,  4.54s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3945/36984 [6:31:30<51:40:21,  5.63s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3946/36984 [6:31:31<41:08:57,  4.48s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3947/36984 [6:31:40<51:27:41,  5.61s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3948/36984 [6:31:42<42:04:42,  4.59s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3949/36984 [6:31:58<73:33:49,  8.02s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3950/36984 [6:31:59<53:20:12,  5.81s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3951/36984 [6:32:08<64:29:50,  7.03s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3952/36984 [6:32:10<48:59:06,  5.34s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3953/36984 [6:32:18<56:51:06,  6.20s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3954/36984 [6:32:20<45:32:12,  4.96s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3955/36984 [6:32:32<65:22:32,  7.13s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3956/36984 [6:32:35<52:54:07,  5.77s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3957/36984 [6:32:42<56:23:01,  6.15s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3958/36984 [6:32:45<47:21:33,  5.16s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3959/36984 [6:32:54<58:19:48,  6.36s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3960/36984 [6:32:58<51:47:16,  5.65s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3961/36984 [6:33:04<52:18:38,  5.70s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3962/36984 [6:33:08<49:21:54,  5.38s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3963/36984 [6:33:17<57:27:29,  6.26s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3964/36984 [6:33:23<59:03:41,  6.44s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3965/36984 [6:33:29<57:40:28,  6.29s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3966/36984 [6:33:34<53:42:54,  5.86s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3967/36984 [6:33:39<51:37:03,  5.63s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3967/36984 [6:33:45<51:37:03,  5.63s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3968/36984 [6:33:45<51:58:40,  5.67s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3969/36984 [6:33:49<47:49:28,  5.21s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3970/36984 [6:33:56<52:02:02,  5.67s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3971/36984 [6:33:59<45:29:52,  4.96s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3972/36984 [6:34:06<50:45:37,  5.54s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3973/36984 [6:34:10<45:45:17,  4.99s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3974/36984 [6:34:17<50:08:00,  5.47s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3975/36984 [6:34:20<45:52:01,  5.00s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3976/36984 [6:34:28<54:00:39,  5.89s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3977/36984 [6:34:31<44:05:31,  4.81s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3978/36984 [6:34:40<56:24:59,  6.15s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3979/36984 [6:34:41<42:37:38,  4.65s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3980/36984 [6:34:50<53:03:29,  5.79s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3981/36984 [6:34:51<40:11:08,  4.38s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3982/36984 [6:35:01<57:48:04,  6.31s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3983/36984 [6:35:03<43:40:12,  4.76s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3984/36984 [6:35:11<54:20:51,  5.93s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3985/36984 [6:35:13<42:20:24,  4.62s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3986/36984 [6:35:23<56:54:55,  6.21s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3987/36984 [6:35:26<47:32:18,  5.19s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3988/36984 [6:35:40<72:45:36,  7.94s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3989/36984 [6:35:42<56:23:21,  6.15s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3990/36984 [6:35:50<62:06:18,  6.78s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3991/36984 [6:35:52<49:39:14,  5.42s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3992/36984 [6:36:01<58:49:17,  6.42s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3993/36984 [6:36:02<44:03:09,  4.81s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3994/36984 [6:36:12<58:37:28,  6.40s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3995/36984 [6:36:13<42:58:16,  4.69s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3996/36984 [6:36:24<59:52:55,  6.53s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3997/36984 [6:36:24<42:30:46,  4.64s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3998/36984 [6:36:34<56:49:37,  6.20s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3999/36984 [6:36:34<40:22:04,  4.41s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 3999/36984 [6:36:45<40:22:04,  4.41s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4000/36984 [6:36:45<57:01:05,  6.22s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4002/36984 [6:36:57<56:09:53,  6.13s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4003/36984 [6:36:57<42:43:56,  4.66s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4004/36984 [6:37:08<57:21:02,  6.26s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4005/36984 [6:37:08<42:17:26,  4.62s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4006/36984 [6:37:18<55:33:54,  6.07s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4007/36984 [6:37:18<40:15:52,  4.40s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4008/36984 [6:37:31<63:02:02,  6.88s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4009/36984 [6:37:31<45:09:34,  4.93s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4010/36984 [6:37:42<62:13:33,  6.79s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4011/36984 [6:37:42<44:22:12,  4.84s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4012/36984 [6:37:54<61:46:32,  6.74s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4013/36984 [6:37:54<43:56:38,  4.80s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4014/36984 [6:38:03<56:34:52,  6.18s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4015/36984 [6:38:04<40:14:55,  4.39s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4016/36984 [6:38:13<55:08:17,  6.02s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4017/36984 [6:38:14<39:12:53,  4.28s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4018/36984 [6:38:24<54:44:39,  5.98s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4019/36984 [6:38:24<38:55:35,  4.25s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4020/36984 [6:38:33<52:47:00,  5.76s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4021/36984 [6:38:33<37:32:35,  4.10s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4022/36984 [6:38:43<52:56:39,  5.78s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4023/36984 [6:38:43<37:39:10,  4.11s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4024/36984 [6:38:52<50:54:30,  5.56s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4025/36984 [6:38:52<36:13:54,  3.96s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4026/36984 [6:39:02<50:49:12,  5.55s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4027/36984 [6:39:02<36:10:11,  3.95s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4028/36984 [6:39:13<56:48:01,  6.20s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4029/36984 [6:39:14<40:21:08,  4.41s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4030/36984 [6:39:26<62:26:03,  6.82s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4031/36984 [6:39:26<44:17:34,  4.84s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4031/36984 [6:39:36<44:17:34,  4.84s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4032/36984 [6:39:36<57:43:35,  6.31s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4034/36984 [6:39:45<50:21:18,  5.50s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4035/36984 [6:39:45<38:21:41,  4.19s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4036/36984 [6:39:55<50:54:28,  5.56s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4037/36984 [6:39:55<37:36:01,  4.11s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4038/36984 [6:40:05<52:01:45,  5.69s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4039/36984 [6:40:05<37:44:06,  4.12s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4040/36984 [6:40:15<53:22:45,  5.83s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4041/36984 [6:40:15<38:19:59,  4.19s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4042/36984 [6:40:24<51:48:57,  5.66s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4043/36984 [6:40:25<37:02:36,  4.05s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4044/36984 [6:40:35<54:02:07,  5.91s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4045/36984 [6:40:35<38:30:33,  4.21s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4046/36984 [6:40:45<53:57:36,  5.90s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4047/36984 [6:40:45<38:24:30,  4.20s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4048/36984 [6:40:56<57:31:33,  6.29s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4049/36984 [6:40:56<40:53:17,  4.47s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4050/36984 [6:41:07<57:31:44,  6.29s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4051/36984 [6:41:07<40:52:35,  4.47s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4052/36984 [6:41:19<61:41:36,  6.74s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4053/36984 [6:41:20<43:47:05,  4.79s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4054/36984 [6:41:29<56:18:54,  6.16s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4055/36984 [6:41:29<40:00:55,  4.37s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4056/36984 [6:41:43<67:14:24,  7.35s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4057/36984 [6:41:44<47:39:59,  5.21s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4058/36984 [6:41:53<60:00:32,  6.56s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4059/36984 [6:41:54<42:35:44,  4.66s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4060/36984 [6:42:10<73:44:12,  8.06s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4061/36984 [6:42:10<52:12:26,  5.71s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4062/36984 [6:42:21<67:09:59,  7.34s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4063/36984 [6:42:21<47:36:34,  5.21s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4063/36984 [6:42:31<47:36:34,  5.21s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4064/36984 [6:42:31<59:15:40,  6.48s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4066/36984 [6:42:42<56:08:50,  6.14s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4067/36984 [6:42:42<42:43:08,  4.67s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4068/36984 [6:42:52<54:07:18,  5.92s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4069/36984 [6:42:52<39:56:23,  4.37s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4070/36984 [6:43:05<63:12:07,  6.91s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4071/36984 [6:43:06<45:42:51,  5.00s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4072/36984 [6:43:18<64:02:43,  7.01s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4073/36984 [6:43:18<45:52:32,  5.02s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4074/36984 [6:43:28<59:12:55,  6.48s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4075/36984 [6:43:28<42:14:52,  4.62s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4076/36984 [6:43:42<68:12:24,  7.46s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4077/36984 [6:43:42<48:27:29,  5.30s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4078/36984 [6:43:52<61:32:03,  6.73s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4079/36984 [6:43:53<43:42:57,  4.78s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4080/36984 [6:44:03<59:29:21,  6.51s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4081/36984 [6:44:03<42:15:44,  4.62s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4082/36984 [6:44:13<55:57:01,  6.12s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4083/36984 [6:44:13<39:46:09,  4.35s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4084/36984 [6:44:24<56:21:40,  6.17s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4085/36984 [6:44:24<40:03:05,  4.38s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4086/36984 [6:44:34<54:49:13,  6.00s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4087/36984 [6:44:34<38:58:10,  4.26s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4088/36984 [6:44:44<54:21:21,  5.95s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4089/36984 [6:44:44<38:38:49,  4.23s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4090/36984 [6:44:54<54:35:52,  5.98s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4091/36984 [6:44:54<38:48:42,  4.25s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4092/36984 [6:45:05<56:47:33,  6.22s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4093/36984 [6:45:05<40:21:12,  4.42s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4094/36984 [6:45:16<57:56:34,  6.34s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4095/36984 [6:45:16<41:09:16,  4.50s/batch, loss=0.0004]Training Epoch 1:  11%|█         | 4095/36984 [6:45:26<41:09:16,  4.50s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4096/36984 [6:45:26<56:32:19,  6.19s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4098/36984 [6:45:36<50:26:01,  5.52s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4099/36984 [6:45:36<38:25:08,  4.21s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4100/36984 [6:45:46<52:21:39,  5.73s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4101/36984 [6:45:46<38:39:17,  4.23s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4102/36984 [6:45:56<52:41:42,  5.77s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4103/36984 [6:45:56<38:12:16,  4.18s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4104/36984 [6:46:06<53:47:21,  5.89s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4105/36984 [6:46:07<38:36:30,  4.23s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4106/36984 [6:46:16<52:49:01,  5.78s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4107/36984 [6:46:16<37:44:47,  4.13s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4108/36984 [6:46:28<57:26:21,  6.29s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4109/36984 [6:46:28<40:53:38,  4.48s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4110/36984 [6:46:38<54:59:30,  6.02s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4111/36984 [6:46:38<39:07:48,  4.29s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4112/36984 [6:46:48<54:16:29,  5.94s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4113/36984 [6:46:48<38:36:07,  4.23s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4114/36984 [6:46:58<54:18:57,  5.95s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4115/36984 [6:46:58<38:37:36,  4.23s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4116/36984 [6:47:08<54:39:01,  5.99s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4117/36984 [6:47:08<38:51:00,  4.26s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4118/36984 [6:47:19<55:25:35,  6.07s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4119/36984 [6:47:19<39:23:39,  4.32s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4120/36984 [6:47:29<54:21:16,  5.95s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4121/36984 [6:47:29<38:38:34,  4.23s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4122/36984 [6:47:39<53:44:36,  5.89s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4123/36984 [6:47:39<38:12:49,  4.19s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4124/36984 [6:47:49<53:34:11,  5.87s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4125/36984 [6:47:49<38:05:22,  4.17s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4126/36984 [6:47:59<53:32:59,  5.87s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4127/36984 [6:47:59<38:04:52,  4.17s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4127/36984 [6:48:09<38:04:52,  4.17s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4128/36984 [6:48:09<54:55:45,  6.02s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4130/36984 [6:48:20<52:44:39,  5.78s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4131/36984 [6:48:20<40:09:07,  4.40s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4132/36984 [6:48:30<52:53:58,  5.80s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4133/36984 [6:48:30<39:02:45,  4.28s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4134/36984 [6:48:40<53:56:57,  5.91s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4135/36984 [6:48:41<39:06:10,  4.29s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4136/36984 [6:48:53<61:08:30,  6.70s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4137/36984 [6:48:54<43:49:00,  4.80s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4138/36984 [6:49:03<55:32:49,  6.09s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4139/36984 [6:49:03<39:40:01,  4.35s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4140/36984 [6:49:13<55:28:06,  6.08s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4141/36984 [6:49:13<39:31:04,  4.33s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4142/36984 [6:49:23<53:22:06,  5.85s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4143/36984 [6:49:23<37:59:42,  4.16s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4144/36984 [6:49:33<52:49:18,  5.79s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4145/36984 [6:49:33<37:35:31,  4.12s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4146/36984 [6:49:43<53:16:10,  5.84s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4147/36984 [6:49:43<37:53:18,  4.15s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4148/36984 [6:49:52<52:44:32,  5.78s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4149/36984 [6:49:53<37:30:54,  4.11s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4150/36984 [6:50:02<53:14:38,  5.84s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4151/36984 [6:50:03<37:51:59,  4.15s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4152/36984 [6:50:13<54:28:40,  5.97s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4153/36984 [6:50:13<38:43:44,  4.25s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4154/36984 [6:50:23<53:12:13,  5.83s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4155/36984 [6:50:23<37:50:19,  4.15s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4156/36984 [6:50:32<51:46:50,  5.68s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4157/36984 [6:50:32<36:50:10,  4.04s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4158/36984 [6:50:42<51:34:42,  5.66s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4159/36984 [6:50:42<36:41:49,  4.02s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4159/36984 [6:50:52<36:41:49,  4.02s/batch, loss=0.0003]Training Epoch 1:  11%|█         | 4160/36984 [6:50:52<53:13:09,  5.84s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4162/36984 [6:51:02<48:52:53,  5.36s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4163/36984 [6:51:02<37:15:02,  4.09s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4164/36984 [6:51:12<51:50:10,  5.69s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4165/36984 [6:51:12<38:16:25,  4.20s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4166/36984 [6:51:22<52:21:48,  5.74s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4167/36984 [6:51:22<37:58:22,  4.17s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4168/36984 [6:51:37<65:53:51,  7.23s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4169/36984 [6:51:37<47:10:55,  5.18s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4170/36984 [6:51:48<62:55:45,  6.90s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4171/36984 [6:51:48<44:51:42,  4.92s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4172/36984 [6:51:58<57:12:27,  6.28s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4173/36984 [6:51:58<40:44:11,  4.47s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4174/36984 [6:52:08<55:49:35,  6.13s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4175/36984 [6:52:08<39:43:15,  4.36s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4176/36984 [6:52:22<63:48:26,  7.00s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4177/36984 [6:52:22<45:17:05,  4.97s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4178/36984 [6:52:35<69:07:26,  7.59s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4179/36984 [6:52:36<48:59:40,  5.38s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4180/36984 [6:52:47<64:06:09,  7.03s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4181/36984 [6:52:47<45:28:15,  4.99s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4182/36984 [6:52:57<58:51:53,  6.46s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4183/36984 [6:52:57<41:48:03,  4.59s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4184/36984 [6:53:08<58:29:42,  6.42s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4185/36984 [6:53:08<41:32:23,  4.56s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4186/36984 [6:53:18<55:42:59,  6.12s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4187/36984 [6:53:18<39:35:37,  4.35s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4188/36984 [6:53:29<57:05:44,  6.27s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4189/36984 [6:53:29<40:33:41,  4.45s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4190/36984 [6:53:38<54:50:50,  6.02s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4191/36984 [6:53:39<38:58:57,  4.28s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4191/36984 [6:53:50<38:58:57,  4.28s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4192/36984 [6:53:50<57:20:43,  6.30s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4194/36984 [6:54:00<52:07:56,  5.72s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4195/36984 [6:54:00<39:41:46,  4.36s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4196/36984 [6:54:10<54:02:54,  5.93s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4197/36984 [6:54:11<39:53:01,  4.38s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4198/36984 [6:54:20<52:42:18,  5.79s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4199/36984 [6:54:20<38:13:05,  4.20s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4200/36984 [6:54:30<52:11:55,  5.73s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4201/36984 [6:54:30<37:29:42,  4.12s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4202/36984 [6:54:43<60:27:38,  6.64s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4203/36984 [6:54:43<43:07:16,  4.74s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4204/36984 [6:54:53<57:17:12,  6.29s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4205/36984 [6:54:53<40:47:34,  4.48s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4206/36984 [6:55:03<55:46:50,  6.13s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4207/36984 [6:55:03<39:41:12,  4.36s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4208/36984 [6:55:15<59:02:16,  6.48s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4209/36984 [6:55:15<41:56:32,  4.61s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4210/36984 [6:55:24<55:06:39,  6.05s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4211/36984 [6:55:25<39:10:42,  4.30s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4212/36984 [6:55:34<53:29:51,  5.88s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4213/36984 [6:55:34<38:02:47,  4.18s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4214/36984 [6:55:44<54:20:40,  5.97s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4215/36984 [6:55:45<38:38:13,  4.24s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4216/36984 [6:55:56<56:41:20,  6.23s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4217/36984 [6:55:56<40:16:31,  4.42s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4218/36984 [6:56:05<53:55:19,  5.92s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4219/36984 [6:56:05<38:20:00,  4.21s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4220/36984 [6:56:16<54:56:07,  6.04s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4221/36984 [6:56:16<39:02:40,  4.29s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4222/36984 [6:56:26<54:20:25,  5.97s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4223/36984 [6:56:26<38:37:35,  4.24s/batch, loss=0.0003]Training Epoch 1:  11%|█▏        | 4223/36984 [6:56:36<38:37:35,  4.24s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4224/36984 [6:56:36<53:11:45,  5.85s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4226/36984 [6:56:48<55:30:26,  6.10s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4227/36984 [6:56:49<42:13:55,  4.64s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4228/36984 [6:56:59<55:30:56,  6.10s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4229/36984 [6:56:59<40:57:12,  4.50s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4230/36984 [6:57:10<57:04:52,  6.27s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4231/36984 [6:57:10<41:20:25,  4.54s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4232/36984 [6:57:22<60:08:29,  6.61s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4233/36984 [6:57:22<43:06:48,  4.74s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4234/36984 [6:57:32<57:59:41,  6.38s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4235/36984 [6:57:32<41:23:13,  4.55s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4236/36984 [6:57:43<56:55:55,  6.26s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4237/36984 [6:57:43<40:32:21,  4.46s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4238/36984 [6:57:53<55:48:18,  6.14s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4239/36984 [6:57:53<39:41:51,  4.36s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4240/36984 [6:58:03<54:30:54,  5.99s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4241/36984 [6:58:03<38:45:58,  4.26s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4242/36984 [6:58:16<62:58:06,  6.92s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4243/36984 [6:58:17<44:41:04,  4.91s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4244/36984 [6:58:27<58:36:09,  6.44s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4245/36984 [6:58:27<41:37:11,  4.58s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4246/36984 [6:58:40<65:39:04,  7.22s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4247/36984 [6:58:41<46:33:02,  5.12s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4248/36984 [6:59:01<87:11:52,  9.59s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4249/36984 [6:59:01<61:37:46,  6.78s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4250/36984 [6:59:11<72:01:22,  7.92s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4251/36984 [6:59:12<51:00:18,  5.61s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4252/36984 [6:59:21<62:10:29,  6.84s/batch, loss=0.0002]Training Epoch 1:  11%|█▏        | 4253/36984 [6:59:21<44:06:58,  4.85s/batch, loss=0.0002]Training Epoch 1:  12%|█▏        | 4254/36984 [6:59:32<58:26:56,  6.43s/batch, loss=0.0002]Training Epoch 1:  12%|█▏        | 4255/36984 [6:59:32<41:30:19,  4.57s/batch, loss=0.0002]Training Epoch 1:  12%|█▏        | 4255/36984 [6:59:45<41:30:19,  4.57s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4256/36984 [6:59:45<64:06:37,  7.05s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4258/36984 [6:59:54<54:20:14,  5.98s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4259/36984 [6:59:54<41:21:08,  4.55s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4260/36984 [7:00:04<53:38:56,  5.90s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4261/36984 [7:00:04<39:35:27,  4.36s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4262/36984 [7:00:14<53:57:32,  5.94s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4263/36984 [7:00:14<39:06:35,  4.30s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4264/36984 [7:00:25<55:17:48,  6.08s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4265/36984 [7:00:25<39:40:57,  4.37s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4266/36984 [7:00:35<53:47:17,  5.92s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4267/36984 [7:00:35<38:25:32,  4.23s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4268/36984 [7:00:45<54:10:58,  5.96s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4269/36984 [7:00:45<38:36:34,  4.25s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4270/36984 [7:00:56<55:32:27,  6.11s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4271/36984 [7:00:56<39:31:03,  4.35s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4272/36984 [7:01:06<56:09:21,  6.18s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4273/36984 [7:01:07<39:55:12,  4.39s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4274/36984 [7:01:17<55:29:14,  6.11s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4275/36984 [7:01:17<39:26:35,  4.34s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4276/36984 [7:01:28<56:19:25,  6.20s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4277/36984 [7:01:28<40:01:29,  4.41s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4278/36984 [7:01:39<57:56:59,  6.38s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4279/36984 [7:01:39<41:09:33,  4.53s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4280/36984 [7:01:49<56:01:58,  6.17s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4281/36984 [7:01:49<39:48:50,  4.38s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4282/36984 [7:02:00<56:48:09,  6.25s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4283/36984 [7:02:00<40:21:14,  4.44s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4284/36984 [7:02:11<58:41:41,  6.46s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4285/36984 [7:02:11<41:40:35,  4.59s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4286/36984 [7:02:24<62:18:28,  6.86s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4287/36984 [7:02:24<44:12:14,  4.87s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4287/36984 [7:02:36<44:12:14,  4.87s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4288/36984 [7:02:36<63:13:57,  6.96s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4290/36984 [7:02:56<76:14:58,  8.40s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4291/36984 [7:02:56<57:49:58,  6.37s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4292/36984 [7:03:06<66:06:42,  7.28s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4293/36984 [7:03:06<48:39:43,  5.36s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4294/36984 [7:03:19<68:16:53,  7.52s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4295/36984 [7:03:19<49:20:37,  5.43s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4296/36984 [7:03:29<59:42:13,  6.58s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4297/36984 [7:03:29<42:48:06,  4.71s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4298/36984 [7:03:42<64:10:39,  7.07s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4299/36984 [7:03:42<45:44:13,  5.04s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4300/36984 [7:03:52<59:13:33,  6.52s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4301/36984 [7:03:52<42:08:45,  4.64s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4302/36984 [7:04:02<55:52:22,  6.15s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4303/36984 [7:04:02<39:44:50,  4.38s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4304/36984 [7:04:12<55:41:19,  6.13s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4305/36984 [7:04:12<39:35:41,  4.36s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4306/36984 [7:04:22<53:28:03,  5.89s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4307/36984 [7:04:22<38:01:49,  4.19s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4308/36984 [7:04:35<62:33:41,  6.89s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4309/36984 [7:04:36<44:23:25,  4.89s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4310/36984 [7:04:45<57:29:02,  6.33s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4311/36984 [7:04:45<40:49:53,  4.50s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4312/36984 [7:04:56<57:02:30,  6.29s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4313/36984 [7:04:56<40:31:12,  4.46s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4314/36984 [7:05:07<58:33:58,  6.45s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4315/36984 [7:05:07<41:35:16,  4.58s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4316/36984 [7:05:18<57:06:04,  6.29s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4317/36984 [7:05:18<40:33:34,  4.47s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4318/36984 [7:05:30<61:24:06,  6.77s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4319/36984 [7:05:30<43:34:16,  4.80s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4319/36984 [7:05:43<43:34:16,  4.80s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4320/36984 [7:05:43<66:23:51,  7.32s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4322/36984 [7:05:59<67:33:27,  7.45s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4323/36984 [7:05:59<51:17:41,  5.65s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4324/36984 [7:06:09<63:00:59,  6.95s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4325/36984 [7:06:10<46:24:48,  5.12s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4326/36984 [7:06:21<62:52:12,  6.93s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4327/36984 [7:06:22<45:28:36,  5.01s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4328/36984 [7:06:33<63:30:23,  7.00s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4329/36984 [7:06:34<45:29:23,  5.01s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4330/36984 [7:06:44<58:51:33,  6.49s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4331/36984 [7:06:44<41:59:36,  4.63s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4332/36984 [7:06:55<59:50:03,  6.60s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4333/36984 [7:06:55<42:34:36,  4.69s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4334/36984 [7:07:06<57:52:22,  6.38s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4335/36984 [7:07:06<41:08:57,  4.54s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4336/36984 [7:07:17<58:30:25,  6.45s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4337/36984 [7:07:17<41:34:11,  4.58s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4338/36984 [7:07:31<66:13:01,  7.30s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4339/36984 [7:07:31<46:57:18,  5.18s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4340/36984 [7:07:41<60:24:08,  6.66s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4341/36984 [7:07:41<42:52:40,  4.73s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4342/36984 [7:07:51<56:41:37,  6.25s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4343/36984 [7:07:51<40:16:27,  4.44s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4344/36984 [7:08:03<59:06:11,  6.52s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4345/36984 [7:08:03<41:57:33,  4.63s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4346/36984 [7:08:12<55:15:02,  6.09s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4347/36984 [7:08:13<39:19:15,  4.34s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4348/36984 [7:08:24<57:29:23,  6.34s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4349/36984 [7:08:24<40:49:50,  4.50s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4350/36984 [7:08:35<59:05:06,  6.52s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4351/36984 [7:08:35<42:17:43,  4.67s/batch, loss=0.0004]Training Epoch 1:  12%|█▏        | 4351/36984 [7:08:46<42:17:43,  4.67s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4352/36984 [7:08:46<57:59:27,  6.40s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4354/36984 [7:08:56<51:35:43,  5.69s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4355/36984 [7:08:56<39:17:09,  4.33s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4356/36984 [7:09:06<52:51:20,  5.83s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4357/36984 [7:09:06<39:00:46,  4.30s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4358/36984 [7:09:16<53:51:30,  5.94s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4359/36984 [7:09:16<39:02:04,  4.31s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4360/36984 [7:09:28<57:40:15,  6.36s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4361/36984 [7:09:28<41:21:41,  4.56s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4362/36984 [7:09:38<54:47:32,  6.05s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4363/36984 [7:09:38<39:08:07,  4.32s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4364/36984 [7:09:49<57:08:59,  6.31s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4365/36984 [7:09:49<40:41:39,  4.49s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4366/36984 [7:09:59<54:36:09,  6.03s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4367/36984 [7:09:59<38:51:26,  4.29s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4368/36984 [7:10:09<53:39:23,  5.92s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4369/36984 [7:10:09<38:10:18,  4.21s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4370/36984 [7:10:21<60:13:09,  6.65s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4371/36984 [7:10:21<42:45:11,  4.72s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4372/36984 [7:10:32<59:41:45,  6.59s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4373/36984 [7:10:33<42:22:59,  4.68s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4374/36984 [7:10:43<56:58:30,  6.29s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4375/36984 [7:10:43<40:28:23,  4.47s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4376/36984 [7:11:00<75:10:55,  8.30s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4377/36984 [7:11:00<53:13:02,  5.88s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4378/36984 [7:11:12<69:39:32,  7.69s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4379/36984 [7:11:12<49:20:54,  5.45s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4380/36984 [7:11:23<64:26:53,  7.12s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4381/36984 [7:11:24<45:41:56,  5.05s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4382/36984 [7:11:33<58:18:39,  6.44s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4383/36984 [7:11:34<41:24:31,  4.57s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4383/36984 [7:11:43<41:24:31,  4.57s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4384/36984 [7:11:43<55:41:51,  6.15s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4386/36984 [7:11:54<51:16:21,  5.66s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4387/36984 [7:11:54<39:02:36,  4.31s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4388/36984 [7:12:03<51:32:41,  5.69s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4389/36984 [7:12:04<38:03:34,  4.20s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4390/36984 [7:12:15<55:52:02,  6.17s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4391/36984 [7:12:15<40:28:22,  4.47s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4392/36984 [7:12:25<53:46:47,  5.94s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4393/36984 [7:12:25<38:36:37,  4.26s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4394/36984 [7:12:35<54:10:56,  5.99s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4395/36984 [7:12:35<38:42:10,  4.28s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4396/36984 [7:12:46<55:04:47,  6.08s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4397/36984 [7:12:46<39:14:21,  4.33s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4398/36984 [7:12:56<55:42:07,  6.15s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4399/36984 [7:12:56<39:37:23,  4.38s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4400/36984 [7:13:07<55:32:20,  6.14s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4401/36984 [7:13:07<39:29:17,  4.36s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4402/36984 [7:13:17<54:02:05,  5.97s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4403/36984 [7:13:17<38:25:30,  4.25s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4404/36984 [7:13:27<53:12:06,  5.88s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4405/36984 [7:13:27<37:50:06,  4.18s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4406/36984 [7:13:37<53:53:47,  5.96s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4407/36984 [7:13:37<38:19:05,  4.23s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4408/36984 [7:13:47<53:32:11,  5.92s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4409/36984 [7:13:47<38:03:55,  4.21s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4410/36984 [7:13:58<55:40:35,  6.15s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4411/36984 [7:13:58<39:33:34,  4.37s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4412/36984 [7:14:08<54:50:49,  6.06s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4413/36984 [7:14:08<38:58:45,  4.31s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4414/36984 [7:14:19<55:23:21,  6.12s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4415/36984 [7:14:19<39:21:44,  4.35s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4415/36984 [7:14:32<39:21:44,  4.35s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4416/36984 [7:14:32<62:03:24,  6.86s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4418/36984 [7:14:46<64:10:43,  7.09s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4419/36984 [7:14:46<48:45:06,  5.39s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4420/36984 [7:14:59<65:01:29,  7.19s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4421/36984 [7:14:59<47:52:14,  5.29s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4422/36984 [7:15:09<59:10:16,  6.54s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4423/36984 [7:15:09<42:50:01,  4.74s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4424/36984 [7:15:19<55:59:22,  6.19s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4425/36984 [7:15:19<40:10:13,  4.44s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4426/36984 [7:15:29<54:07:32,  5.98s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4427/36984 [7:15:29<38:39:52,  4.28s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4428/36984 [7:15:41<58:53:51,  6.51s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4429/36984 [7:15:41<41:54:59,  4.64s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4430/36984 [7:15:50<54:44:58,  6.05s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4431/36984 [7:15:50<38:57:41,  4.31s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4432/36984 [7:16:00<53:42:03,  5.94s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4433/36984 [7:16:00<38:12:07,  4.22s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4434/36984 [7:16:10<53:15:19,  5.89s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4435/36984 [7:16:10<37:52:25,  4.19s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4436/36984 [7:16:23<59:27:44,  6.58s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4437/36984 [7:16:23<42:13:00,  4.67s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4438/36984 [7:16:33<56:13:58,  6.22s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4439/36984 [7:16:33<39:57:10,  4.42s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4440/36984 [7:16:43<54:52:08,  6.07s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4441/36984 [7:16:43<38:59:46,  4.31s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4442/36984 [7:16:52<52:39:07,  5.82s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4443/36984 [7:16:53<37:26:45,  4.14s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4444/36984 [7:17:02<52:19:25,  5.79s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4445/36984 [7:17:02<37:12:48,  4.12s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4446/36984 [7:17:13<53:56:35,  5.97s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4447/36984 [7:17:13<38:20:41,  4.24s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4447/36984 [7:17:23<38:20:41,  4.24s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4448/36984 [7:17:23<54:48:16,  6.06s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4450/36984 [7:17:33<50:16:07,  5.56s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4451/36984 [7:17:33<38:17:26,  4.24s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4452/36984 [7:17:43<51:23:12,  5.69s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4453/36984 [7:17:43<37:56:00,  4.20s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4454/36984 [7:17:54<53:41:54,  5.94s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4455/36984 [7:17:54<38:55:19,  4.31s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4456/36984 [7:18:04<54:24:32,  6.02s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4457/36984 [7:18:04<39:03:17,  4.32s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4458/36984 [7:18:14<53:33:35,  5.93s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4459/36984 [7:18:14<38:15:54,  4.24s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4460/36984 [7:18:26<58:57:48,  6.53s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4461/36984 [7:18:27<41:57:48,  4.64s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4462/36984 [7:18:37<58:16:47,  6.45s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4463/36984 [7:18:37<41:25:47,  4.59s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4464/36984 [7:18:47<55:56:37,  6.19s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4465/36984 [7:18:48<39:45:55,  4.40s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4466/36984 [7:18:58<55:47:47,  6.18s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4467/36984 [7:18:58<39:39:13,  4.39s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4468/36984 [7:19:08<54:07:21,  5.99s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4469/36984 [7:19:08<38:28:51,  4.26s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4470/36984 [7:19:21<62:43:32,  6.95s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4471/36984 [7:19:22<44:29:40,  4.93s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4472/36984 [7:19:31<57:49:45,  6.40s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4473/36984 [7:19:32<41:04:13,  4.55s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4474/36984 [7:19:43<60:39:43,  6.72s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4475/36984 [7:19:44<43:03:05,  4.77s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4476/36984 [7:19:54<59:07:34,  6.55s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4477/36984 [7:19:55<41:58:27,  4.65s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4478/36984 [7:20:07<63:10:11,  7.00s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4479/36984 [7:20:07<44:48:20,  4.96s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4479/36984 [7:20:18<44:48:20,  4.96s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4480/36984 [7:20:18<61:09:18,  6.77s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4482/36984 [7:20:30<56:49:40,  6.29s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4483/36984 [7:20:30<43:13:25,  4.79s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4484/36984 [7:20:42<61:20:13,  6.79s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4485/36984 [7:20:43<45:11:03,  5.01s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4486/36984 [7:20:56<65:53:45,  7.30s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4487/36984 [7:20:56<47:38:05,  5.28s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4488/36984 [7:21:10<70:24:38,  7.80s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4489/36984 [7:21:10<50:22:08,  5.58s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4490/36984 [7:21:22<65:40:44,  7.28s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4491/36984 [7:21:22<46:47:26,  5.18s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4492/36984 [7:21:39<79:11:05,  8.77s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4493/36984 [7:21:39<56:09:05,  6.22s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4494/36984 [7:21:53<76:26:07,  8.47s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4495/36984 [7:21:53<54:09:21,  6.00s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4496/36984 [7:22:05<69:24:52,  7.69s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4497/36984 [7:22:05<49:12:12,  5.45s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4498/36984 [7:22:22<79:30:53,  8.81s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4499/36984 [7:22:22<56:15:39,  6.23s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4500/36984 [7:22:36<78:30:06,  8.70s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4501/36984 [7:22:37<55:32:21,  6.16s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4502/36984 [7:22:49<72:10:57,  8.00s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4503/36984 [7:22:49<51:06:52,  5.67s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4504/36984 [7:23:00<64:41:13,  7.17s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4505/36984 [7:23:00<45:52:01,  5.08s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4506/36984 [7:23:10<59:51:14,  6.63s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4507/36984 [7:23:11<42:29:06,  4.71s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4508/36984 [7:23:27<73:01:28,  8.09s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4509/36984 [7:23:27<51:42:17,  5.73s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4510/36984 [7:23:40<73:24:21,  8.14s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4511/36984 [7:23:41<51:58:11,  5.76s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4511/36984 [7:23:51<51:58:11,  5.76s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4512/36984 [7:23:51<63:05:42,  7.00s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4514/36984 [7:24:07<67:11:10,  7.45s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4515/36984 [7:24:07<51:00:36,  5.66s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4516/36984 [7:24:17<61:50:57,  6.86s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4517/36984 [7:24:17<45:33:04,  5.05s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4518/36984 [7:24:28<59:37:18,  6.61s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4519/36984 [7:24:28<43:08:40,  4.78s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4520/36984 [7:24:38<57:15:30,  6.35s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4521/36984 [7:24:38<41:03:57,  4.55s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4522/36984 [7:24:48<53:59:09,  5.99s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4523/36984 [7:24:48<38:33:44,  4.28s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4524/36984 [7:24:58<52:53:54,  5.87s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4525/36984 [7:24:58<37:42:31,  4.18s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4526/36984 [7:25:07<51:32:19,  5.72s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4527/36984 [7:25:07<36:42:17,  4.07s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4528/36984 [7:25:19<56:32:52,  6.27s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4529/36984 [7:25:19<40:11:37,  4.46s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4530/36984 [7:25:30<57:10:43,  6.34s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4531/36984 [7:25:30<40:37:28,  4.51s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4532/36984 [7:25:42<61:26:15,  6.82s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4533/36984 [7:25:42<43:35:57,  4.84s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4534/36984 [7:25:56<68:05:30,  7.55s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4535/36984 [7:25:57<48:15:03,  5.35s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4536/36984 [7:26:08<64:03:23,  7.11s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4537/36984 [7:26:08<45:25:24,  5.04s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4538/36984 [7:26:18<58:28:30,  6.49s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4539/36984 [7:26:18<41:31:08,  4.61s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4540/36984 [7:26:27<54:10:15,  6.01s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4541/36984 [7:26:28<38:30:26,  4.27s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4542/36984 [7:26:41<62:44:42,  6.96s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4543/36984 [7:26:41<44:30:26,  4.94s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4543/36984 [7:26:52<44:30:26,  4.94s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4544/36984 [7:26:52<60:35:51,  6.72s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4546/36984 [7:27:02<52:49:56,  5.86s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4547/36984 [7:27:02<40:13:06,  4.46s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4548/36984 [7:27:19<70:57:31,  7.88s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4549/36984 [7:27:20<52:11:16,  5.79s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4550/36984 [7:27:29<61:48:58,  6.86s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4551/36984 [7:27:29<44:43:00,  4.96s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4552/36984 [7:27:39<57:51:15,  6.42s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4553/36984 [7:27:40<41:29:13,  4.61s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4554/36984 [7:27:54<66:50:08,  7.42s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4555/36984 [7:27:54<47:36:14,  5.28s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4556/36984 [7:28:06<64:56:10,  7.21s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4557/36984 [7:28:06<46:09:12,  5.12s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4558/36984 [7:28:16<58:52:59,  6.54s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4559/36984 [7:28:16<41:51:10,  4.65s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4560/36984 [7:28:28<61:04:03,  6.78s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4561/36984 [7:28:28<43:21:27,  4.81s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4562/36984 [7:28:42<68:28:18,  7.60s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4563/36984 [7:28:42<48:31:38,  5.39s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4564/36984 [7:28:55<67:36:33,  7.51s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4565/36984 [7:28:55<47:54:55,  5.32s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4566/36984 [7:29:05<59:39:39,  6.63s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4567/36984 [7:29:05<42:21:10,  4.70s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4568/36984 [7:29:19<68:27:39,  7.60s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4569/36984 [7:29:20<48:30:37,  5.39s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4570/36984 [7:29:34<74:03:22,  8.22s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4571/36984 [7:29:35<52:25:14,  5.82s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4572/36984 [7:29:47<68:59:45,  7.66s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4573/36984 [7:29:47<48:52:41,  5.43s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4574/36984 [7:29:57<60:48:51,  6.76s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4575/36984 [7:29:57<43:09:28,  4.79s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4575/36984 [7:30:08<43:09:28,  4.79s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4576/36984 [7:30:08<59:27:33,  6.60s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4578/36984 [7:30:20<57:05:38,  6.34s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4579/36984 [7:30:20<43:25:22,  4.82s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4580/36984 [7:30:34<65:08:24,  7.24s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4581/36984 [7:30:34<47:56:56,  5.33s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4582/36984 [7:30:47<66:50:37,  7.43s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4583/36984 [7:30:47<48:18:32,  5.37s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4584/36984 [7:31:03<74:16:54,  8.25s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4585/36984 [7:31:03<53:06:23,  5.90s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4586/36984 [7:31:16<72:23:12,  8.04s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4587/36984 [7:31:16<51:30:21,  5.72s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4588/36984 [7:31:27<65:15:50,  7.25s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4589/36984 [7:31:27<46:22:50,  5.15s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4590/36984 [7:31:38<61:50:19,  6.87s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4591/36984 [7:31:38<43:55:13,  4.88s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4592/36984 [7:31:48<57:57:53,  6.44s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4593/36984 [7:31:49<41:10:58,  4.58s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4594/36984 [7:31:59<56:50:51,  6.32s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4595/36984 [7:31:59<40:23:31,  4.49s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4596/36984 [7:32:11<60:12:24,  6.69s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4597/36984 [7:32:11<42:44:07,  4.75s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4598/36984 [7:32:23<61:07:01,  6.79s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4599/36984 [7:32:23<43:22:14,  4.82s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4600/36984 [7:32:33<56:31:47,  6.28s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4601/36984 [7:32:33<40:09:36,  4.46s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4602/36984 [7:32:44<56:29:14,  6.28s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4603/36984 [7:32:44<40:07:24,  4.46s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4604/36984 [7:32:54<54:48:02,  6.09s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4605/36984 [7:32:54<38:56:38,  4.33s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4606/36984 [7:33:03<52:39:06,  5.85s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4607/36984 [7:33:04<37:26:35,  4.16s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4607/36984 [7:33:13<37:26:35,  4.16s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4608/36984 [7:33:13<52:18:47,  5.82s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4610/36984 [7:33:23<49:00:20,  5.45s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4611/36984 [7:33:23<37:20:12,  4.15s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4612/36984 [7:33:33<49:59:18,  5.56s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4613/36984 [7:33:33<36:55:22,  4.11s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4614/36984 [7:33:43<49:59:29,  5.56s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4615/36984 [7:33:43<36:16:08,  4.03s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4616/36984 [7:33:52<50:57:50,  5.67s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4617/36984 [7:33:53<36:36:50,  4.07s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4618/36984 [7:34:02<50:06:36,  5.57s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4619/36984 [7:34:02<35:49:56,  3.99s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4620/36984 [7:34:11<49:05:45,  5.46s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4621/36984 [7:34:11<35:02:12,  3.90s/batch, loss=0.0003]Training Epoch 1:  12%|█▏        | 4622/36984 [7:34:21<50:47:09,  5.65s/batch, loss=0.0003]Training Epoch 1:  12%|█▎        | 4623/36984 [7:34:21<36:10:32,  4.02s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4624/36984 [7:34:31<50:39:57,  5.64s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4625/36984 [7:34:31<36:04:25,  4.01s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4626/36984 [7:34:40<51:10:37,  5.69s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4627/36984 [7:34:41<36:25:12,  4.05s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4628/36984 [7:34:50<51:59:02,  5.78s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4629/36984 [7:34:51<36:58:44,  4.11s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4630/36984 [7:35:00<52:02:14,  5.79s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4631/36984 [7:35:01<37:00:50,  4.12s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4632/36984 [7:35:16<67:42:47,  7.53s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4633/36984 [7:35:16<47:58:57,  5.34s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4634/36984 [7:35:30<70:46:14,  7.88s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4635/36984 [7:35:30<50:07:00,  5.58s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4636/36984 [7:35:40<61:18:27,  6.82s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4637/36984 [7:35:40<43:29:43,  4.84s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4638/36984 [7:35:52<63:07:50,  7.03s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4639/36984 [7:35:53<44:46:40,  4.98s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4639/36984 [7:36:03<44:46:40,  4.98s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4640/36984 [7:36:03<58:31:30,  6.51s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4642/36984 [7:36:12<51:49:22,  5.77s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4643/36984 [7:36:13<39:27:12,  4.39s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4644/36984 [7:36:24<56:10:54,  6.25s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4645/36984 [7:36:24<41:25:37,  4.61s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4646/36984 [7:36:33<52:29:30,  5.84s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4647/36984 [7:36:34<38:03:13,  4.24s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4648/36984 [7:36:43<51:57:45,  5.79s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4649/36984 [7:36:43<37:19:02,  4.15s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4650/36984 [7:36:53<51:58:47,  5.79s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4651/36984 [7:36:53<37:08:52,  4.14s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4652/36984 [7:37:05<57:57:01,  6.45s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4653/36984 [7:37:06<41:15:02,  4.59s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4654/36984 [7:37:15<54:54:44,  6.11s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4655/36984 [7:37:15<39:04:05,  4.35s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4656/36984 [7:37:25<52:39:35,  5.86s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4657/36984 [7:37:25<37:28:08,  4.17s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4658/36984 [7:37:35<53:59:07,  6.01s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4659/36984 [7:37:36<38:23:10,  4.28s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4660/36984 [7:37:45<52:45:17,  5.88s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4661/36984 [7:37:45<37:31:03,  4.18s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4662/36984 [7:37:55<52:19:29,  5.83s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4663/36984 [7:37:55<37:12:42,  4.14s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4664/36984 [7:38:05<51:15:16,  5.71s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4665/36984 [7:38:05<36:27:58,  4.06s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4666/36984 [7:38:15<53:06:27,  5.92s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4667/36984 [7:38:15<37:45:32,  4.21s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4668/36984 [7:38:25<52:29:57,  5.85s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4669/36984 [7:38:25<37:19:57,  4.16s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4670/36984 [7:38:35<52:46:59,  5.88s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4671/36984 [7:38:35<37:31:56,  4.18s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4671/36984 [7:38:44<37:31:56,  4.18s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4672/36984 [7:38:44<50:47:21,  5.66s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4674/36984 [7:38:54<47:47:09,  5.32s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4675/36984 [7:38:55<36:25:12,  4.06s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4676/36984 [7:39:04<49:37:07,  5.53s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4677/36984 [7:39:04<36:38:59,  4.08s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4678/36984 [7:39:14<50:18:58,  5.61s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4679/36984 [7:39:14<36:30:00,  4.07s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4680/36984 [7:39:27<58:40:21,  6.54s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4681/36984 [7:39:27<42:03:49,  4.69s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4682/36984 [7:39:37<57:28:10,  6.40s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4683/36984 [7:39:38<41:00:43,  4.57s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4684/36984 [7:39:48<55:06:37,  6.14s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4685/36984 [7:39:48<39:15:14,  4.38s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4686/36984 [7:39:57<52:27:02,  5.85s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4687/36984 [7:39:57<37:20:37,  4.16s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4688/36984 [7:40:07<51:20:46,  5.72s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4689/36984 [7:40:07<36:32:52,  4.07s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4690/36984 [7:40:18<56:05:55,  6.25s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4691/36984 [7:40:18<39:51:41,  4.44s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4692/36984 [7:40:28<53:34:53,  5.97s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4693/36984 [7:40:28<38:05:34,  4.25s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4694/36984 [7:40:38<53:35:15,  5.97s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4695/36984 [7:40:38<38:05:28,  4.25s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4696/36984 [7:40:49<53:48:41,  6.00s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4697/36984 [7:40:49<38:15:08,  4.27s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4698/36984 [7:40:58<52:50:52,  5.89s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4699/36984 [7:40:59<37:34:37,  4.19s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4700/36984 [7:41:09<54:52:17,  6.12s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4701/36984 [7:41:09<38:59:34,  4.35s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4702/36984 [7:41:20<55:00:08,  6.13s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4703/36984 [7:41:20<39:05:08,  4.36s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4703/36984 [7:41:31<39:05:08,  4.36s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4704/36984 [7:41:31<56:23:04,  6.29s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4706/36984 [7:41:43<55:03:09,  6.14s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4707/36984 [7:41:43<41:53:09,  4.67s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4708/36984 [7:41:54<56:52:17,  6.34s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4709/36984 [7:41:54<41:55:48,  4.68s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4710/36984 [7:42:05<57:53:31,  6.46s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4711/36984 [7:42:05<41:54:47,  4.68s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4712/36984 [7:42:17<59:59:13,  6.69s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4713/36984 [7:42:17<42:59:43,  4.80s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4714/36984 [7:42:27<54:57:02,  6.13s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4715/36984 [7:42:27<39:14:24,  4.38s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4716/36984 [7:42:39<59:55:06,  6.68s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4717/36984 [7:42:39<42:37:47,  4.76s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4718/36984 [7:42:49<54:58:07,  6.13s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4719/36984 [7:42:49<39:06:27,  4.36s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4720/36984 [7:42:58<52:48:49,  5.89s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4721/36984 [7:42:58<37:34:29,  4.19s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4722/36984 [7:43:11<58:46:09,  6.56s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4723/36984 [7:43:11<41:44:07,  4.66s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4724/36984 [7:43:21<56:12:24,  6.27s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4725/36984 [7:43:21<39:56:06,  4.46s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4726/36984 [7:43:30<53:19:59,  5.95s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4727/36984 [7:43:31<37:55:18,  4.23s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4728/36984 [7:43:42<56:23:08,  6.29s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4729/36984 [7:43:42<40:03:18,  4.47s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4730/36984 [7:43:57<68:42:22,  7.67s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4731/36984 [7:43:57<48:40:36,  5.43s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4732/36984 [7:44:09<66:32:36,  7.43s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4733/36984 [7:44:10<47:09:44,  5.26s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4734/36984 [7:44:20<60:38:39,  6.77s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4735/36984 [7:44:20<43:02:02,  4.80s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4735/36984 [7:44:30<43:02:02,  4.80s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4736/36984 [7:44:30<57:49:49,  6.46s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4738/36984 [7:44:44<58:11:20,  6.50s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4739/36984 [7:44:44<44:14:32,  4.94s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4740/36984 [7:44:55<60:04:51,  6.71s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4741/36984 [7:44:56<44:15:57,  4.94s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4742/36984 [7:45:06<56:28:27,  6.31s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4743/36984 [7:45:06<40:53:51,  4.57s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4744/36984 [7:45:17<57:41:30,  6.44s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4745/36984 [7:45:17<41:21:57,  4.62s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4746/36984 [7:45:27<55:06:53,  6.15s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4747/36984 [7:45:27<39:21:14,  4.39s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4748/36984 [7:45:38<56:59:41,  6.36s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4749/36984 [7:45:38<40:34:23,  4.53s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4750/36984 [7:45:50<59:37:31,  6.66s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4751/36984 [7:45:50<42:22:08,  4.73s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4752/36984 [7:46:02<61:57:03,  6.92s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4753/36984 [7:46:02<43:58:05,  4.91s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4754/36984 [7:46:13<59:39:43,  6.66s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4755/36984 [7:46:13<42:21:26,  4.73s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4756/36984 [7:46:25<60:12:36,  6.73s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4757/36984 [7:46:25<42:43:58,  4.77s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4758/36984 [7:46:35<58:03:19,  6.49s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4759/36984 [7:46:36<41:13:15,  4.60s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4760/36984 [7:46:46<57:33:47,  6.43s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4761/36984 [7:46:47<40:52:37,  4.57s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4762/36984 [7:46:58<58:21:29,  6.52s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4763/36984 [7:46:58<41:26:04,  4.63s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4764/36984 [7:47:10<62:21:27,  6.97s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4765/36984 [7:47:11<44:14:05,  4.94s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4766/36984 [7:47:21<60:06:59,  6.72s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4767/36984 [7:47:22<42:39:50,  4.77s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4767/36984 [7:47:37<42:39:50,  4.77s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4768/36984 [7:47:37<72:25:34,  8.09s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4770/36984 [7:47:47<59:36:33,  6.66s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4771/36984 [7:47:48<45:18:34,  5.06s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4772/36984 [7:47:58<57:46:38,  6.46s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4773/36984 [7:47:58<42:35:18,  4.76s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4774/36984 [7:48:09<57:44:55,  6.45s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4775/36984 [7:48:09<41:48:32,  4.67s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4776/36984 [7:48:19<55:22:37,  6.19s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4777/36984 [7:48:19<39:43:55,  4.44s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4778/36984 [7:48:29<53:37:08,  5.99s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4779/36984 [7:48:29<38:17:56,  4.28s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4780/36984 [7:48:39<53:36:53,  5.99s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4781/36984 [7:48:40<38:11:52,  4.27s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4782/36984 [7:48:50<54:23:07,  6.08s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4783/36984 [7:48:50<38:41:39,  4.33s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4784/36984 [7:49:00<52:58:58,  5.92s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4785/36984 [7:49:00<37:41:27,  4.21s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4786/36984 [7:49:10<53:28:29,  5.98s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4787/36984 [7:49:10<38:00:43,  4.25s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4788/36984 [7:49:22<57:49:02,  6.46s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4789/36984 [7:49:22<41:03:15,  4.59s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4790/36984 [7:49:35<63:21:54,  7.09s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4791/36984 [7:49:35<44:56:19,  5.03s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4792/36984 [7:49:46<58:59:18,  6.60s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4793/36984 [7:49:46<41:52:20,  4.68s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4794/36984 [7:49:57<59:36:47,  6.67s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4795/36984 [7:49:57<42:18:45,  4.73s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4796/36984 [7:50:08<59:07:53,  6.61s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4797/36984 [7:50:09<41:58:05,  4.69s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4798/36984 [7:50:18<56:08:31,  6.28s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4799/36984 [7:50:19<39:52:52,  4.46s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4799/36984 [7:50:29<39:52:52,  4.46s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4800/36984 [7:50:29<55:33:28,  6.21s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4802/36984 [7:50:39<50:57:26,  5.70s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4803/36984 [7:50:39<38:48:21,  4.34s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4804/36984 [7:50:49<51:00:05,  5.71s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4805/36984 [7:50:49<37:39:20,  4.21s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4806/36984 [7:50:59<52:28:29,  5.87s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4807/36984 [7:51:00<38:02:25,  4.26s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4808/36984 [7:51:10<53:07:05,  5.94s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4809/36984 [7:51:10<38:08:03,  4.27s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4810/36984 [7:51:19<52:11:26,  5.84s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4811/36984 [7:51:20<37:17:33,  4.17s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4812/36984 [7:51:31<55:24:33,  6.20s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4813/36984 [7:51:31<39:27:41,  4.42s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4814/36984 [7:51:42<58:37:22,  6.56s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4815/36984 [7:51:43<41:39:45,  4.66s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4816/36984 [7:51:52<54:17:27,  6.08s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4817/36984 [7:51:52<38:36:34,  4.32s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4818/36984 [7:52:02<53:56:13,  6.04s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4819/36984 [7:52:03<38:20:56,  4.29s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4820/36984 [7:52:13<54:00:57,  6.05s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4821/36984 [7:52:13<38:23:58,  4.30s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4822/36984 [7:52:23<53:02:52,  5.94s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4823/36984 [7:52:23<37:43:14,  4.22s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4824/36984 [7:52:33<52:59:38,  5.93s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4825/36984 [7:52:33<37:40:44,  4.22s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4826/36984 [7:52:43<52:46:14,  5.91s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4827/36984 [7:52:43<37:31:00,  4.20s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4828/36984 [7:52:54<55:33:03,  6.22s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4829/36984 [7:52:54<39:27:58,  4.42s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4830/36984 [7:53:05<55:34:36,  6.22s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4831/36984 [7:53:05<39:29:02,  4.42s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4831/36984 [7:53:17<39:29:02,  4.42s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4832/36984 [7:53:17<59:48:18,  6.70s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4834/36984 [7:53:26<51:30:23,  5.77s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4835/36984 [7:53:26<39:12:53,  4.39s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4836/36984 [7:53:36<51:41:06,  5.79s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4837/36984 [7:53:36<38:09:11,  4.27s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4838/36984 [7:53:46<51:09:27,  5.73s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4839/36984 [7:53:46<37:05:48,  4.15s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4840/36984 [7:53:56<50:37:55,  5.67s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4841/36984 [7:53:56<36:22:42,  4.07s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4842/36984 [7:54:05<50:41:51,  5.68s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4843/36984 [7:54:05<36:14:25,  4.06s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4844/36984 [7:54:16<52:11:54,  5.85s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4845/36984 [7:54:16<37:12:24,  4.17s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4846/36984 [7:54:26<53:18:06,  5.97s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4847/36984 [7:54:26<37:56:15,  4.25s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4848/36984 [7:54:36<53:43:30,  6.02s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4849/36984 [7:54:37<38:12:27,  4.28s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4850/36984 [7:54:46<52:48:20,  5.92s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4851/36984 [7:54:46<37:33:20,  4.21s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4852/36984 [7:54:56<51:25:09,  5.76s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4853/36984 [7:54:56<36:34:50,  4.10s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4854/36984 [7:55:06<51:43:03,  5.79s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4855/36984 [7:55:06<36:46:52,  4.12s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4856/36984 [7:55:18<56:22:16,  6.32s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4857/36984 [7:55:18<40:02:30,  4.49s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4858/36984 [7:56:07<161:05:10, 18.05s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4859/36984 [7:56:08<113:20:14, 12.70s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4860/36984 [7:56:18<107:34:27, 12.06s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4861/36984 [7:56:18<75:52:51,  8.50s/batch, loss=0.0003] Training Epoch 1:  13%|█▎        | 4862/36984 [7:56:28<79:52:24,  8.95s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4863/36984 [7:56:29<56:29:27,  6.33s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4863/36984 [7:56:41<56:29:27,  6.33s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4864/36984 [7:56:41<73:17:00,  8.21s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4866/36984 [7:56:52<61:34:15,  6.90s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4867/36984 [7:56:52<46:46:57,  5.24s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4868/36984 [7:57:05<63:39:36,  7.14s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4869/36984 [7:57:05<46:52:11,  5.25s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4870/36984 [7:57:15<58:12:41,  6.53s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4871/36984 [7:57:15<42:08:23,  4.72s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4872/36984 [7:57:26<58:37:02,  6.57s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4873/36984 [7:57:26<42:01:15,  4.71s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4874/36984 [7:57:36<55:05:21,  6.18s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4875/36984 [7:57:36<39:20:01,  4.41s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4876/36984 [7:57:45<52:31:32,  5.89s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4877/36984 [7:57:46<37:26:07,  4.20s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4878/36984 [7:57:56<54:44:18,  6.14s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4879/36984 [7:57:57<38:56:34,  4.37s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4880/36984 [7:58:07<54:15:14,  6.08s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4881/36984 [7:58:07<38:34:44,  4.33s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4882/36984 [7:58:16<51:46:11,  5.81s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4883/36984 [7:58:16<36:49:52,  4.13s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4884/36984 [7:58:27<55:08:15,  6.18s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4885/36984 [7:58:28<39:10:49,  4.39s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4886/36984 [7:58:38<54:31:46,  6.12s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4887/36984 [7:58:38<38:45:04,  4.35s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4888/36984 [7:58:48<53:19:08,  5.98s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4889/36984 [7:58:48<37:54:08,  4.25s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4890/36984 [7:58:58<53:55:33,  6.05s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4891/36984 [7:58:58<38:19:40,  4.30s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4892/36984 [7:59:09<54:56:20,  6.16s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4893/36984 [7:59:09<39:02:14,  4.38s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4894/36984 [7:59:19<54:52:47,  6.16s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4895/36984 [7:59:20<38:59:40,  4.37s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4895/36984 [7:59:30<38:59:40,  4.37s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4896/36984 [7:59:30<55:47:39,  6.26s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4898/36984 [7:59:40<50:48:45,  5.70s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4899/36984 [7:59:41<38:41:26,  4.34s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4900/36984 [7:59:53<57:28:49,  6.45s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4901/36984 [7:59:53<42:22:12,  4.75s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4902/36984 [8:00:03<54:15:54,  6.09s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4903/36984 [8:00:03<39:19:07,  4.41s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4904/36984 [8:00:15<57:45:10,  6.48s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4905/36984 [8:00:15<41:24:35,  4.65s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4906/36984 [8:00:25<55:48:07,  6.26s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4907/36984 [8:00:25<39:50:08,  4.47s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4908/36984 [8:00:35<53:21:31,  5.99s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4909/36984 [8:00:35<38:01:20,  4.27s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4910/36984 [8:00:46<57:04:28,  6.41s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4911/36984 [8:00:47<40:34:52,  4.55s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4912/36984 [8:00:56<53:52:19,  6.05s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4913/36984 [8:00:56<38:18:45,  4.30s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4914/36984 [8:01:06<53:13:42,  5.98s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4915/36984 [8:01:06<37:51:10,  4.25s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4916/36984 [8:01:16<52:36:55,  5.91s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4917/36984 [8:01:16<37:24:50,  4.20s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4918/36984 [8:01:28<58:16:21,  6.54s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4919/36984 [8:01:29<41:22:31,  4.65s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4920/36984 [8:01:39<55:28:18,  6.23s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4921/36984 [8:01:39<39:24:32,  4.42s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4922/36984 [8:01:49<55:27:19,  6.23s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4923/36984 [8:01:49<39:23:56,  4.42s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4924/36984 [8:02:02<61:27:49,  6.90s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4925/36984 [8:02:02<43:35:55,  4.90s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4926/36984 [8:02:12<56:53:41,  6.39s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4927/36984 [8:02:12<40:24:10,  4.54s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4927/36984 [8:02:27<40:24:10,  4.54s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4928/36984 [8:02:27<66:16:23,  7.44s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4930/36984 [8:02:37<57:27:46,  6.45s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4931/36984 [8:02:37<43:41:31,  4.91s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4932/36984 [8:02:47<54:11:11,  6.09s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4933/36984 [8:02:47<39:58:18,  4.49s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4934/36984 [8:03:00<59:56:54,  6.73s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4935/36984 [8:03:00<43:22:39,  4.87s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4936/36984 [8:03:10<56:45:20,  6.38s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4937/36984 [8:03:10<40:42:11,  4.57s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4938/36984 [8:03:20<53:43:26,  6.04s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4939/36984 [8:03:20<38:22:26,  4.31s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4940/36984 [8:03:37<72:50:24,  8.18s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4941/36984 [8:03:37<51:41:29,  5.81s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4942/36984 [8:03:47<61:53:37,  6.95s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4943/36984 [8:03:47<43:57:21,  4.94s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4944/36984 [8:03:59<62:55:08,  7.07s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4945/36984 [8:04:00<44:38:54,  5.02s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4946/36984 [8:04:10<58:16:40,  6.55s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4947/36984 [8:04:10<41:23:03,  4.65s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4948/36984 [8:04:20<57:05:08,  6.41s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4949/36984 [8:04:21<40:32:36,  4.56s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4950/36984 [8:04:31<55:59:28,  6.29s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4951/36984 [8:04:31<39:46:19,  4.47s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4952/36984 [8:04:42<55:37:43,  6.25s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4953/36984 [8:04:42<39:31:16,  4.44s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4954/36984 [8:04:54<60:36:00,  6.81s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4955/36984 [8:04:54<42:59:50,  4.83s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4956/36984 [8:05:06<60:37:01,  6.81s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4957/36984 [8:05:06<43:00:37,  4.83s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4958/36984 [8:05:16<57:30:05,  6.46s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4959/36984 [8:05:17<40:49:50,  4.59s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4959/36984 [8:05:27<40:49:50,  4.59s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4960/36984 [8:05:27<57:22:00,  6.45s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4962/36984 [8:05:37<51:03:12,  5.74s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4963/36984 [8:05:37<38:52:16,  4.37s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4964/36984 [8:05:46<50:00:02,  5.62s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4965/36984 [8:05:47<36:55:14,  4.15s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4966/36984 [8:05:57<52:45:43,  5.93s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4967/36984 [8:05:57<38:14:48,  4.30s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4968/36984 [8:06:12<63:51:20,  7.18s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4969/36984 [8:06:12<45:43:29,  5.14s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4970/36984 [8:06:25<66:03:00,  7.43s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4971/36984 [8:06:25<47:02:24,  5.29s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4972/36984 [8:06:35<60:03:04,  6.75s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4973/36984 [8:06:35<42:42:50,  4.80s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4974/36984 [8:06:52<73:42:00,  8.29s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4975/36984 [8:06:52<52:13:51,  5.87s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4976/36984 [8:07:04<69:00:01,  7.76s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4977/36984 [8:07:05<48:54:21,  5.50s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4978/36984 [8:07:15<62:07:27,  6.99s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4979/36984 [8:07:15<44:04:35,  4.96s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4980/36984 [8:07:29<66:38:06,  7.50s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4981/36984 [8:07:29<47:13:42,  5.31s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4982/36984 [8:07:38<58:30:03,  6.58s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4983/36984 [8:07:39<41:31:53,  4.67s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4984/36984 [8:07:52<65:22:30,  7.35s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4985/36984 [8:07:52<46:20:17,  5.21s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4986/36984 [8:08:04<62:25:42,  7.02s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4987/36984 [8:08:04<44:16:23,  4.98s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4988/36984 [8:08:16<62:28:24,  7.03s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4989/36984 [8:08:16<44:18:35,  4.99s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4990/36984 [8:08:26<59:00:56,  6.64s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4991/36984 [8:08:27<41:53:22,  4.71s/batch, loss=0.0002]Training Epoch 1:  13%|█▎        | 4991/36984 [8:08:39<41:53:22,  4.71s/batch, loss=0.0003]Training Epoch 1:  13%|█▎        | 4992/36984 [8:08:39<63:36:28,  7.16s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 4994/36984 [8:08:49<54:23:46,  6.12s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 4995/36984 [8:08:50<41:23:08,  4.66s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 4996/36984 [8:08:59<53:26:38,  6.01s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 4997/36984 [8:09:00<39:25:44,  4.44s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 4998/36984 [8:09:10<53:09:57,  5.98s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 4999/36984 [8:09:10<38:31:58,  4.34s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5000/36984 [8:09:20<53:09:59,  5.98s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5001/36984 [8:09:20<38:09:51,  4.30s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5002/36984 [8:09:29<50:01:26,  5.63s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5003/36984 [8:09:29<35:45:57,  4.03s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5004/36984 [8:09:39<50:56:24,  5.73s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5005/36984 [8:09:39<36:19:18,  4.09s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5006/36984 [8:09:49<51:15:34,  5.77s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5007/36984 [8:09:49<36:30:13,  4.11s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5008/36984 [8:09:58<50:50:47,  5.72s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5009/36984 [8:09:59<36:11:29,  4.07s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5010/36984 [8:10:09<51:48:14,  5.83s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5011/36984 [8:10:09<36:51:07,  4.15s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5012/36984 [8:10:20<55:38:02,  6.26s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5013/36984 [8:10:20<39:31:38,  4.45s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5014/36984 [8:10:30<53:39:49,  6.04s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5015/36984 [8:10:30<38:08:47,  4.30s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5016/36984 [8:10:40<51:57:53,  5.85s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5017/36984 [8:10:40<36:57:19,  4.16s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5018/36984 [8:10:50<51:30:16,  5.80s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5019/36984 [8:10:50<36:37:36,  4.13s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5020/36984 [8:11:00<51:36:03,  5.81s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5021/36984 [8:11:00<36:41:59,  4.13s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5022/36984 [8:11:10<51:53:20,  5.84s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5023/36984 [8:11:10<36:53:41,  4.16s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5023/36984 [8:11:20<36:53:41,  4.16s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5024/36984 [8:11:20<52:00:17,  5.86s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5026/36984 [8:11:29<47:44:09,  5.38s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5027/36984 [8:11:29<36:22:32,  4.10s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5028/36984 [8:11:39<49:23:29,  5.56s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5029/36984 [8:11:39<36:28:41,  4.11s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5030/36984 [8:11:50<53:27:51,  6.02s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5031/36984 [8:11:51<38:44:31,  4.36s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5032/36984 [8:12:01<53:15:48,  6.00s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5033/36984 [8:12:01<38:13:51,  4.31s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5034/36984 [8:12:10<51:33:03,  5.81s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5035/36984 [8:12:10<36:50:11,  4.15s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5036/36984 [8:12:21<53:37:55,  6.04s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5037/36984 [8:12:21<38:12:32,  4.31s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5038/36984 [8:12:32<55:01:30,  6.20s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5039/36984 [8:12:32<39:08:43,  4.41s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5040/36984 [8:12:43<55:18:37,  6.23s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5041/36984 [8:12:43<39:18:57,  4.43s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5042/36984 [8:12:53<54:00:35,  6.09s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5043/36984 [8:12:53<38:23:49,  4.33s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5044/36984 [8:13:04<55:43:54,  6.28s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5045/36984 [8:13:04<39:35:31,  4.46s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5046/36984 [8:13:14<55:38:43,  6.27s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5047/36984 [8:13:15<39:31:51,  4.46s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5048/36984 [8:13:25<54:46:54,  6.18s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5049/36984 [8:13:25<38:55:30,  4.39s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5050/36984 [8:13:35<54:03:33,  6.09s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5051/36984 [8:13:35<38:25:09,  4.33s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5052/36984 [8:13:46<54:59:42,  6.20s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5053/36984 [8:13:46<39:04:18,  4.41s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5054/36984 [8:13:56<53:29:20,  6.03s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5055/36984 [8:13:56<38:01:03,  4.29s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5055/36984 [8:14:09<38:01:03,  4.29s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5056/36984 [8:14:09<59:36:00,  6.72s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5058/36984 [8:14:20<55:01:13,  6.20s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5059/36984 [8:14:20<41:51:20,  4.72s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5060/36984 [8:14:30<53:32:15,  6.04s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5061/36984 [8:14:30<39:29:52,  4.45s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5062/36984 [8:14:40<52:18:48,  5.90s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5063/36984 [8:14:40<37:55:16,  4.28s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5064/36984 [8:14:50<54:11:23,  6.11s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5065/36984 [8:14:51<38:53:16,  4.39s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5066/36984 [8:15:01<55:38:09,  6.28s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5067/36984 [8:15:02<39:42:50,  4.48s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5068/36984 [8:15:12<55:43:43,  6.29s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5069/36984 [8:15:12<39:40:46,  4.48s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5070/36984 [8:15:22<53:47:59,  6.07s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5071/36984 [8:15:22<38:16:54,  4.32s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5072/36984 [8:15:36<62:11:21,  7.02s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5073/36984 [8:15:36<44:08:10,  4.98s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5074/36984 [8:15:46<58:15:01,  6.57s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5075/36984 [8:15:46<41:21:58,  4.67s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5076/36984 [8:15:58<59:11:07,  6.68s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5077/36984 [8:15:58<42:00:34,  4.74s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5078/36984 [8:16:08<55:49:13,  6.30s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5079/36984 [8:16:08<39:39:09,  4.47s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5080/36984 [8:16:25<73:37:05,  8.31s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5081/36984 [8:16:26<52:06:33,  5.88s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5082/36984 [8:16:36<63:39:00,  7.18s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5083/36984 [8:16:36<45:07:49,  5.09s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5084/36984 [8:16:48<62:33:58,  7.06s/batch, loss=0.0003]Training Epoch 1:  14%|█▎        | 5085/36984 [8:16:48<44:22:16,  5.01s/batch, loss=0.0003]Training Epoch 1:  14%|█▍        | 5086/36984 [8:17:01<66:15:03,  7.48s/batch, loss=0.0003]Training Epoch 1:  14%|█▍        | 5087/36984 [8:17:01<46:57:10,  5.30s/batch, loss=0.0003]Training Epoch 1:  14%|█▍        | 5087/36984 [8:17:14<46:57:10,  5.30s/batch, loss=0.0003]Training Epoch 1:  14%|█▍        | 5088/36984 [8:17:14<65:44:56,  7.42s/batch, loss=0.0003]slurmstepd: error: *** JOB 62474948 ON mb-gen002 CANCELLED AT 2025-10-21T10:33:38 ***
